#!/usr/bin/env python3
"""
Cian.ru Parser —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º breadcrumbs –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ—Ö–æ–∂–∏—Ö –æ–±—ä—è–≤–ª–µ–Ω–∏–π
"""

from playwright.sync_api import sync_playwright, Page
from typing import Dict, List, Optional
import logging
import time
import random
import re

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class CianParserBreadcrumbs:
    """
    –ü–∞—Ä—Å–µ—Ä —Å –ø–æ–∏—Å–∫–æ–º —á–µ—Ä–µ–∑ breadcrumbs (—Ö–ª–µ–±–Ω—ã–µ –∫—Ä–æ—à–∫–∏)
    """

    def __init__(self, headless: bool = True):
        self.headless = headless
        self.playwright = None
        self.browser = None
        self.context = None

    def __enter__(self):
        self.playwright = sync_playwright().start()
        
        logger.info("üöÄ –ó–∞–ø—É—Å–∫ –±—Ä–∞—É–∑–µ—Ä–∞...")
        
        self.browser = self.playwright.chromium.launch(
            headless=self.headless,
            args=[
                '--disable-blink-features=AutomationControlled',
                '--disable-dev-shm-usage',
                '--no-sandbox',
            ]
        )

        self.context = self.browser.new_context(
            user_agent='Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36',
            viewport={'width': 1920, 'height': 1080},
            locale='ru-RU',
            timezone_id='Europe/Moscow',
        )

        self.context.add_init_script("""
            Object.defineProperty(navigator, 'webdriver', {
                get: () => undefined
            });
            window.chrome = { runtime: {} };
        """)

        logger.info("‚úÖ –ë—Ä–∞—É–∑–µ—Ä –≥–æ—Ç–æ–≤")
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        if self.context:
            self.context.close()
        if self.browser:
            self.browser.close()
        if self.playwright:
            self.playwright.stop()

    def _extract_characteristics(self, page: Page) -> Dict[str, str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≤—Å–µ—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫"""
        characteristics = {}

        try:
            items = page.locator('[data-testid="OfferSummaryInfoItem"]').all()
            
            for item in items:
                try:
                    paragraphs = item.locator('p').all()
                    if len(paragraphs) >= 2:
                        key = paragraphs[0].text_content().strip()
                        value = paragraphs[1].text_content().strip()
                        if key and value:
                            characteristics[key] = value
                except:
                    pass

            # –≠—Ç–∞–∂ –∏–∑ meta
            try:
                og_title = page.locator('meta[property="og:title"]').first
                if og_title:
                    content = og_title.get_attribute('content')
                    if content:
                        floor_match = re.search(r'—ç—Ç–∞–∂ (\d+/\d+)', content, re.IGNORECASE)
                        if floor_match:
                            characteristics['–≠—Ç–∞–∂'] = floor_match.group(1)
            except:
                pass

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫: {e}")

        return characteristics

    def _find_breadcrumb_link(self, page: Page) -> Optional[str]:
        """
        –ù–∞—Ö–æ–¥–∏–º —Å—Å—ã–ª–∫—É –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É –ø–æ–∏—Å–∫–∞ —á–µ—Ä–µ–∑ breadcrumbs
        """
        try:
            # –ò—â–µ–º breadcrumbs (—Ö–ª–µ–±–Ω—ã–µ –∫—Ä–æ—à–∫–∏)
            breadcrumb_selectors = [
                'nav[data-name="Breadcrumbs"] a',
                '[data-name="Breadcrumbs"] a',
                'nav a[href*="/cat.php"]',
                'a[href*="deal_type=sale"]',
            ]
            
            for selector in breadcrumb_selectors:
                links = page.locator(selector).all()
                
                for link in links:
                    href = link.get_attribute('href')
                    text = link.text_content()
                    
                    # –ò—â–µ–º —Å—Å—ã–ª–∫—É –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É –ø–æ–∏—Å–∫–∞ (–Ω–µ –≥–ª–∞–≤–Ω—É—é, –Ω–µ —Ä–µ–≥–∏–æ–Ω)
                    if href and '/cat.php' in href and 'deal_type=sale' in href:
                        full_url = href if href.startswith('http') else f"https://www.cian.ru{href}"
                        logger.info(f"üîó –ù–∞–π–¥–µ–Ω breadcrumb: '{text}' -> {full_url}")
                        return full_url
            
            logger.warning("‚ö†Ô∏è Breadcrumb –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return None
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ breadcrumb: {e}")
            return None

    def _parse_listing_card(self, card, page: Page) -> Optional[Dict]:
        """
        –ü–∞—Ä—Å–∏–Ω–≥ –æ–¥–Ω–æ–π –∫–∞—Ä—Ç–æ—á–∫–∏ –æ–±—ä—è–≤–ª–µ–Ω–∏—è –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ –ø–æ–∏—Å–∫–∞
        """
        try:
            listing = {}
            
            # URL –æ–±—ä—è–≤–ª–µ–Ω–∏—è
            link = card.locator('a[href*="/sale/flat/"]').first
            if link:
                href = link.get_attribute('href')
                if href:
                    listing['url'] = href if href.startswith('http') else f"https://www.cian.ru{href}"
            
            if not listing.get('url'):
                return None
            
            # –ó–∞–≥–æ–ª–æ–≤–æ–∫
            title_selectors = [
                '[data-mark="OfferTitle"]',
                'h3',
                'span[data-mark="OfferTitle"]'
            ]
            for sel in title_selectors:
                title_elem = card.locator(sel).first
                if title_elem:
                    listing['title'] = title_elem.text_content().strip()
                    break
            
            # –¶–µ–Ω–∞
            price_selectors = [
                '[data-mark="MainPrice"]',
                'span[data-mark="MainPrice"]',
                '[class*="price"]'
            ]
            for sel in price_selectors:
                price_elem = card.locator(sel).first
                if price_elem:
                    price_text = price_elem.text_content().strip()
                    if price_text and ('‚ÇΩ' in price_text or '—Ä—É–±' in price_text):
                        listing['price'] = price_text
                        # –ò–∑–≤–ª–µ–∫–∞–µ–º —á–∏—Å–ª–æ
                        price_match = re.search(r'(\d+[\s\d]*)', price_text.replace(' ', ''))
                        if price_match:
                            listing['price_raw'] = int(price_match.group(1).replace(' ', ''))
                        break
            
            # –ü–ª–æ—â–∞–¥—å –∏ —ç—Ç–∞–∂ –∏–∑ —Ç–µ–∫—Å—Ç–∞
            text_content = card.text_content()
            
            area_match = re.search(r'(\d+[,.]?\d*)\s*–º¬≤', text_content)
            if area_match:
                listing['area'] = area_match.group(0)
            
            floor_match = re.search(r'(\d+)/(\d+)\s*—ç—Ç', text_content)
            if floor_match:
                listing['floor'] = f"{floor_match.group(1)}/{floor_match.group(2)}"
            
            return listing if listing.get('title') and listing.get('price') else None
            
        except Exception as e:
            logger.debug(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –∫–∞—Ä—Ç–æ—á–∫–∏: {e}")
            return None

    def _parse_full_listing(self, url: str) -> Dict:
        """
        –ü–æ–ª–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –æ–¥–Ω–æ–≥–æ –æ–±—ä—è–≤–ª–µ–Ω–∏—è (–¥–ª—è –ø–æ—Ö–æ–∂–∏—Ö)
        """
        result = {
            'url': url,
            'title': None,
            'price': None,
            'characteristics': {},
        }
        
        try:
            page = self.context.new_page()
            
            logger.info(f"   üìÑ –ü–∞—Ä—Å–∏–Ω–≥: {url[:60]}...")
            
            page.goto(url, wait_until='domcontentloaded', timeout=30000)
            time.sleep(1)
            
            # –ó–∞–≥–æ–ª–æ–≤–æ–∫
            try:
                h1 = page.locator('h1').first
                if h1:
                    result['title'] = h1.text_content().strip()
            except:
                pass
            
            # –¶–µ–Ω–∞
            try:
                price_elem = page.locator('[data-testid="price-amount"]').first
                if price_elem:
                    result['price'] = price_elem.text_content().strip()
            except:
                pass
            
            # –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
            result['characteristics'] = self._extract_characteristics(page)
            
            page.close()
            
        except Exception as e:
            logger.debug(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞: {e}")
        
        return result

    def _get_similar_from_search(self, breadcrumb_url: str, max_similar: int = 10) -> List[Dict]:
        """
        –ü–æ–ª—É—á–∞–µ–º –ø–æ—Ö–æ–∂–∏–µ –æ–±—ä—è–≤–ª–µ–Ω–∏—è —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –ø–æ–∏—Å–∫–∞
        """
        similar = []
        
        try:
            logger.info(f"üîç –û—Ç–∫—Ä—ã–≤–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É –ø–æ–∏—Å–∫–∞...")
            
            page = self.context.new_page()
            page.goto(breadcrumb_url, wait_until='domcontentloaded', timeout=30000)
            time.sleep(2)
            
            # –ò—â–µ–º –∫–∞—Ä—Ç–æ—á–∫–∏ –æ–±—ä—è–≤–ª–µ–Ω–∏–π
            card_selectors = [
                '[data-name="CardComponent"]',
                'article[data-name="CardComponent"]',
                'div[data-name="OfferCard"]',
            ]
            
            cards = []
            for selector in card_selectors:
                cards = page.locator(selector).all()
                if cards:
                    logger.info(f"   –ù–∞–π–¥–µ–Ω–æ {len(cards)} –∫–∞—Ä—Ç–æ—á–µ–∫")
                    break
            
            # –ü–∞—Ä—Å–∏–º –∫–∞—Ä—Ç–æ—á–∫–∏
            for i, card in enumerate(cards[:max_similar]):
                listing = self._parse_listing_card(card, page)
                if listing:
                    similar.append(listing)
                    logger.info(f"   ‚úÖ [{i+1}] {listing.get('title', 'N/A')[:40]}... - {listing.get('price', 'N/A')}")
            
            page.close()
            
            logger.info(f"‚úÖ –°–æ–±—Ä–∞–Ω–æ {len(similar)} –ø–æ—Ö–æ–∂–∏—Ö –æ–±—ä—è–≤–ª–µ–Ω–∏–π")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ—Ö–æ–∂–∏—Ö: {e}")
        
        return similar

    def _get_full_data_for_similar(self, similar_list: List[Dict], max_full: int = 5) -> List[Dict]:
        """
        –ü–æ–ª—É—á–∞–µ–º –ü–û–õ–ù–´–ï –¥–∞–Ω–Ω—ã–µ (–≤—Å–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏) –¥–ª—è –ø–æ—Ö–æ–∂–∏—Ö –æ–±—ä—è–≤–ª–µ–Ω–∏–π
        """
        logger.info(f"üìä –ü–æ–ª—É—á–∞–µ–º –ø–æ–ª–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è {min(len(similar_list), max_full)} –ø–æ—Ö–æ–∂–∏—Ö...")
        
        full_similar = []
        
        for i, listing in enumerate(similar_list[:max_full]):
            if listing.get('url'):
                full_data = self._parse_full_listing(listing['url'])
                
                # –û–±—ä–µ–¥–∏–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ
                listing.update(full_data)
                full_similar.append(listing)
                
                time.sleep(1)  # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
        
        logger.info(f"‚úÖ –ü–æ–ª—É—á–µ–Ω—ã –ø–æ–ª–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è {len(full_similar)} –æ–±—ä—è–≤–ª–µ–Ω–∏–π")
        
        return full_similar

    def parse_detail_page_full(self, url: str, get_full_similar: bool = True) -> Dict:
        """
        –ü–æ–ª–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ —Å –ø–æ—Ö–æ–∂–∏–º–∏ –æ–±—ä—è–≤–ª–µ–Ω–∏—è–º–∏ —á–µ—Ä–µ–∑ breadcrumbs
        
        Args:
            url: URL –æ–±—ä—è–≤–ª–µ–Ω–∏—è
            get_full_similar: –ü–æ–ª—É—á–∞—Ç—å –ª–∏ –ø–æ–ª–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –ø–æ—Ö–æ–∂–∏—Ö (–º–µ–¥–ª–µ–Ω–Ω–µ–µ, –Ω–æ –±–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö)
        """
        result = {
            'url': url,
            'title': None,
            'price': None,
            'price_raw': None,
            'currency': 'RUB',
            'address': None,
            'metro': [],
            'characteristics': {},
            'images': [],
            'description': None,
            'similar_listings': [],
        }

        try:
            page = self.context.new_page()
            
            logger.info(f"üìÑ –ó–∞–≥—Ä—É–∑–∫–∞ –æ—Å–Ω–æ–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã: {url}")
            
            time.sleep(random.uniform(0.5, 1.0))
            page.goto(url, wait_until='domcontentloaded', timeout=60000)
            
            try:
                page.wait_for_selector('h1', timeout=10000)
            except:
                pass

            time.sleep(2)

            # === –û–°–ù–û–í–ù–´–ï –î–ê–ù–ù–´–ï ===
            
            # –ó–∞–≥–æ–ª–æ–≤–æ–∫
            try:
                h1 = page.locator('h1').first
                if h1:
                    result['title'] = h1.text_content().strip()
            except:
                pass

            # –¶–µ–Ω–∞
            try:
                price_elem = page.locator('[data-testid="price-amount"]').first
                if price_elem:
                    price_text = price_elem.text_content()
                    result['price'] = price_text.strip()
                    price_match = re.search(r'(\d+[\s\d]*)', price_text.replace(' ', ''))
                    if price_match:
                        result['price_raw'] = int(price_match.group(1).replace(' ', ''))
            except:
                pass

            # –ê–¥—Ä–µ—Å
            try:
                address_elem = page.locator('[data-name="Geo"]').first
                if address_elem:
                    result['address'] = address_elem.text_content().strip()
            except:
                pass

            # –ú–µ—Ç—Ä–æ
            try:
                metro_items = page.locator('[data-name="UndergroundLabel"]').all()
                for item in metro_items:
                    metro_text = item.text_content().strip()
                    if metro_text and metro_text not in result['metro']:
                        result['metro'].append(metro_text)
            except:
                pass

            # –û–ø–∏—Å–∞–Ω–∏–µ
            try:
                desc_elem = page.locator('[data-name="Description"]').first
                if desc_elem:
                    result['description'] = desc_elem.text_content().strip()
            except:
                pass

            # –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
            logger.info("üìä –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫...")
            result['characteristics'] = self._extract_characteristics(page)

            # –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            try:
                img_elements = page.locator('img[src*="cdn-cian.ru/images"]').all()
                images = []
                for img in img_elements[:30]:
                    src = img.get_attribute('src')
                    if src and src.startswith('http'):
                        images.append(src)
                result['images'] = list(dict.fromkeys(images))
            except:
                pass

            # === –ü–û–ò–°–ö –ü–û–•–û–ñ–ò–• –ß–ï–†–ï–ó BREADCRUMBS ===
            
            logger.info("üîç –ü–æ–∏—Å–∫ breadcrumb –¥–ª—è –ø–æ—Ö–æ–∂–∏—Ö –æ–±—ä—è–≤–ª–µ–Ω–∏–π...")
            breadcrumb_url = self._find_breadcrumb_link(page)
            
            page.close()
            
            if breadcrumb_url:
                # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –ø–æ—Ö–æ–∂–∏—Ö
                similar_basic = self._get_similar_from_search(breadcrumb_url, max_similar=10)

                if get_full_similar and similar_basic:
                    # –ü–æ–ª—É—á–∞–µ–º –ø–æ–ª–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –í–°–ï–• –ø–æ—Ö–æ–∂–∏—Ö –æ–±—ä—è–≤–ª–µ–Ω–∏–π
                    result['similar_listings'] = self._get_full_data_for_similar(similar_basic, max_full=len(similar_basic))
                else:
                    result['similar_listings'] = similar_basic
            
            logger.info(f"‚úÖ –ì–æ—Ç–æ–≤–æ: {len(result['characteristics'])} —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫, {len(result['similar_listings'])} –ø–æ—Ö–æ–∂–∏—Ö")

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞: {e}")
            result['error'] = str(e)

        return result


# Alias –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
CianParserWithSimilar = CianParserBreadcrumbs
