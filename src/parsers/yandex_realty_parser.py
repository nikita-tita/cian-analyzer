"""
–ü–∞—Ä—Å–µ—Ä –¥–ª—è Yandex Real Estate (realty.yandex.ru)

–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ –Ø–Ω–¥–µ–∫—Å –ù–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏:
- GraphQL API
- React SPA –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
- –°—Ä–µ–¥–Ω—è—è –∑–∞—â–∏—Ç–∞ (Yandex Cloud Shield)
- –•–æ—Ä–æ—à–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ

–°—Ç—Ä–∞—Ç–µ–≥–∏—è –ø–∞—Ä—Å–∏–Ω–≥–∞:
1. GraphQL API (—á–µ—Ä–µ–∑ httpx –∏–ª–∏ curl_cffi)
2. Playwright –¥–ª—è –ø–æ–∏—Å–∫–∞ –∏ –¥–µ—Ç–∞–ª—å–Ω—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü
3. Fallback –Ω–∞ HTML –ø–∞—Ä—Å–∏–Ω–≥
"""

import json
import logging
import re
import time
from typing import Optional, Dict, List, Literal
from bs4 import BeautifulSoup
from urllib.parse import urljoin, parse_qs, urlparse

from .base_real_estate_parser import BaseRealEstateParser, ParserCapabilities, ParsingError
from .field_mapper import get_field_mapper
from .parser_registry import register_parser

logger = logging.getLogger(__name__)

# –ò–º–ø–æ—Ä—Ç —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
try:
    from .strategies.httpx_strategy import HttpxStrategy
    HTTPX_AVAILABLE = True
except ImportError:
    HTTPX_AVAILABLE = False

try:
    from .strategies.curl_cffi_strategy import CurlCffiStrategy
    CURL_CFFI_AVAILABLE = True
except ImportError:
    CURL_CFFI_AVAILABLE = False

try:
    from .strategies.playwright_stealth_strategy import PlaywrightStealthStrategy
    PLAYWRIGHT_AVAILABLE = True
except ImportError:
    PLAYWRIGHT_AVAILABLE = False


@register_parser('yandex', [r'realty\.yandex\.ru', r'yandex\.ru/realty'])
class YandexRealtyParser(BaseRealEstateParser):
    """
    –ü–∞—Ä—Å–µ—Ä –¥–ª—è Yandex Realty —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π GraphQL API

    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç:
    - GraphQL API —á–µ—Ä–µ–∑ httpx (–±—ã—Å—Ç—Ä–æ, —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ)
    - Playwright –¥–ª—è fallback
    - HTML –ø–∞—Ä—Å–∏–Ω–≥ –¥–ª—è —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ –≤–∞—Ä–∏–∞–Ω—Ç–∞
    """

    def __init__(
        self,
        delay: float = 2.0,
        cache=None,
        region: str = 'spb',
        use_graphql: bool = True
    ):
        """
        Args:
            delay: –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
            cache: –û–±—ä–µ–∫—Ç –∫—ç—à–∞
            region: –†–µ–≥–∏–æ–Ω ('spb', 'msk')
            use_graphql: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å GraphQL API (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)
        """
        super().__init__(delay, cache)
        self.region = region
        self.use_graphql = use_graphql

        self.base_url = "https://realty.yandex.ru"
        self.graphql_url = "https://realty.yandex.ru/graphql"

        # –ú–∞–ø–ø–∏–Ω–≥ —Ä–µ–≥–∏–æ–Ω–æ–≤ –≤ region_id –Ø–Ω–¥–µ–∫—Å–∞
        self.region_codes = {
            'spb': '2',      # –°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥
            'msk': '1',      # –ú–æ—Å–∫–≤–∞
        }
        self.region_id = self.region_codes.get(region, '2')

        # –°—Ç—Ä–∞—Ç–µ–≥–∏–∏ (–ª–µ–Ω–∏–≤–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è)
        self.httpx: Optional[HttpxStrategy] = None
        self.curl_cffi: Optional[CurlCffiStrategy] = None
        self.playwright: Optional[PlaywrightStealthStrategy] = None

        # –ú–∞–ø–ø–µ—Ä –ø–æ–ª–µ–π
        self.field_mapper = get_field_mapper('yandex')

        logger.info(f"‚úì –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω YandexRealtyParser (—Ä–µ–≥–∏–æ–Ω: {region}, GraphQL: {use_graphql})")

    def _init_httpx(self):
        """–õ–µ–Ω–∏–≤–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è httpx"""
        if not HTTPX_AVAILABLE:
            logger.warning("httpx –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
            return

        if not self.httpx:
            self.httpx = HttpxStrategy(
                timeout=30,
                enable_http2=True
            )
            logger.info("‚úì httpx –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –¥–ª—è Yandex")

    def _init_curl_cffi(self):
        """–õ–µ–Ω–∏–≤–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è curl_cffi"""
        if not CURL_CFFI_AVAILABLE:
            logger.warning("curl_cffi –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
            return

        if not self.curl_cffi:
            self.curl_cffi = CurlCffiStrategy(
                impersonate='chrome110',
                timeout=30
            )
            logger.info("‚úì curl_cffi –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –¥–ª—è Yandex")

    def _init_playwright(self):
        """–õ–µ–Ω–∏–≤–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Playwright"""
        if not PLAYWRIGHT_AVAILABLE:
            logger.warning("Playwright –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
            return

        if not self.playwright:
            self.playwright = PlaywrightStealthStrategy(
                headless=True,
                stealth_mode=True,
                timeout=30000
            )
            logger.info("‚úì Playwright –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –¥–ª—è Yandex")

    # ===== –û–°–ù–û–í–ù–´–ï –ú–ï–¢–û–î–´ –ü–ê–†–°–ò–ù–ì–ê =====

    def _get_page_content(self, url: str) -> Optional[str]:
        """
        –ü–æ–ª—É—á–∏—Ç—å HTML –∫–æ–Ω—Ç–µ–Ω—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—ã

        Args:
            url: URL —Å—Ç—Ä–∞–Ω–∏—Ü—ã

        Returns:
            HTML –∫–æ–Ω—Ç–µ–Ω—Ç –∏–ª–∏ None
        """
        if self.use_graphql:
            # –ü—ã—Ç–∞–µ–º—Å—è —á–µ—Ä–µ–∑ GraphQL API
            offer_id = self._extract_offer_id(url)
            if offer_id:
                graphql_data = self._fetch_via_graphql(offer_id)
                if graphql_data:
                    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º JSON –∫–∞–∫ "HTML"
                    return json.dumps(graphql_data)

        # Fallback –Ω–∞ Playwright
        return self._get_via_playwright(url)

    def _fetch_via_graphql(self, offer_id: str) -> Optional[Dict]:
        """
        –ü–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ —á–µ—Ä–µ–∑ GraphQL API

        Args:
            offer_id: ID –æ–±—ä—è–≤–ª–µ–Ω–∏—è

        Returns:
            JSON –¥–∞–Ω–Ω—ã–µ –∏–ª–∏ None
        """
        # –ü—ã—Ç–∞–µ–º—Å—è —Å–Ω–∞—á–∞–ª–∞ —á–µ—Ä–µ–∑ httpx, –ø–æ—Ç–æ–º —á–µ—Ä–µ–∑ curl_cffi
        self._init_httpx()

        if self.httpx:
            result = self._execute_graphql_query(offer_id, self.httpx)
            if result:
                return result

        # Fallback –Ω–∞ curl_cffi
        self._init_curl_cffi()

        if self.curl_cffi:
            result = self._execute_graphql_query(offer_id, self.curl_cffi)
            if result:
                return result

        logger.warning("‚ö†Ô∏è GraphQL –∑–∞–ø—Ä–æ—Å—ã –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–∏")
        return None

    def _execute_graphql_query(self, offer_id: str, strategy) -> Optional[Dict]:
        """
        –í—ã–ø–æ–ª–Ω–∏—Ç—å GraphQL –∑–∞–ø—Ä–æ—Å —á–µ—Ä–µ–∑ –∑–∞–¥–∞–Ω–Ω—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é

        Args:
            offer_id: ID –æ–±—ä—è–≤–ª–µ–Ω–∏—è
            strategy: –°—Ç—Ä–∞—Ç–µ–≥–∏—è (httpx –∏–ª–∏ curl_cffi)

        Returns:
            JSON –¥–∞–Ω–Ω—ã–µ –∏–ª–∏ None
        """
        logger.info(f"üîÑ GraphQL –∑–∞–ø—Ä–æ—Å Yandex –¥–ª—è {offer_id}")

        # GraphQL query –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –æ–±—ä—è–≤–ª–µ–Ω–∏—è
        # –≠—Ç–æ —É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è, —Ä–µ–∞–ª—å–Ω—ã–π query –º–æ–∂–µ—Ç –æ—Ç–ª–∏—á–∞—Ç—å—Å—è
        query = """
        query GetOffer($offerId: ID!) {
            offer(id: $offerId) {
                id
                title
                description
                price {
                    value
                    currency
                }
                area {
                    value
                    unit
                }
                rooms
                floor
                floorsTotal
                address {
                    fullAddress
                }
                location {
                    latitude
                    longitude
                }
                images {
                    url
                }
                characteristics {
                    key
                    value
                }
            }
        }
        """

        variables = {
            "offerId": offer_id
        }

        payload = {
            "query": query,
            "variables": variables
        }

        headers = {
            'Content-Type': 'application/json',
            'Accept': 'application/json',
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
            'Referer': f'https://realty.yandex.ru/offer/{offer_id}',
        }

        try:
            data = strategy.fetch_api(
                self.graphql_url,
                method='POST',
                json=payload,
                headers=headers
            )

            if data and 'data' in data:
                logger.info(f"‚úì GraphQL Yandex —É—Å–ø–µ—à–Ω–æ: {offer_id}")
                return data.get('data', {}).get('offer')
            else:
                logger.warning(f"‚ö†Ô∏è GraphQL –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç—ã–µ –¥–∞–Ω–Ω—ã–µ")
                return None

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ GraphQL Yandex: {e}")
            return None

    def _get_via_playwright(self, url: str) -> Optional[str]:
        """
        –ü–æ–ª—É—á–∏—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—É —á–µ—Ä–µ–∑ Playwright

        Args:
            url: URL —Å—Ç—Ä–∞–Ω–∏—Ü—ã

        Returns:
            HTML –∫–æ–Ω—Ç–µ–Ω—Ç –∏–ª–∏ None
        """
        self._init_playwright()

        if not self.playwright:
            logger.error("Playwright –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –¥–ª—è Yandex")
            return None

        try:
            logger.info(f"üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ —á–µ—Ä–µ–∑ Playwright: {url}")

            html = self.playwright.fetch_content(
                url,
                wait_for_selector='[class*="CardContainer"]',
                additional_wait=1000  # ms
            )

            return html

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ Playwright: {e}")
            return None

    def _parse_single_property(self, url: str, html: str) -> Dict:
        """
        –ü–∞—Ä—Å–∏–Ω–≥ –æ–¥–Ω–æ–≥–æ –æ–±—ä—è–≤–ª–µ–Ω–∏—è

        Args:
            url: URL –æ–±—ä—è–≤–ª–µ–Ω–∏—è
            html: HTML –∫–æ–Ω—Ç–µ–Ω—Ç (–∏–ª–∏ JSON —Å—Ç—Ä–æ–∫–∞ –æ—Ç GraphQL)

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –¥–∞–Ω–Ω—ã–º–∏ (–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç)
        """
        data = {'url': url, 'source': 'yandex'}

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —ç—Ç–æ JSON –æ—Ç GraphQL –∏–ª–∏ HTML
        if html and html.strip().startswith('{'):
            # –≠—Ç–æ JSON –æ—Ç GraphQL
            try:
                json_data = json.loads(html)
                logger.info("üìä –ü–∞—Ä—Å–∏–º –¥–∞–Ω–Ω—ã–µ GraphQL Yandex")
                data.update(self._parse_from_graphql(json_data))
                return data
            except json.JSONDecodeError:
                logger.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON, –ø—Ä–æ–±—É–µ–º –∫–∞–∫ HTML")

        # –û–±—ã—á–Ω—ã–π HTML –ø–∞—Ä—Å–∏–Ω–≥
        soup = BeautifulSoup(html, 'lxml')

        # –ü—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å –∏–∑ window.__INITIAL_STATE__
        initial_state = self._extract_initial_state(html)
        if initial_state:
            data.update(self._parse_from_initial_state(initial_state))

        # JSON-LD
        json_ld = self._extract_json_ld(soup)
        if json_ld:
            data.update(self._parse_from_json_ld(json_ld))

        # Fallback HTML –ø–∞—Ä—Å–∏–Ω–≥
        if not data.get('title'):
            data.update(self._parse_from_html(soup))

        return data

    def _extract_offer_id(self, url: str) -> Optional[str]:
        """
        –ò–∑–≤–ª–µ—á—å ID –æ–±—ä—è–≤–ª–µ–Ω–∏—è –∏–∑ URL

        Args:
            url: URL –æ–±—ä—è–≤–ª–µ–Ω–∏—è

        Returns:
            ID –∏–ª–∏ None
        """
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã URL Yandex:
        # https://realty.yandex.ru/offer/1234567890/
        # https://realty.yandex.ru/offer/1234567890

        patterns = [
            r'/offer/(\d+)',
        ]

        for pattern in patterns:
            match = re.search(pattern, url)
            if match:
                return match.group(1)

        logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å ID –∏–∑ URL: {url}")
        return None

    def _parse_from_graphql(self, graphql_data: Dict) -> Dict:
        """
        –ü–∞—Ä—Å–∏–Ω–≥ –¥–∞–Ω–Ω—ã—Ö GraphQL

        Args:
            graphql_data: JSON –¥–∞–Ω–Ω—ã–µ –∏–∑ GraphQL

        Returns:
            –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        """
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–∞–ø–ø–µ—Ä –ø–æ–ª–µ–π
        return self.field_mapper.transform(graphql_data)

    def _extract_initial_state(self, html: str) -> Optional[Dict]:
        """
        –ò–∑–≤–ª–µ—á—å –¥–∞–Ω–Ω—ã–µ –∏–∑ window.__INITIAL_STATE__

        Args:
            html: HTML –∫–æ–Ω—Ç–µ–Ω—Ç

        Returns:
            –î–∞–Ω–Ω—ã–µ –∏–ª–∏ None
        """
        patterns = [
            r'window\.__INITIAL_STATE__\s*=\s*(\{.+?\});',
            r'window\.INITIAL_STATE\s*=\s*(\{.+?\});',
        ]

        for pattern in patterns:
            try:
                match = re.search(pattern, html, re.DOTALL)
                if match:
                    data = json.loads(match.group(1))
                    logger.info("‚úì –ò–∑–≤–ª–µ—á–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ –∏–∑ __INITIAL_STATE__")
                    return data
            except Exception as e:
                logger.debug(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è __INITIAL_STATE__: {e}")

        return None

    def _parse_from_initial_state(self, state: Dict) -> Dict:
        """–ü–∞—Ä—Å–∏–Ω–≥ –∏–∑ __INITIAL_STATE__"""
        result = {}

        # –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö Yandex: state.offer –∏–ª–∏ state.card
        offer = state.get('offer') or state.get('card')

        if offer:
            result.update(self.field_mapper.transform(offer))

        return result

    def _extract_json_ld(self, soup: BeautifulSoup) -> Optional[Dict]:
        """–ò–∑–≤–ª–µ—á—å JSON-LD"""
        try:
            json_ld_script = soup.find('script', type='application/ld+json')
            if json_ld_script and json_ld_script.string:
                return json.loads(json_ld_script.string)
        except Exception as e:
            logger.debug(f"JSON-LD –Ω–µ –Ω–∞–π–¥–µ–Ω: {e}")
        return None

    def _parse_from_json_ld(self, json_ld: Dict) -> Dict:
        """–ü–∞—Ä—Å–∏–Ω–≥ –∏–∑ JSON-LD"""
        data = {}

        if json_ld.get('@type') in ['Product', 'RealEstateListing', 'Apartment']:
            data['title'] = json_ld.get('name')
            data['description'] = json_ld.get('description')

            if 'offers' in json_ld:
                offers = json_ld['offers']
                if isinstance(offers, dict):
                    data['price'] = offers.get('price')
                    data['currency'] = offers.get('priceCurrency', 'RUB')

        return data

    def _parse_from_html(self, soup: BeautifulSoup) -> Dict:
        """Fallback HTML –ø–∞—Ä—Å–∏–Ω–≥"""
        data = {}

        # –ó–∞–≥–æ–ª–æ–≤–æ–∫
        h1 = soup.find('h1')
        if h1:
            data['title'] = h1.get_text(strip=True)

        # –¶–µ–Ω–∞
        price_elem = soup.find('[class*="Price"]')
        if price_elem:
            price_text = price_elem.get_text(strip=True)
            data['price'] = self._extract_number(price_text)

        # –û–ø–∏—Å–∞–Ω–∏–µ
        desc_elem = soup.find('[class*="Description"]')
        if desc_elem:
            data['description'] = desc_elem.get_text(strip=True)

        return data

    def _extract_number(self, text: str) -> Optional[float]:
        """–ò–∑–≤–ª–µ—á—å —á–∏—Å–ª–æ –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
        if not text:
            return None
        cleaned = re.sub(r'[^\d.]', '', text)
        try:
            return float(cleaned)
        except ValueError:
            return None

    # ===== –ü–û–ò–°–ö –ê–ù–ê–õ–û–ì–û–í =====

    def _search_similar_impl(
        self,
        target_property: Dict,
        limit: int = 20,
        strategy: Literal['same_building', 'same_area', 'citywide'] = 'citywide'
    ) -> List[Dict]:
        """
        –ü–æ–∏—Å–∫ –∞–Ω–∞–ª–æ–≥–æ–≤ –Ω–∞ Yandex

        Args:
            target_property: –¶–µ–ª–µ–≤–æ–π –æ–±—ä–µ–∫—Ç
            limit: –õ–∏–º–∏—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            strategy: –°—Ç—Ä–∞—Ç–µ–≥–∏—è –ø–æ–∏—Å–∫–∞

        Returns:
            –°–ø–∏—Å–æ–∫ –∞–Ω–∞–ª–æ–≥–æ–≤
        """
        logger.info(f"üîç –ü–æ–∏—Å–∫ –∞–Ω–∞–ª–æ–≥–æ–≤ –Ω–∞ –Ø–Ω–¥–µ–∫—Å (—Å—Ç—Ä–∞—Ç–µ–≥–∏—è: {strategy})")

        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–∏—Å–∫–∞
        search_params = self._build_search_params(target_property, strategy)

        # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫
        try:
            results = self._search_via_url(search_params, limit)
            logger.info(f"‚úì –ù–∞–π–¥–µ–Ω–æ {len(results)} –∞–Ω–∞–ª–æ–≥–æ–≤ –Ω–∞ –Ø–Ω–¥–µ–∫—Å")
            return results
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –Ω–∞ –Ø–Ω–¥–µ–∫—Å: {e}")
            return []

    def _build_search_params(self, target: Dict, strategy: str) -> Dict:
        """
        –ü–æ—Å—Ç—Ä–æ–∏—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–∏—Å–∫–∞ –¥–ª—è URL –Ø–Ω–¥–µ–∫—Å.–ù–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏

        Args:
            target: –¶–µ–ª–µ–≤–æ–π –æ–±—ä–µ–∫—Ç
            strategy: –°—Ç—Ä–∞—Ç–µ–≥–∏—è –ø–æ–∏—Å–∫–∞

        Returns:
            –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è URL
        """
        params = {
            'type': 'SELL',
            'category': 'APARTMENT',
            'region': self.region_id,
        }

        # –ë–∞–∑–æ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        price = target.get('price')
        area = target.get('total_area')
        rooms = target.get('rooms')

        if price:
            # ¬±30% –æ—Ç —Ü–µ–Ω—ã
            price_min = int(price * 0.7)
            price_max = int(price * 1.3)
            params['priceMin'] = price_min
            params['priceMax'] = price_max

        if area:
            # ¬±20% –æ—Ç –ø–ª–æ—â–∞–¥–∏
            area_min = int(area * 0.8)
            area_max = int(area * 1.2)
            params['areaMin'] = area_min
            params['areaMax'] = area_max

        if rooms and rooms != '—Å—Ç—É–¥–∏—è':
            # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–º–Ω–∞—Ç
            params['roomsTotal'] = rooms
        elif rooms == '—Å—Ç—É–¥–∏—è':
            params['roomsTotal'] = 'STUDIO'

        # –°—Ç—Ä–∞—Ç–µ–≥–∏—è –ø–æ–∏—Å–∫–∞
        if strategy == 'same_building':
            # –Ø–Ω–¥–µ–∫—Å –º–æ–∂–µ—Ç –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—Ç—å –ø–æ–∏—Å–∫ –ø–æ –ñ–ö —á–µ—Ä–µ–∑ ID
            # –ù–æ –¥–ª—è —É–ø—Ä–æ—â–µ–Ω–∏—è –∏—Å–ø–æ–ª—å–∑—É–µ–º –∞–¥—Ä–µ—Å
            address = target.get('address', '')
            if address:
                parts = [p.strip() for p in address.split(',')]
                if len(parts) >= 2:
                    params['address'] = parts[1]  # –†–∞–π–æ–Ω –∏–ª–∏ —É–ª–∏—Ü–∞

        return params

    def _search_via_url(self, params: Dict, limit: int) -> List[Dict]:
        """
        –í—ã–ø–æ–ª–Ω–∏—Ç—å –ø–æ–∏—Å–∫ —á–µ—Ä–µ–∑ URL —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏

        Args:
            params: –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–∏—Å–∫–∞
            limit: –õ–∏–º–∏—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

        Returns:
            –°–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        """
        # –§–æ—Ä–º–∏—Ä—É–µ–º URL –ø–æ–∏—Å–∫–∞
        region_name = 'sankt-peterburg' if self.region == 'spb' else 'moskva'
        base_search_url = f"https://realty.yandex.ru/{region_name}/kupit/kvartira/"

        # –î–æ–±–∞–≤–ª—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        if params:
            param_str = '&'.join([f"{k}={v}" for k, v in params.items()])
            search_url = f"{base_search_url}?{param_str}"
        else:
            search_url = base_search_url

        logger.info(f"üîç –ü–æ–∏—Å–∫ –Ø–Ω–¥–µ–∫—Å: {search_url}")

        # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—É –ø–æ–∏—Å–∫–∞
        html = self._get_search_page(search_url)

        if not html:
            logger.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—É –ø–æ–∏—Å–∫–∞ –Ø–Ω–¥–µ–∫—Å")
            return []

        # –ü–∞—Ä—Å–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞
        results = self._parse_search_results(html, limit)

        return results

    def _get_search_page(self, url: str) -> Optional[str]:
        """
        –ü–æ–ª—É—á–∏—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—É –ø–æ–∏—Å–∫–∞

        Args:
            url: URL —Å—Ç—Ä–∞–Ω–∏—Ü—ã –ø–æ–∏—Å–∫–∞

        Returns:
            HTML –∏–ª–∏ None
        """
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º Playwright
        return self._get_via_playwright(url)

    def _parse_search_results(self, html: str, limit: int) -> List[Dict]:
        """
        –ü–∞—Ä—Å–∏–Ω–≥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞ –∏–∑ HTML

        Args:
            html: HTML —Å—Ç—Ä–∞–Ω–∏—Ü—ã –ø–æ–∏—Å–∫–∞
            limit: –õ–∏–º–∏—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

        Returns:
            –°–ø–∏—Å–æ–∫ –æ–±—ä—è–≤–ª–µ–Ω–∏–π
        """
        from bs4 import BeautifulSoup

        soup = BeautifulSoup(html, 'lxml')
        results = []

        # –ò—â–µ–º –∫–∞—Ä—Ç–æ—á–∫–∏ –æ–±—ä—è–≤–ª–µ–Ω–∏–π
        # –Ø–Ω–¥–µ–∫—Å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –∫–ª–∞—Å—Å—ã
        cards = soup.find_all('div', class_=re.compile(r'OffersSerp__list|SeriesCard|OffersSerpItem', re.I))

        if not cards:
            # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫
            cards = soup.find_all('article') or soup.find_all('div', attrs={'data-testid': re.compile(r'offer', re.I)})

        logger.debug(f"–ù–∞–π–¥–µ–Ω–æ {len(cards)} –∫–∞—Ä—Ç–æ—á–µ–∫ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ –ø–æ–∏—Å–∫–∞")

        for card in cards[:limit]:
            try:
                item = self._parse_search_card(card)
                if item:
                    results.append(item)
            except Exception as e:
                logger.debug(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –∫–∞—Ä—Ç–æ—á–∫–∏: {e}")
                continue

        return results

    def _parse_search_card(self, card) -> Optional[Dict]:
        """
        –ü–∞—Ä—Å–∏–Ω–≥ –æ–¥–Ω–æ–π –∫–∞—Ä—Ç–æ—á–∫–∏ –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞

        Args:
            card: BeautifulSoup —ç–ª–µ–º–µ–Ω—Ç –∫–∞—Ä—Ç–æ—á–∫–∏

        Returns:
            –î–∞–Ω–Ω—ã–µ –æ–±—ä—è–≤–ª–µ–Ω–∏—è –∏–ª–∏ None
        """
        data = {'source': 'yandex'}

        # URL
        link = card.find('a', href=re.compile(r'/offer/'))

        if link and link.get('href'):
            url = link['href']
            if not url.startswith('http'):
                url = f"https://realty.yandex.ru{url}"
            data['url'] = url
        else:
            return None

        # –ó–∞–≥–æ–ª–æ–≤–æ–∫
        title_elem = card.find('h3') or card.find('h2') or card.find('a', href=re.compile(r'/offer/'))

        if title_elem:
            data['title'] = title_elem.get_text(strip=True)

        # –¶–µ–Ω–∞
        price_elem = card.find('span', class_=re.compile(r'price', re.I))

        if price_elem:
            price_text = price_elem.get_text(strip=True)
            data['price'] = self._extract_number(price_text)

        # –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ (–ø–ª–æ—â–∞–¥—å, –∫–æ–º–Ω–∞—Ç—ã –∏ —Ç.–¥.)
        # –Ø–Ω–¥–µ–∫—Å –≥—Ä—É–ø–ø–∏—Ä—É–µ—Ç —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –≤ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–∞—Ö
        params_container = card.find('div', class_=re.compile(r'param|info|characteristics', re.I))

        if params_container:
            params_text = params_container.get_text(strip=True)

            # –ü–ª–æ—â–∞–¥—å
            area_match = re.search(r'(\d+(?:[.,]\d+)?)\s*–º', params_text)
            if area_match:
                data['total_area'] = float(area_match.group(1).replace(',', '.'))

            # –ö–æ–º–Ω–∞—Ç—ã
            if '—Å—Ç—É–¥–∏—è' in params_text.lower():
                data['rooms'] = '—Å—Ç—É–¥–∏—è'
            else:
                rooms_match = re.search(r'(\d+)[- ]?–∫–æ–º–Ω', params_text)
                if rooms_match:
                    data['rooms'] = int(rooms_match.group(1))

            # –≠—Ç–∞–∂
            floor_match = re.search(r'(\d+)/(\d+)\s*—ç—Ç', params_text)
            if floor_match:
                data['floor'] = int(floor_match.group(1))
                data['floor_total'] = int(floor_match.group(2))

        # –ê–¥—Ä–µ—Å
        address_elem = card.find('div', class_=re.compile(r'address|geo|location', re.I))

        if address_elem:
            data['address'] = address_elem.get_text(strip=True)

        # –í—ã—á–∏—Å–ª—è–µ–º —Ü–µ–Ω—É –∑–∞ –º¬≤
        if data.get('price') and data.get('total_area'):
            data['price_per_sqm'] = round(data['price'] / data['total_area'], 2)

        return data

    # ===== –í–û–ó–ú–û–ñ–ù–û–°–¢–ò =====

    def get_capabilities(self) -> ParserCapabilities:
        """–í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –ø–∞—Ä—Å–µ—Ä–∞"""
        return ParserCapabilities(
            supports_search=True,  # ‚úÖ –†–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ —á–µ—Ä–µ–∑ HTML –ø–∞—Ä—Å–∏–Ω–≥
            supports_residential_complex=False,  # –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞ —á–µ—Ä–µ–∑ –∞–¥—Ä–µ—Å
            supports_regions=['msk', 'spb'],
            supports_async=True,  # httpx async
            has_api=True,  # GraphQL
            requires_browser=True  # Playwright –¥–ª—è –ø–æ–∏—Å–∫–∞
        )

    def get_source_name(self) -> str:
        """–ù–∞–∑–≤–∞–Ω–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∞"""
        return 'yandex'
