"""
–ü–∞—Ä—Å–µ—Ä –¥–ª—è Yandex Real Estate (realty.yandex.ru)

–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ –Ø–Ω–¥–µ–∫—Å –ù–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏:
- GraphQL API
- React SPA –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
- –°—Ä–µ–¥–Ω—è—è –∑–∞—â–∏—Ç–∞ (Yandex Cloud Shield)
- –•–æ—Ä–æ—à–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ

–°—Ç—Ä–∞—Ç–µ–≥–∏—è –ø–∞—Ä—Å–∏–Ω–≥–∞:
1. GraphQL API (—á–µ—Ä–µ–∑ httpx –∏–ª–∏ curl_cffi)
2. Playwright –¥–ª—è –ø–æ–∏—Å–∫–∞ –∏ –¥–µ—Ç–∞–ª—å–Ω—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü
3. Fallback –Ω–∞ HTML –ø–∞—Ä—Å–∏–Ω–≥
"""

import json
import logging
import re
import time
from typing import Optional, Dict, List, Literal
from bs4 import BeautifulSoup
from urllib.parse import urljoin, parse_qs, urlparse

from .base_real_estate_parser import BaseRealEstateParser, ParserCapabilities, ParsingError
from .field_mapper import get_field_mapper
from .parser_registry import register_parser

logger = logging.getLogger(__name__)

# –ò–º–ø–æ—Ä—Ç —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
try:
    from .strategies.httpx_strategy import HttpxStrategy
    HTTPX_AVAILABLE = True
except ImportError:
    HTTPX_AVAILABLE = False

try:
    from .strategies.curl_cffi_strategy import CurlCffiStrategy
    CURL_CFFI_AVAILABLE = True
except ImportError:
    CURL_CFFI_AVAILABLE = False

try:
    from .strategies.playwright_stealth_strategy import PlaywrightStealthStrategy
    PLAYWRIGHT_AVAILABLE = True
except ImportError:
    PLAYWRIGHT_AVAILABLE = False


@register_parser('yandex', [r'realty\.yandex\.ru', r'yandex\.ru/realty'])
class YandexRealtyParser(BaseRealEstateParser):
    """
    –ü–∞—Ä—Å–µ—Ä –¥–ª—è Yandex Realty —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π GraphQL API

    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç:
    - GraphQL API —á–µ—Ä–µ–∑ httpx (–±—ã—Å—Ç—Ä–æ, —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ)
    - Playwright –¥–ª—è fallback
    - HTML –ø–∞—Ä—Å–∏–Ω–≥ –¥–ª—è —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ –≤–∞—Ä–∏–∞–Ω—Ç–∞
    """

    def __init__(
        self,
        delay: float = 2.0,
        cache=None,
        region: str = 'spb',
        use_graphql: bool = True
    ):
        """
        Args:
            delay: –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
            cache: –û–±—ä–µ–∫—Ç –∫—ç—à–∞
            region: –†–µ–≥–∏–æ–Ω ('spb', 'msk')
            use_graphql: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å GraphQL API (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)
        """
        super().__init__(delay, cache)
        self.region = region
        self.use_graphql = use_graphql

        self.base_url = "https://realty.yandex.ru"
        self.graphql_url = "https://realty.yandex.ru/graphql"

        # –ú–∞–ø–ø–∏–Ω–≥ —Ä–µ–≥–∏–æ–Ω–æ–≤ –≤ region_id –Ø–Ω–¥–µ–∫—Å–∞
        self.region_codes = {
            'spb': '2',      # –°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥
            'msk': '1',      # –ú–æ—Å–∫–≤–∞
        }
        self.region_id = self.region_codes.get(region, '2')

        # –°—Ç—Ä–∞—Ç–µ–≥–∏–∏ (–ª–µ–Ω–∏–≤–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è)
        self.httpx: Optional[HttpxStrategy] = None
        self.curl_cffi: Optional[CurlCffiStrategy] = None
        self.playwright: Optional[PlaywrightStealthStrategy] = None

        # –ú–∞–ø–ø–µ—Ä –ø–æ–ª–µ–π
        self.field_mapper = get_field_mapper('yandex')

        logger.info(f"‚úì –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω YandexRealtyParser (—Ä–µ–≥–∏–æ–Ω: {region}, GraphQL: {use_graphql})")

    def _init_httpx(self):
        """–õ–µ–Ω–∏–≤–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è httpx"""
        if not HTTPX_AVAILABLE:
            logger.warning("httpx –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
            return

        if not self.httpx:
            self.httpx = HttpxStrategy(
                timeout=30,
                enable_http2=True
            )
            logger.info("‚úì httpx –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –¥–ª—è Yandex")

    def _init_curl_cffi(self):
        """–õ–µ–Ω–∏–≤–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è curl_cffi"""
        if not CURL_CFFI_AVAILABLE:
            logger.warning("curl_cffi –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
            return

        if not self.curl_cffi:
            self.curl_cffi = CurlCffiStrategy(
                impersonate='chrome110',
                timeout=30
            )
            logger.info("‚úì curl_cffi –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –¥–ª—è Yandex")

    def _init_playwright(self):
        """–õ–µ–Ω–∏–≤–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Playwright"""
        if not PLAYWRIGHT_AVAILABLE:
            logger.warning("Playwright –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
            return

        if not self.playwright:
            self.playwright = PlaywrightStealthStrategy(
                headless=True,
                stealth_mode=True,
                timeout=30000
            )
            logger.info("‚úì Playwright –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –¥–ª—è Yandex")

    # ===== –û–°–ù–û–í–ù–´–ï –ú–ï–¢–û–î–´ –ü–ê–†–°–ò–ù–ì–ê =====

    def _get_page_content(self, url: str) -> Optional[str]:
        """
        –ü–æ–ª—É—á–∏—Ç—å HTML –∫–æ–Ω—Ç–µ–Ω—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—ã

        Args:
            url: URL —Å—Ç—Ä–∞–Ω–∏—Ü—ã

        Returns:
            HTML –∫–æ–Ω—Ç–µ–Ω—Ç –∏–ª–∏ None
        """
        if self.use_graphql:
            # –ü—ã—Ç–∞–µ–º—Å—è —á–µ—Ä–µ–∑ GraphQL API
            offer_id = self._extract_offer_id(url)
            if offer_id:
                graphql_data = self._fetch_via_graphql(offer_id)
                if graphql_data:
                    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º JSON –∫–∞–∫ "HTML"
                    return json.dumps(graphql_data)

        # Fallback –Ω–∞ Playwright
        return self._get_via_playwright(url)

    def _fetch_via_graphql(self, offer_id: str) -> Optional[Dict]:
        """
        –ü–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ —á–µ—Ä–µ–∑ GraphQL API

        Args:
            offer_id: ID –æ–±—ä—è–≤–ª–µ–Ω–∏—è

        Returns:
            JSON –¥–∞–Ω–Ω—ã–µ –∏–ª–∏ None
        """
        # –ü—ã—Ç–∞–µ–º—Å—è —Å–Ω–∞—á–∞–ª–∞ —á–µ—Ä–µ–∑ httpx, –ø–æ—Ç–æ–º —á–µ—Ä–µ–∑ curl_cffi
        self._init_httpx()

        if self.httpx:
            result = self._execute_graphql_query(offer_id, self.httpx)
            if result:
                return result

        # Fallback –Ω–∞ curl_cffi
        self._init_curl_cffi()

        if self.curl_cffi:
            result = self._execute_graphql_query(offer_id, self.curl_cffi)
            if result:
                return result

        logger.warning("‚ö†Ô∏è GraphQL –∑–∞–ø—Ä–æ—Å—ã –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–∏")
        return None

    def _execute_graphql_query(self, offer_id: str, strategy) -> Optional[Dict]:
        """
        –í—ã–ø–æ–ª–Ω–∏—Ç—å GraphQL –∑–∞–ø—Ä–æ—Å —á–µ—Ä–µ–∑ –∑–∞–¥–∞–Ω–Ω—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é

        Args:
            offer_id: ID –æ–±—ä—è–≤–ª–µ–Ω–∏—è
            strategy: –°—Ç—Ä–∞—Ç–µ–≥–∏—è (httpx –∏–ª–∏ curl_cffi)

        Returns:
            JSON –¥–∞–Ω–Ω—ã–µ –∏–ª–∏ None
        """
        logger.info(f"üîÑ GraphQL –∑–∞–ø—Ä–æ—Å Yandex –¥–ª—è {offer_id}")

        # GraphQL query –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –æ–±—ä—è–≤–ª–µ–Ω–∏—è
        # –≠—Ç–æ —É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è, —Ä–µ–∞–ª—å–Ω—ã–π query –º–æ–∂–µ—Ç –æ—Ç–ª–∏—á–∞—Ç—å—Å—è
        query = """
        query GetOffer($offerId: ID!) {
            offer(id: $offerId) {
                id
                title
                description
                price {
                    value
                    currency
                }
                area {
                    value
                    unit
                }
                rooms
                floor
                floorsTotal
                address {
                    fullAddress
                }
                location {
                    latitude
                    longitude
                }
                images {
                    url
                }
                characteristics {
                    key
                    value
                }
            }
        }
        """

        variables = {
            "offerId": offer_id
        }

        payload = {
            "query": query,
            "variables": variables
        }

        headers = {
            'Content-Type': 'application/json',
            'Accept': 'application/json',
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
            'Referer': f'https://realty.yandex.ru/offer/{offer_id}',
        }

        try:
            data = strategy.fetch_api(
                self.graphql_url,
                method='POST',
                json=payload,
                headers=headers
            )

            if data and 'data' in data:
                logger.info(f"‚úì GraphQL Yandex —É—Å–ø–µ—à–Ω–æ: {offer_id}")
                return data.get('data', {}).get('offer')
            else:
                logger.warning(f"‚ö†Ô∏è GraphQL –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç—ã–µ –¥–∞–Ω–Ω—ã–µ")
                return None

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ GraphQL Yandex: {e}")
            return None

    def _get_via_playwright(self, url: str) -> Optional[str]:
        """
        –ü–æ–ª—É—á–∏—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—É —á–µ—Ä–µ–∑ Playwright

        Args:
            url: URL —Å—Ç—Ä–∞–Ω–∏—Ü—ã

        Returns:
            HTML –∫–æ–Ω—Ç–µ–Ω—Ç –∏–ª–∏ None
        """
        self._init_playwright()

        if not self.playwright:
            logger.error("Playwright –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –¥–ª—è Yandex")
            return None

        try:
            logger.info(f"üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ —á–µ—Ä–µ–∑ Playwright: {url}")

            html = self.playwright.fetch_content(
                url,
                wait_for_selector='[class*="CardContainer"]',
                additional_wait=1000  # ms
            )

            return html

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ Playwright: {e}")
            return None

    def _parse_single_property(self, url: str, html: str) -> Dict:
        """
        –ü–∞—Ä—Å–∏–Ω–≥ –æ–¥–Ω–æ–≥–æ –æ–±—ä—è–≤–ª–µ–Ω–∏—è

        Args:
            url: URL –æ–±—ä—è–≤–ª–µ–Ω–∏—è
            html: HTML –∫–æ–Ω—Ç–µ–Ω—Ç (–∏–ª–∏ JSON —Å—Ç—Ä–æ–∫–∞ –æ—Ç GraphQL)

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –¥–∞–Ω–Ω—ã–º–∏ (–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç)
        """
        data = {'url': url, 'source': 'yandex'}

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —ç—Ç–æ JSON –æ—Ç GraphQL –∏–ª–∏ HTML
        if html and html.strip().startswith('{'):
            # –≠—Ç–æ JSON –æ—Ç GraphQL
            try:
                json_data = json.loads(html)
                logger.info("üìä –ü–∞—Ä—Å–∏–º –¥–∞–Ω–Ω—ã–µ GraphQL Yandex")
                data.update(self._parse_from_graphql(json_data))
                return data
            except json.JSONDecodeError:
                logger.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON, –ø—Ä–æ–±—É–µ–º –∫–∞–∫ HTML")

        # –û–±—ã—á–Ω—ã–π HTML –ø–∞—Ä—Å–∏–Ω–≥
        soup = BeautifulSoup(html, 'lxml')

        # –ü—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å –∏–∑ window.__INITIAL_STATE__
        initial_state = self._extract_initial_state(html)
        if initial_state:
            data.update(self._parse_from_initial_state(initial_state))

        # JSON-LD
        json_ld = self._extract_json_ld(soup)
        if json_ld:
            data.update(self._parse_from_json_ld(json_ld))

        # Fallback HTML –ø–∞—Ä—Å–∏–Ω–≥
        if not data.get('title'):
            data.update(self._parse_from_html(soup))

        return data

    def _extract_offer_id(self, url: str) -> Optional[str]:
        """
        –ò–∑–≤–ª–µ—á—å ID –æ–±—ä—è–≤–ª–µ–Ω–∏—è –∏–∑ URL

        Args:
            url: URL –æ–±—ä—è–≤–ª–µ–Ω–∏—è

        Returns:
            ID –∏–ª–∏ None
        """
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã URL Yandex:
        # https://realty.yandex.ru/offer/1234567890/
        # https://realty.yandex.ru/offer/1234567890

        patterns = [
            r'/offer/(\d+)',
        ]

        for pattern in patterns:
            match = re.search(pattern, url)
            if match:
                return match.group(1)

        logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å ID –∏–∑ URL: {url}")
        return None

    def _parse_from_graphql(self, graphql_data: Dict) -> Dict:
        """
        –ü–∞—Ä—Å–∏–Ω–≥ –¥–∞–Ω–Ω—ã—Ö GraphQL

        Args:
            graphql_data: JSON –¥–∞–Ω–Ω—ã–µ –∏–∑ GraphQL

        Returns:
            –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        """
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–∞–ø–ø–µ—Ä –ø–æ–ª–µ–π
        return self.field_mapper.transform(graphql_data)

    def _extract_initial_state(self, html: str) -> Optional[Dict]:
        """
        –ò–∑–≤–ª–µ—á—å –¥–∞–Ω–Ω—ã–µ –∏–∑ window.__INITIAL_STATE__

        Args:
            html: HTML –∫–æ–Ω—Ç–µ–Ω—Ç

        Returns:
            –î–∞–Ω–Ω—ã–µ –∏–ª–∏ None
        """
        patterns = [
            r'window\.__INITIAL_STATE__\s*=\s*(\{.+?\});',
            r'window\.INITIAL_STATE\s*=\s*(\{.+?\});',
        ]

        for pattern in patterns:
            try:
                match = re.search(pattern, html, re.DOTALL)
                if match:
                    data = json.loads(match.group(1))
                    logger.info("‚úì –ò–∑–≤–ª–µ—á–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ –∏–∑ __INITIAL_STATE__")
                    return data
            except Exception as e:
                logger.debug(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è __INITIAL_STATE__: {e}")

        return None

    def _parse_from_initial_state(self, state: Dict) -> Dict:
        """–ü–∞—Ä—Å–∏–Ω–≥ –∏–∑ __INITIAL_STATE__"""
        result = {}

        # –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö Yandex: state.offer –∏–ª–∏ state.card
        offer = state.get('offer') or state.get('card')

        if offer:
            result.update(self.field_mapper.transform(offer))

        return result

    def _extract_json_ld(self, soup: BeautifulSoup) -> Optional[Dict]:
        """–ò–∑–≤–ª–µ—á—å JSON-LD"""
        try:
            json_ld_script = soup.find('script', type='application/ld+json')
            if json_ld_script and json_ld_script.string:
                return json.loads(json_ld_script.string)
        except Exception as e:
            logger.debug(f"JSON-LD –Ω–µ –Ω–∞–π–¥–µ–Ω: {e}")
        return None

    def _parse_from_json_ld(self, json_ld: Dict) -> Dict:
        """–ü–∞—Ä—Å–∏–Ω–≥ –∏–∑ JSON-LD"""
        data = {}

        if json_ld.get('@type') in ['Product', 'RealEstateListing', 'Apartment']:
            data['title'] = json_ld.get('name')
            data['description'] = json_ld.get('description')

            if 'offers' in json_ld:
                offers = json_ld['offers']
                if isinstance(offers, dict):
                    data['price'] = offers.get('price')
                    data['currency'] = offers.get('priceCurrency', 'RUB')

        return data

    def _parse_from_html(self, soup: BeautifulSoup) -> Dict:
        """Fallback HTML –ø–∞—Ä—Å–∏–Ω–≥"""
        data = {}

        # –ó–∞–≥–æ–ª–æ–≤–æ–∫
        h1 = soup.find('h1')
        if h1:
            data['title'] = h1.get_text(strip=True)

        # –¶–µ–Ω–∞
        price_elem = soup.find('[class*="Price"]')
        if price_elem:
            price_text = price_elem.get_text(strip=True)
            data['price'] = self._extract_number(price_text)

        # –û–ø–∏—Å–∞–Ω–∏–µ
        desc_elem = soup.find('[class*="Description"]')
        if desc_elem:
            data['description'] = desc_elem.get_text(strip=True)

        return data

    def _extract_number(self, text: str) -> Optional[float]:
        """–ò–∑–≤–ª–µ—á—å —á–∏—Å–ª–æ –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
        if not text:
            return None
        cleaned = re.sub(r'[^\d.]', '', text)
        try:
            return float(cleaned)
        except ValueError:
            return None

    # ===== –ü–û–ò–°–ö –ê–ù–ê–õ–û–ì–û–í =====

    def _search_similar_impl(
        self,
        target_property: Dict,
        limit: int = 20,
        strategy: Literal['same_building', 'same_area', 'citywide'] = 'citywide'
    ) -> List[Dict]:
        """
        –ü–æ–∏—Å–∫ –∞–Ω–∞–ª–æ–≥–æ–≤ –Ω–∞ Yandex

        Args:
            target_property: –¶–µ–ª–µ–≤–æ–π –æ–±—ä–µ–∫—Ç
            limit: –õ–∏–º–∏—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            strategy: –°—Ç—Ä–∞—Ç–µ–≥–∏—è –ø–æ–∏—Å–∫–∞

        Returns:
            –°–ø–∏—Å–æ–∫ –∞–Ω–∞–ª–æ–≥–æ–≤
        """
        logger.info(f"–ü–æ–∏—Å–∫ –∞–Ω–∞–ª–æ–≥–æ–≤ –Ω–∞ Yandex (—Å—Ç—Ä–∞—Ç–µ–≥–∏—è: {strategy})")

        # TODO: Implement search via GraphQL
        logger.warning("‚ö†Ô∏è –ü–æ–∏—Å–∫ –∞–Ω–∞–ª–æ–≥–æ–≤ –Ω–∞ Yandex –ø–æ–∫–∞ –Ω–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω")

        return []

    # ===== –í–û–ó–ú–û–ñ–ù–û–°–¢–ò =====

    def get_capabilities(self) -> ParserCapabilities:
        """–í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –ø–∞—Ä—Å–µ—Ä–∞"""
        return ParserCapabilities(
            supports_search=False,  # TODO: —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å
            supports_residential_complex=False,
            supports_regions=['msk', 'spb'],
            supports_async=True,  # httpx async
            has_api=True,  # GraphQL
            requires_browser=False  # GraphQL –Ω–µ —Ç—Ä–µ–±—É–µ—Ç –±—Ä–∞—É–∑–µ—Ä
        )

    def get_source_name(self) -> str:
        """–ù–∞–∑–≤–∞–Ω–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∞"""
        return 'yandex'
