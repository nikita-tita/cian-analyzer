"""
–ü–∞—Ä—Å–µ—Ä –¥–ª—è Avito.ru (–ê–≤–∏—Ç–æ –ù–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç—å)

–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ –ê–≤–∏—Ç–æ:
- –û—á–µ–Ω—å —Å–∏–ª—å–Ω–∞—è –∑–∞—â–∏—Ç–∞ (DataDome)
- React SPA –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
- –ú–æ–±–∏–ª—å–Ω–æ–µ API –¥–æ—Å—Ç—É–ø–Ω–æ
- –¢—Ä–µ–±—É–µ—Ç –æ–±—Ö–æ–¥ –∫–∞–ø—á–∏

–°—Ç—Ä–∞—Ç–µ–≥–∏—è –ø–∞—Ä—Å–∏–Ω–≥–∞:
1. –ú–æ–±–∏–ª—å–Ω–æ–µ API (—á–µ—Ä–µ–∑ curl_cffi —Å Android User-Agent)
2. Nodriver (–æ–±—Ö–æ–¥ DataDome)
3. Proxy rotation + Nodriver (–ø–æ—Å–ª–µ–¥–Ω—è—è –ø–æ–ø—ã—Ç–∫–∞)
"""

import json
import logging
import re
import time
from typing import Optional, Dict, List, Literal
from bs4 import BeautifulSoup
from urllib.parse import urljoin, parse_qs, urlparse

from .base_real_estate_parser import BaseRealEstateParser, ParserCapabilities, ParsingError
from .field_mapper import get_field_mapper
from .parser_registry import register_parser

logger = logging.getLogger(__name__)

# –ò–º–ø–æ—Ä—Ç —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
try:
    from .strategies.curl_cffi_strategy import CurlCffiStrategy
    CURL_CFFI_AVAILABLE = True
except ImportError:
    CURL_CFFI_AVAILABLE = False

try:
    from .strategies.nodriver_strategy import NodriverStrategy
    NODRIVER_AVAILABLE = True
except ImportError:
    NODRIVER_AVAILABLE = False


@register_parser('avito', [r'avito\.ru', r'www\.avito\.ru'])
class AvitoParser(BaseRealEstateParser):
    """
    –ü–∞—Ä—Å–µ—Ä –¥–ª—è Avito.ru —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π

    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç:
    - –ú–æ–±–∏–ª—å–Ω–æ–µ API —á–µ—Ä–µ–∑ curl_cffi (–±—ã—Å—Ç—Ä–æ, —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ)
    - Nodriver –¥–ª—è –æ–±—Ö–æ–¥–∞ DataDome
    - Proxy rotation (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    """

    def __init__(
        self,
        delay: float = 2.0,
        cache=None,
        region: str = 'spb',
        use_mobile_api: bool = True
    ):
        """
        Args:
            delay: –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
            cache: –û–±—ä–µ–∫—Ç –∫—ç—à–∞
            region: –†–µ–≥–∏–æ–Ω ('spb', 'msk')
            use_mobile_api: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–æ–±–∏–ª—å–Ω–æ–µ API (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)
        """
        super().__init__(delay, cache)
        self.region = region
        self.use_mobile_api = use_mobile_api

        self.base_url = "https://www.avito.ru"
        self.mobile_api_base = "https://m.avito.ru/api"

        # –ú–∞–ø–ø–∏–Ω–≥ —Ä–µ–≥–∏–æ–Ω–æ–≤
        self.region_codes = {
            'spb': 'sankt-peterburg',
            'msk': 'moskva',
        }
        self.region_slug = self.region_codes.get(region, 'sankt-peterburg')

        # –°—Ç—Ä–∞—Ç–µ–≥–∏–∏ (–ª–µ–Ω–∏–≤–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è)
        self.curl_cffi: Optional[CurlCffiStrategy] = None
        self.nodriver: Optional[NodriverStrategy] = None

        # –ú–∞–ø–ø–µ—Ä –ø–æ–ª–µ–π
        self.field_mapper = get_field_mapper('avito')

        logger.info(f"‚úì –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω AvitoParser (—Ä–µ–≥–∏–æ–Ω: {region}, mobile_api: {use_mobile_api})")

    def _init_curl_cffi(self):
        """–õ–µ–Ω–∏–≤–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è curl_cffi"""
        if not CURL_CFFI_AVAILABLE:
            logger.warning("curl_cffi –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
            return

        if not self.curl_cffi:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º Android User-Agent –¥–ª—è –º–æ–±–∏–ª—å–Ω–æ–≥–æ API
            self.curl_cffi = CurlCffiStrategy(
                impersonate='chrome110',  # –ò–º–∏—Ç–∏—Ä—É–µ–º Chrome
                timeout=30
            )
            logger.info("‚úì curl_cffi –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –¥–ª—è Avito")

    def _init_nodriver(self):
        """–õ–µ–Ω–∏–≤–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Nodriver"""
        if not NODRIVER_AVAILABLE:
            logger.warning("Nodriver –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
            return

        if not self.nodriver:
            self.nodriver = NodriverStrategy(
                headless=False,  # –î–ª—è Avito –ª—É—á—à–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–µ-headless
                timeout=30
            )
            logger.info("‚úì Nodriver –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –¥–ª—è Avito")

    # ===== –û–°–ù–û–í–ù–´–ï –ú–ï–¢–û–î–´ –ü–ê–†–°–ò–ù–ì–ê =====

    def _get_page_content(self, url: str) -> Optional[str]:
        """
        –ü–æ–ª—É—á–∏—Ç—å HTML –∫–æ–Ω—Ç–µ–Ω—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—ã

        Args:
            url: URL —Å—Ç—Ä–∞–Ω–∏—Ü—ã

        Returns:
            HTML –∫–æ–Ω—Ç–µ–Ω—Ç –∏–ª–∏ None
        """
        if self.use_mobile_api:
            # –ü—ã—Ç–∞–µ–º—Å—è —á–µ—Ä–µ–∑ –º–æ–±–∏–ª—å–Ω–æ–µ API
            offer_id = self._extract_offer_id(url)
            if offer_id:
                mobile_html = self._get_via_mobile_api(offer_id)
                if mobile_html:
                    return mobile_html

        # Fallback –Ω–∞ Nodriver
        return self._get_via_nodriver(url)

    def _get_via_mobile_api(self, offer_id: str) -> Optional[str]:
        """
        –ü–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ —á–µ—Ä–µ–∑ –º–æ–±–∏–ª—å–Ω–æ–µ API

        Args:
            offer_id: ID –æ–±—ä—è–≤–ª–µ–Ω–∏—è

        Returns:
            "HTML" (JSON –¥–∞–Ω–Ω—ã–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–Ω—ã–µ –≤ HTML-–ø–æ–¥–æ–±–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É)
        """
        self._init_curl_cffi()

        if not self.curl_cffi:
            return None

        # –ú–æ–±–∏–ª—å–Ω—ã–π API endpoint
        api_url = f"{self.mobile_api_base}/1/items/{offer_id}"

        logger.info(f"üîÑ –ó–∞–ø—Ä–æ—Å –∫ –º–æ–±–∏–ª—å–Ω–æ–º—É API Avito: {api_url}")

        # –ó–∞–≥–æ–ª–æ–≤–∫–∏ –¥–ª—è –º–æ–±–∏–ª—å–Ω–æ–≥–æ API
        headers = {
            'User-Agent': 'Mozilla/5.0 (Linux; Android 10; SM-G973F) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Mobile Safari/537.36',
            'Accept': 'application/json, text/plain, */*',
            'Accept-Language': 'ru-RU,ru;q=0.9',
            'X-Requested-With': 'XMLHttpRequest',
            'Referer': f'https://m.avito.ru/{self.region_slug}/kvartiry/{offer_id}',
        }

        try:
            data = self.curl_cffi.fetch_api(api_url, headers=headers)

            if data:
                logger.info(f"‚úì –ú–æ–±–∏–ª—å–Ω–æ–µ API Avito —É—Å–ø–µ—à–Ω–æ: {offer_id}")
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º JSON –≤ —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞
                return json.dumps(data)
            else:
                logger.warning(f"‚ö†Ô∏è –ú–æ–±–∏–ª—å–Ω–æ–µ API –Ω–µ –≤–µ—Ä–Ω—É–ª–æ –¥–∞–Ω–Ω—ã–µ")
                return None

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –º–æ–±–∏–ª—å–Ω–æ–≥–æ API Avito: {e}")
            return None

    def _get_via_nodriver(self, url: str) -> Optional[str]:
        """
        –ü–æ–ª—É—á–∏—Ç—å —Å—Ç—Ä–∞–Ω–∏—Ü—É —á–µ—Ä–µ–∑ Nodriver (–æ–±—Ö–æ–¥ DataDome)

        Args:
            url: URL —Å—Ç—Ä–∞–Ω–∏—Ü—ã

        Returns:
            HTML –∫–æ–Ω—Ç–µ–Ω—Ç –∏–ª–∏ None
        """
        self._init_nodriver()

        if not self.nodriver:
            logger.error("Nodriver –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –¥–ª—è Avito")
            return None

        try:
            logger.info(f"üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ —á–µ—Ä–µ–∑ Nodriver (–æ–±—Ö–æ–¥ DataDome): {url}")

            html = self.nodriver.fetch_content(
                url,
                wait_for_selector='[data-marker="item-view"]',
                additional_wait=3  # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ –æ–∂–∏–¥–∞–Ω–∏–µ –¥–ª—è Avito
            )

            return html

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ Nodriver: {e}")
            return None

    def _parse_single_property(self, url: str, html: str) -> Dict:
        """
        –ü–∞—Ä—Å–∏–Ω–≥ –æ–¥–Ω–æ–≥–æ –æ–±—ä—è–≤–ª–µ–Ω–∏—è

        Args:
            url: URL –æ–±—ä—è–≤–ª–µ–Ω–∏—è
            html: HTML –∫–æ–Ω—Ç–µ–Ω—Ç (–∏–ª–∏ JSON —Å—Ç—Ä–æ–∫–∞ –æ—Ç –º–æ–±–∏–ª—å–Ω–æ–≥–æ API)

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –¥–∞–Ω–Ω—ã–º–∏ (–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç)
        """
        data = {'url': url, 'source': 'avito'}

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —ç—Ç–æ JSON –æ—Ç –º–æ–±–∏–ª—å–Ω–æ–≥–æ API –∏–ª–∏ HTML
        if html and html.strip().startswith('{'):
            # –≠—Ç–æ JSON –æ—Ç –º–æ–±–∏–ª—å–Ω–æ–≥–æ API
            try:
                json_data = json.loads(html)
                logger.info("üì± –ü–∞—Ä—Å–∏–º –¥–∞–Ω–Ω—ã–µ –º–æ–±–∏–ª—å–Ω–æ–≥–æ API Avito")
                data.update(self._parse_from_mobile_api(json_data))
                return data
            except json.JSONDecodeError:
                logger.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å JSON, –ø—Ä–æ–±—É–µ–º –∫–∞–∫ HTML")

        # –û–±—ã—á–Ω—ã–π HTML –ø–∞—Ä—Å–∏–Ω–≥
        soup = BeautifulSoup(html, 'lxml')

        # –ü—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å –∏–∑ window.__initialData__ –∏–ª–∏ JSON-LD
        initial_data = self._extract_initial_data(html)
        if initial_data:
            data.update(self._parse_from_initial_data(initial_data))

        # JSON-LD
        json_ld = self._extract_json_ld(soup)
        if json_ld:
            data.update(self._parse_from_json_ld(json_ld))

        # Fallback HTML –ø–∞—Ä—Å–∏–Ω–≥
        if not data.get('title'):
            data.update(self._parse_from_html(soup))

        return data

    def _extract_offer_id(self, url: str) -> Optional[str]:
        """
        –ò–∑–≤–ª–µ—á—å ID –æ–±—ä—è–≤–ª–µ–Ω–∏—è –∏–∑ URL

        Args:
            url: URL –æ–±—ä—è–≤–ª–µ–Ω–∏—è

        Returns:
            ID –∏–ª–∏ None
        """
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã URL –ê–≤–∏—Ç–æ:
        # https://www.avito.ru/sankt-peterburg/kvartiry/2-k._kvartira_56m_44et._1234567890
        # https://m.avito.ru/sankt-peterburg/kvartiry/1234567890

        patterns = [
            r'/kvartiry/[^/]*_(\d{10,})$',  # Desktop URL
            r'/kvartiry/(\d{10,})$',        # Mobile URL
            r'_(\d{10,})$',                 # Fallback
        ]

        for pattern in patterns:
            match = re.search(pattern, url)
            if match:
                return match.group(1)

        logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å ID –∏–∑ URL: {url}")
        return None

    def _parse_from_mobile_api(self, api_data: Dict) -> Dict:
        """
        –ü–∞—Ä—Å–∏–Ω–≥ –¥–∞–Ω–Ω—ã—Ö –º–æ–±–∏–ª—å–Ω–æ–≥–æ API

        Args:
            api_data: JSON –¥–∞–Ω–Ω—ã–µ –∏–∑ API

        Returns:
            –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        """
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–∞–ø–ø–µ—Ä –ø–æ–ª–µ–π
        return self.field_mapper.transform(api_data)

    def _extract_initial_data(self, html: str) -> Optional[Dict]:
        """
        –ò–∑–≤–ª–µ—á—å –¥–∞–Ω–Ω—ã–µ –∏–∑ window.__initialData__

        Args:
            html: HTML –∫–æ–Ω—Ç–µ–Ω—Ç

        Returns:
            –î–∞–Ω–Ω—ã–µ –∏–ª–∏ None
        """
        pattern = r'window\.__initialData__\s*=\s*"([^"]+)"'

        try:
            match = re.search(pattern, html)
            if match:
                # –î–∞–Ω–Ω—ã–µ –∑–∞–∫–æ–¥–∏—Ä–æ–≤–∞–Ω—ã –≤ JSON —Å—Ç—Ä–æ–∫–µ
                json_str = match.group(1)
                # –î–µ–∫–æ–¥–∏—Ä—É–µ–º escape-–ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
                json_str = json_str.encode().decode('unicode_escape')
                data = json.loads(json_str)
                logger.info("‚úì –ò–∑–≤–ª–µ—á–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ –∏–∑ window.__initialData__")
                return data
        except Exception as e:
            logger.debug(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è __initialData__: {e}")

        return None

    def _parse_from_initial_data(self, data: Dict) -> Dict:
        """–ü–∞—Ä—Å–∏–Ω–≥ –∏–∑ __initialData__"""
        result = {}

        # –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö Avito —Å–ª–æ–∂–Ω–∞—è, –ø—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –Ω—É–∂–Ω—ã–µ –ø–æ–ª—è
        # –ü—Ä–∏–º–µ—Ä–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞: data.item (–æ–±—ä—è–≤–ª–µ–Ω–∏–µ)
        item = data.get('item', {})

        if item:
            result.update(self.field_mapper.transform(item))

        return result

    def _extract_json_ld(self, soup: BeautifulSoup) -> Optional[Dict]:
        """–ò–∑–≤–ª–µ—á—å JSON-LD"""
        try:
            json_ld_script = soup.find('script', type='application/ld+json')
            if json_ld_script and json_ld_script.string:
                return json.loads(json_ld_script.string)
        except Exception as e:
            logger.debug(f"JSON-LD –Ω–µ –Ω–∞–π–¥–µ–Ω: {e}")
        return None

    def _parse_from_json_ld(self, json_ld: Dict) -> Dict:
        """–ü–∞—Ä—Å–∏–Ω–≥ –∏–∑ JSON-LD"""
        data = {}

        if json_ld.get('@type') in ['Product', 'RealEstateListing']:
            data['title'] = json_ld.get('name')
            data['description'] = json_ld.get('description')

            if 'offers' in json_ld:
                offers = json_ld['offers']
                if isinstance(offers, dict):
                    data['price'] = offers.get('price')
                    data['currency'] = offers.get('priceCurrency', 'RUB')

        return data

    def _parse_from_html(self, soup: BeautifulSoup) -> Dict:
        """Fallback HTML –ø–∞—Ä—Å–∏–Ω–≥"""
        data = {}

        # –ó–∞–≥–æ–ª–æ–≤–æ–∫
        title_elem = soup.find('h1', {'data-marker': 'item-view/title'}) or soup.find('h1')
        if title_elem:
            data['title'] = title_elem.get_text(strip=True)

        # –¶–µ–Ω–∞
        price_elem = soup.find('[data-marker="item-view/item-price"]')
        if price_elem:
            price_text = price_elem.get_text(strip=True)
            data['price'] = self._extract_number(price_text)

        # –û–ø–∏—Å–∞–Ω–∏–µ
        desc_elem = soup.find('[data-marker="item-view/item-description"]')
        if desc_elem:
            data['description'] = desc_elem.get_text(strip=True)

        # –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
        params = soup.find_all('li', class_='params-paramsList__item')
        characteristics = {}
        for param in params:
            try:
                key = param.get_text(separator='|', strip=True).split('|')[0].strip()
                value = param.get_text(separator='|', strip=True).split('|')[1].strip() if '|' in param.get_text(separator='|') else ''
                if key and value:
                    characteristics[key] = value
            except:
                pass

        data['characteristics'] = characteristics

        return data

    def _extract_number(self, text: str) -> Optional[float]:
        """–ò–∑–≤–ª–µ—á—å —á–∏—Å–ª–æ –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
        if not text:
            return None
        cleaned = re.sub(r'[^\d.]', '', text)
        try:
            return float(cleaned)
        except ValueError:
            return None

    # ===== –ü–û–ò–°–ö –ê–ù–ê–õ–û–ì–û–í =====

    def _search_similar_impl(
        self,
        target_property: Dict,
        limit: int = 20,
        strategy: Literal['same_building', 'same_area', 'citywide'] = 'citywide'
    ) -> List[Dict]:
        """
        –ü–æ–∏—Å–∫ –∞–Ω–∞–ª–æ–≥–æ–≤ –Ω–∞ Avito

        Args:
            target_property: –¶–µ–ª–µ–≤–æ–π –æ–±—ä–µ–∫—Ç
            limit: –õ–∏–º–∏—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            strategy: –°—Ç—Ä–∞—Ç–µ–≥–∏—è –ø–æ–∏—Å–∫–∞

        Returns:
            –°–ø–∏—Å–æ–∫ –∞–Ω–∞–ª–æ–≥–æ–≤
        """
        logger.info(f"–ü–æ–∏—Å–∫ –∞–Ω–∞–ª–æ–≥–æ–≤ –Ω–∞ –ê–≤–∏—Ç–æ (—Å—Ç—Ä–∞—Ç–µ–≥–∏—è: {strategy})")

        # TODO: Implement search
        logger.warning("‚ö†Ô∏è –ü–æ–∏—Å–∫ –∞–Ω–∞–ª–æ–≥–æ–≤ –Ω–∞ Avito –ø–æ–∫–∞ –Ω–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω")

        return []

    # ===== –í–û–ó–ú–û–ñ–ù–û–°–¢–ò =====

    def get_capabilities(self) -> ParserCapabilities:
        """–í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –ø–∞—Ä—Å–µ—Ä–∞"""
        return ParserCapabilities(
            supports_search=False,  # TODO: —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å
            supports_residential_complex=False,
            supports_regions=['msk', 'spb'],
            supports_async=False,
            has_api=True,  # –ú–æ–±–∏–ª—å–Ω–æ–µ API
            requires_browser=True  # Nodriver –¥–ª—è fallback
        )

    def get_source_name(self) -> str:
        """–ù–∞–∑–≤–∞–Ω–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∞"""
        return 'avito'
