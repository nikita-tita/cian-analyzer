"""
–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π Playwright –ø–∞—Ä—Å–µ—Ä —Å –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –±—Ä–∞—É–∑–µ—Ä–∞
"""

import time
import logging
from typing import Optional, List, Dict
from playwright.sync_api import sync_playwright, Page, Browser, BrowserContext
from bs4 import BeautifulSoup

from .base_parser import BaseCianParser, ParsingError

logger = logging.getLogger(__name__)


class PlaywrightParser(BaseCianParser):
    """
    Playwright –ø–∞—Ä—Å–µ—Ä —Å –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –±—Ä–∞—É–∑–µ—Ä–∞

    –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø:
    - –ë—Ä–∞—É–∑–µ—Ä –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –æ–¥–∏–Ω —Ä–∞–∑ –Ω–∞ –≤—Å—é —Å–µ—Å—Å–∏—é
    - Context –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è
    - –ë–ª–æ–∫–∏—Ä—É—é—Ç—Å—è –Ω–µ–Ω—É–∂–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã (–∫–∞—Ä—Ç–∏–Ω–∫–∏, —à—Ä–∏—Ñ—Ç—ã)
    """

    def __init__(self, headless: bool = True, delay: float = 2.0, block_resources: bool = True):
        """
        Args:
            headless: –ó–∞–ø—É—Å–∫–∞—Ç—å –±—Ä–∞—É–∑–µ—Ä –≤ —Ñ–æ–Ω–æ–≤–æ–º —Ä–µ–∂–∏–º–µ
            delay: –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
            block_resources: –ë–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å –∫–∞—Ä—Ç–∏–Ω–∫–∏/—à—Ä–∏—Ñ—Ç—ã –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è
        """
        super().__init__(delay)
        self.headless = headless
        self.block_resources = block_resources
        self.playwright = None
        self.browser: Optional[Browser] = None
        self.context: Optional[BrowserContext] = None

    def __enter__(self):
        """Context manager –≤—Ö–æ–¥"""
        self.start()
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        """Context manager –≤—ã—Ö–æ–¥"""
        self.close()

    def start(self):
        """–ó–∞–ø—É—Å–∫ –±—Ä–∞—É–∑–µ—Ä–∞ (–æ–¥–∏–Ω —Ä–∞–∑ –∑–∞ —Å–µ—Å—Å–∏—é)"""
        if self.browser:
            logger.warning("–ë—Ä–∞—É–∑–µ—Ä —É–∂–µ –∑–∞–ø—É—â–µ–Ω")
            return

        logger.info("üöÄ –ó–∞–ø—É—Å–∫ Playwright –±—Ä–∞—É–∑–µ—Ä–∞...")
        self.playwright = sync_playwright().start()

        self.browser = self.playwright.chromium.launch(
            headless=self.headless,
            args=[
                '--disable-blink-features=AutomationControlled',
                '--disable-dev-shm-usage',
                '--no-sandbox',
                '--disable-gpu',
                '--disable-software-rasterizer',
            ]
        )

        self.context = self.browser.new_context(
            viewport={'width': 1920, 'height': 1080},
            user_agent='Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            locale='ru-RU',
            timezone_id='Europe/Moscow',
        )

        # –°–∫—Ä—ã–≤–∞–µ–º –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—é
        self.context.add_init_script("""
            Object.defineProperty(navigator, 'webdriver', {
                get: () => undefined
            });
            window.chrome = { runtime: {} };
        """)

        # –ë–ª–æ–∫–∏—Ä—É–µ–º –Ω–µ–Ω—É–∂–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è
        if self.block_resources:
            self.context.route(
                "**/*.{png,jpg,jpeg,gif,svg,webp,woff,woff2,ttf,mp4,mp3,pdf}",
                lambda route: route.abort()
            )

        logger.info("‚úì –ë—Ä–∞—É–∑–µ—Ä –∑–∞–ø—É—â–µ–Ω –∏ –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ")

    def close(self):
        """–ó–∞–∫—Ä—ã—Ç–∏–µ –±—Ä–∞—É–∑–µ—Ä–∞"""
        if self.context:
            self.context.close()
            self.context = None

        if self.browser:
            self.browser.close()
            self.browser = None

        if self.playwright:
            self.playwright.stop()
            self.playwright = None

        logger.info("–ë—Ä–∞—É–∑–µ—Ä –∑–∞–∫—Ä—ã—Ç")

    def _get_page_content(self, url: str) -> Optional[str]:
        """
        –ü–æ–ª—É—á–∏—Ç—å HTML –∫–æ–Ω—Ç–µ–Ω—Ç —á–µ—Ä–µ–∑ Playwright

        Args:
            url: URL –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏

        Returns:
            HTML –∫–æ–Ω—Ç–µ–Ω—Ç –∏–ª–∏ None
        """
        if not self.context:
            raise RuntimeError("–ë—Ä–∞—É–∑–µ—Ä –Ω–µ –∑–∞–ø—É—â–µ–Ω. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ with context –∏–ª–∏ –≤—ã–∑–æ–≤–∏—Ç–µ .start()")

        page: Page = self.context.new_page()

        try:
            logger.info(f"–ó–∞–≥—Ä—É–∑–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã: {url}")

            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É
            page.goto(url, wait_until='domcontentloaded', timeout=30000)

            # –ñ–¥–µ–º –ø–æ—è–≤–ª–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞
            try:
                page.wait_for_selector(
                    'h1, [data-mark="OfferTitle"], script[type="application/ld+json"]',
                    timeout=10000
                )
            except:
                logger.warning("–°–µ–ª–µ–∫—Ç–æ—Ä—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, –Ω–æ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º")

            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ –æ–∂–∏–¥–∞–Ω–∏–µ –¥–ª—è –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
            time.sleep(1)

            html = page.content()

            logger.info(f"‚úì –°—Ç—Ä–∞–Ω–∏—Ü–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ ({len(html)} —Å–∏–º–≤–æ–ª–æ–≤)")
            return html

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ {url}: {e}", exc_info=True)
            return None

        finally:
            page.close()
            time.sleep(self.delay)

    def parse_search_page(self, url: str) -> List[Dict]:
        """
        –ü–∞—Ä—Å–∏–Ω–≥ —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –ø–æ–∏—Å–∫–∞

        Args:
            url: URL —Å—Ç—Ä–∞–Ω–∏—Ü—ã –ø–æ–∏—Å–∫–∞

        Returns:
            –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –¥–∞–Ω–Ω—ã–º–∏ –æ–±—ä—è–≤–ª–µ–Ω–∏–π
        """
        logger.info(f"–ü–∞—Ä—Å–∏–Ω–≥ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –ø–æ–∏—Å–∫–∞: {url}")

        html = self._get_page_content(url)
        if not html:
            return []

        soup = BeautifulSoup(html, 'lxml')

        # –ü–æ–∏—Å–∫ –∫–∞—Ä—Ç–æ—á–µ–∫ –æ–±—ä—è–≤–ª–µ–Ω–∏–π
        cards = soup.find_all('article', {'data-name': 'CardComponent'})

        if not cards:
            cards = soup.find_all('div', class_=lambda x: x and 'offer-card' in str(x).lower())

        logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(cards)} –æ–±—ä—è–≤–ª–µ–Ω–∏–π")

        listings = []
        for card in cards:
            try:
                listing_data = self._parse_listing_card(card)
                if listing_data.get('title'):
                    listings.append(listing_data)
            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ –∫–∞—Ä—Ç–æ—á–∫–∏: {e}")
                continue

        return listings

    def _parse_listing_card(self, card: BeautifulSoup) -> Dict:
        """
        –ü–∞—Ä—Å–∏–Ω–≥ –∫–∞—Ä—Ç–æ—á–∫–∏ –æ–±—ä—è–≤–ª–µ–Ω–∏—è –∏–∑ —Å–ø–∏—Å–∫–∞

        Args:
            card: BeautifulSoup –æ–±—ä–µ–∫—Ç –∫–∞—Ä—Ç–æ—á–∫–∏

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –¥–∞–Ω–Ω—ã–º–∏ –æ–±—ä—è–≤–ª–µ–Ω–∏—è
        """
        data = {
            'title': None,
            'price': None,
            'price_per_sqm': None,  # –¶–µ–Ω–∞ –∑–∞ –∫–≤.–º
            'price_raw': None,  # –¶–µ–Ω–∞ –≤ —á–∏—Å–ª–æ–≤–æ–º –≤–∏–¥–µ
            'address': None,
            'metro': None,
            'area': None,
            'area_value': None,  # –ü–ª–æ—â–∞–¥—å –≤ —á–∏—Å–ª–æ–≤–æ–º –≤–∏–¥–µ
            'rooms': None,
            'floor': None,
            'renovation': None,  # –¢–∏–ø —Ä–µ–º–æ–Ω—Ç–∞
            'url': None,
            'image_url': None,
        }

        # –ó–∞–≥–æ–ª–æ–≤–æ–∫ - –ø—Ä–æ–±—É–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤
        title_elem = (
            card.find('span', {'data-mark': 'OfferTitle'}) or
            card.find('h3') or
            card.find('a', {'data-name': 'LinkArea'})
        )
        if title_elem:
            data['title'] = title_elem.get_text(strip=True)

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–º–Ω–∞—Ç –∏–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞
            import re
            title_lower = data['title'].lower()
            if '—Å—Ç—É–¥–∏' in title_lower:
                data['rooms'] = '—Å—Ç—É–¥–∏—è'
            else:
                match = re.search(r'(\d+)-–∫–æ–º–Ω', data['title'])
                if match:
                    data['rooms'] = match.group(1)

        # –¶–µ–Ω–∞ - –ø—Ä–æ–±—É–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤
        price_elem = (
            card.find('span', {'data-mark': 'MainPrice'}) or
            card.find('span', class_=lambda x: x and 'price' in str(x).lower())
        )
        if price_elem:
            price_text = price_elem.get_text(strip=True)
            data['price'] = price_text

            # –ò–∑–≤–ª–µ–∫–∞–µ–º —á–∏—Å–ª–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ —Ü–µ–Ω—ã
            import re
            price_numbers = re.sub(r'[^\d]', '', price_text)
            if price_numbers:
                data['price_raw'] = int(price_numbers)

        # –ê–¥—Ä–µ—Å - —Å–æ–±–∏—Ä–∞–µ–º –í–°–ï GeoLabel (breadcrumbs)
        geo_labels = card.find_all('a', {'data-name': 'GeoLabel'})
        if geo_labels:
            # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —á–∞—Å—Ç–∏ –∞–¥—Ä–µ—Å–∞
            address_parts = [label.get_text(strip=True) for label in geo_labels]
            # –°–æ–µ–¥–∏–Ω—è–µ–º —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é, –ø—Ä–æ–ø—É—Å–∫–∞—è –¥—É–±–ª–∏–∫–∞—Ç—ã
            unique_parts = []
            for part in address_parts:
                if part not in unique_parts:
                    unique_parts.append(part)
            data['address'] = ', '.join(unique_parts)

        # –ï—Å–ª–∏ GeoLabel –Ω–µ –Ω–∞–π–¥–µ–Ω—ã
        if not data['address']:
            address_elem = (
                card.find('div', {'data-name': 'AddressContainer'}) or
                card.find('div', class_=lambda x: x and 'address' in str(x).lower())
            )
            if address_elem:
                data['address'] = address_elem.get_text(strip=True)

        # –ï—Å–ª–∏ –∞–¥—Ä–µ—Å –≤—Å–µ –µ—â–µ –Ω–µ –Ω–∞–π–¥–µ–Ω, –ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –ª—é–±–æ–π —Ç–µ–∫—Å—Ç —Å –≥–æ—Ä–æ–¥–æ–º
        if not data['address']:
            # –ò—â–µ–º div/span —Å —Ç–µ–∫—Å—Ç–æ–º, —Å–æ–¥–µ—Ä–∂–∞—â–∏–º "–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥" –∏–ª–∏ "–ú–æ—Å–∫–≤–∞"
            for elem in card.find_all(['div', 'span', 'a']):
                text = elem.get_text(strip=True)
                if '–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥' in text or '–ú–æ—Å–∫–≤–∞' in text:
                    if len(text) < 200:  # –ù–µ –±–µ—Ä–µ–º —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã
                        data['address'] = text
                        break

        # –ú–µ—Ç—Ä–æ
        metro_elem = card.find('a', {'data-name': 'UndergroundLabel'})
        if metro_elem:
            data['metro'] = metro_elem.get_text(strip=True)

        # –ü–æ–¥–∑–∞–≥–æ–ª–æ–≤–æ–∫ —Å —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞–º–∏ (–ü–†–ò–û–†–ò–¢–ï–¢ - –∑–¥–µ—Å—å —Å–æ–¥–µ—Ä–∂–∏—Ç—Å—è –ø–ª–æ—â–∞–¥—å!)
        # –§–æ—Ä–º–∞—Ç: "2-–∫–æ–º–Ω. –∫–≤–∞—Ä—Ç–∏—Ä–∞, 85 –º¬≤, 4/9 —ç—Ç–∞–∂"
        subtitle_elem = card.find('span', {'data-mark': 'OfferSubtitle'})
        if subtitle_elem:
            subtitle_text = subtitle_elem.get_text(strip=True)
            import re

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–ª–æ—â–∞–¥—å (85 –º¬≤)
            area_match = re.search(r'([\d,\.]+)\s*–º¬≤', subtitle_text)
            if area_match:
                data['area'] = area_match.group(0)  # "85 –º¬≤"
                area_str = area_match.group(1).replace(',', '.')
                try:
                    data['area_value'] = float(area_str)
                except ValueError:
                    pass

            # –ò–∑–≤–ª–µ–∫–∞–µ–º —ç—Ç–∞–∂ (4/9 —ç—Ç–∞–∂ ‚Üí 4)
            floor_match = re.search(r'(\d+)/\d+\s*—ç—Ç–∞–∂', subtitle_text)
            if floor_match:
                try:
                    data['floor'] = int(floor_match.group(1))  # –¢–æ–ª—å–∫–æ –Ω–æ–º–µ—Ä —ç—Ç–∞–∂–∞, –Ω–µ "4/9"
                except ValueError:
                    pass

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–º–Ω–∞—Ç (2-–∫–æ–º–Ω.)
            if not data['rooms']:  # –ï—Å–ª–∏ –µ—â–µ –Ω–µ –∏–∑–≤–ª–µ–∫–ª–∏ –∏–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞
                if '—Å—Ç—É–¥–∏' in subtitle_text.lower():
                    data['rooms'] = '—Å—Ç—É–¥–∏—è'
                else:
                    rooms_match = re.search(r'(\d+)-–∫–æ–º–Ω', subtitle_text)
                    if rooms_match:
                        data['rooms'] = rooms_match.group(1)

        # –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ (FALLBACK - –µ—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –≤ –ø–æ–¥–∑–∞–≥–æ–ª–æ–≤–∫–µ)
        characteristics = card.find_all('span', {'data-mark': 'OfferCharacteristics'})
        for char in characteristics:
            text = char.get_text(strip=True)
            if '–º¬≤' in text and not data['area_value']:
                data['area'] = text
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —á–∏—Å–ª–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–ª–æ—â–∞–¥–∏
                import re
                area_match = re.search(r'([\d,\.]+)\s*–º¬≤', text)
                if area_match:
                    area_str = area_match.group(1).replace(',', '.')
                    try:
                        data['area_value'] = float(area_str)
                    except ValueError:
                        pass
            elif '—ç—Ç–∞–∂' in text.lower() and not data['floor']:
                data['floor'] = text
            elif '—Ä–µ–º–æ–Ω—Ç' in text.lower() or '–æ—Ç–¥–µ–ª–∫' in text.lower():
                data['renovation'] = text

        # –í—ã—á–∏—Å–ª—è–µ–º —Ü–µ–Ω—É –∑–∞ –∫–≤.–º –µ—Å–ª–∏ –µ—Å—Ç—å —Ü–µ–Ω–∞ –∏ –ø–ª–æ—â–∞–¥—å
        if data['price_raw'] and data['area_value']:
            data['price_per_sqm'] = round(data['price_raw'] / data['area_value'])

        # –°—Å—ã–ª–∫–∞ - –ø—Ä–æ–±—É–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤
        link_elem = (
            card.find('a', {'data-mark': 'OfferTitle'}) or
            card.find('a', {'data-name': 'LinkArea'}) or
            card.find('a', href=lambda x: x and '/sale/flat/' in str(x))
        )
        if link_elem and link_elem.get('href'):
            href = link_elem['href']
            data['url'] = self.base_url + href if not href.startswith('http') else href

        # –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        img_elem = card.find('img', {'data-mark': 'OfferPreviewImage'})
        if img_elem:
            data['image_url'] = img_elem.get('src') or img_elem.get('data-src')

        return data

    def search_similar_in_building(self, target_property: Dict, limit: int = 20) -> List[Dict]:
        """
        –ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö –∫–≤–∞—Ä—Ç–∏—Ä –≤ —Ç–æ–º –∂–µ –ñ–ö (–∂–∏–ª–æ–º –∫–æ–º–ø–ª–µ–∫—Å–µ)

        Args:
            target_property: –¶–µ–ª–µ–≤–æ–π –æ–±—ä–µ–∫—Ç —Å –ø–æ–ª—è–º–∏ residential_complex, residential_complex_url, address
            limit: –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

        Returns:
            –°–ø–∏—Å–æ–∫ –ø–æ—Ö–æ–∂–∏—Ö –æ–±—ä—è–≤–ª–µ–Ω–∏–π –∏–∑ —Ç–æ–≥–æ –∂–µ –ñ–ö
        """
        logger.info("üîç –ù–∞—á–∏–Ω–∞–µ–º –ø–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö –∫–≤–∞—Ä—Ç–∏—Ä –≤ —Ç–æ–º –∂–µ –ñ–ö...")

        residential_complex = target_property.get('residential_complex')
        residential_complex_url = target_property.get('residential_complex_url')
        address = target_property.get('address', '')

        # –ü–†–ò–û–†–ò–¢–ï–¢ 1: –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä—è–º—É—é —Å—Å—ã–ª–∫—É –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É –ñ–ö (—Å–∞–º—ã–π —Ç–æ—á–Ω—ã–π –º–µ—Ç–æ–¥!)
        if residential_complex_url:
            logger.info(f"‚ú® –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä—è–º—É—é —Å—Å—ã–ª–∫—É –Ω–∞ –ñ–ö: {residential_complex_url}")

            # –ï—Å–ª–∏ —ç—Ç–æ —Å—Å—ã–ª–∫–∞ –Ω–∞ –ø–æ–¥–¥–æ–º–µ–Ω (zhk-–Ω–∞–∑–≤–∞–Ω–∏–µ.cian.ru), –∏—â–µ–º –∫–Ω–æ–ø–∫—É "–í—Å–µ –∫–≤–∞—Ä—Ç–∏—Ä—ã"
            # –ï—Å–ª–∏ —ç—Ç–æ —Å—Å—ã–ª–∫–∞ /kupit-kvartiru-zhiloy-kompleks-*, –æ–Ω–∞ —É–∂–µ –≥–æ—Ç–æ–≤–∞ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞
            if 'zhk-' in residential_complex_url and '.cian.ru' in residential_complex_url:
                # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É –ñ–ö –∏ –∏—â–µ–º —Å—Å—ã–ª–∫—É –Ω–∞ –∫–∞—Ç–∞–ª–æ–≥
                html = self._get_page_content(residential_complex_url)
                if html:
                    from bs4 import BeautifulSoup
                    soup = BeautifulSoup(html, 'lxml')

                    # –ò—â–µ–º —Å—Å—ã–ª–∫—É –Ω–∞ –∫–∞—Ç–∞–ª–æ–≥ –∫–≤–∞—Ä—Ç–∏—Ä –ñ–ö
                    catalog_links = soup.find_all('a', href=True)
                    for link in catalog_links:
                        href = link.get('href')
                        text = link.get_text(strip=True).lower()

                        if ('/kupit-kvartiru-zhiloy-kompleks-' in href or
                            ('/cat.php' in href and 'newobject' in href)):
                            residential_complex_url = href if href.startswith('http') else f"https://www.cian.ru{href}"
                            logger.info(f"   –ù–∞–π–¥–µ–Ω–∞ —Å—Å—ã–ª–∫–∞ –Ω–∞ –∫–∞—Ç–∞–ª–æ–≥: {residential_complex_url[:80]}")
                            break

            # –ü–∞—Ä—Å–∏–º —Å—Ç—Ä–∞–Ω–∏—Ü—É —Å –æ–±—ä—è–≤–ª–µ–Ω–∏—è–º–∏ –ñ–ö
            results = self.parse_search_page(residential_complex_url)

            if results:
                # –ú–∞–ø–ø–∏–Ω–≥ –ø–æ–ª–µ–π –¥–ª—è Pydantic –º–æ–¥–µ–ª–µ–π
                for result in results:
                    if 'area_value' in result and result['area_value']:
                        result['total_area'] = result['area_value']
                    if 'price_raw' in result and result['price_raw']:
                        result['price'] = result['price_raw']
                    if 'rooms' in result and isinstance(result['rooms'], str) and result['rooms'].isdigit():
                        result['rooms'] = int(result['rooms'])

                logger.info(f"‚úì –ù–∞–π–¥–µ–Ω–æ {len(results)} –æ–±—ä—è–≤–ª–µ–Ω–∏–π —á–µ—Ä–µ–∑ –ø—Ä—è–º—É—é —Å—Å—ã–ª–∫—É –Ω–∞ –ñ–ö")
                return results[:limit]
            else:
                logger.warning("‚ö†Ô∏è –ü–æ –ø—Ä—è–º–æ–π —Å—Å—ã–ª–∫–µ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –ø—Ä–æ–±—É–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–π –ø–æ–∏—Å–∫")

        # –ü–†–ò–û–†–ò–¢–ï–¢ 2: –¢–µ–∫—Å—Ç–æ–≤—ã–π –ø–æ–∏—Å–∫ –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é –ñ–ö (fallback)
        if not residential_complex:
            logger.warning("‚ö†Ô∏è –ù–µ —É–∫–∞–∑–∞–Ω –ñ–ö, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø–æ–∏—Å–∫ –ø–æ –∞–¥—Ä–µ—Å—É")
            # –ü—Ä–æ–±—É–µ–º –∏–∑–≤–ª–µ—á—å –∏–∑ –∞–¥—Ä–µ—Å–∞
            import re
            match = re.search(r'–ñ–ö\s+([–ê-–Ø–∞-—è—ë–Å\s\-\d]+?)(?:,|$)', address)
            if match:
                residential_complex = match.group(1).strip()
            else:
                # –ï—Å–ª–∏ –Ω–µ—Ç –ñ–ö - –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞—Ä—ã–π –º–µ—Ç–æ–¥
                logger.warning("‚ö†Ô∏è –ñ–ö –Ω–µ –Ω–∞–π–¥–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —à–∏—Ä–æ–∫–∏–π –ø–æ–∏—Å–∫")
                return self.search_similar(target_property, limit)

        logger.info(f"üìç –¢–µ–∫—Å—Ç–æ–≤—ã–π –ø–æ–∏—Å–∫ –ø–æ –ñ–ö: {residential_complex}")

        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
        import urllib.parse

        # –í–∞—Ä–∏–∞–Ω—Ç 1: –¢–æ—á–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –ñ–ö
        search_query = f"–ñ–ö {residential_complex}"
        encoded_query = urllib.parse.quote(search_query)

        # –°—Ç—Ä–æ–∏–º URL –ø–æ–∏—Å–∫–∞ —Å —Ç–µ–∫—Å—Ç–æ–≤—ã–º –∑–∞–ø—Ä–æ—Å–æ–º
        search_params = {
            'deal_type': 'sale',
            'offer_type': 'flat',
            'engine_version': '2',
            'region': '2',  # –°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥
            'text': encoded_query,
        }

        url = f"{self.base_url}/cat.php?" + '&'.join([f"{k}={v}" for k, v in search_params.items()])

        logger.info(f"üîó URL –ø–æ–∏—Å–∫–∞: {url}")

        # –ü–∞—Ä—Å–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        results = self.parse_search_page(url)

        # –§–∏–ª—å—Ç—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã - –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ, —á—Ç–æ —Ç–æ—á–Ω–æ –∏–∑ —ç—Ç–æ–≥–æ –ñ–ö
        filtered_results = []
        rc_lower = residential_complex.lower()

        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –ñ–ö –Ω–∞ —Å–ª–æ–≤–∞ –¥–ª—è –±–æ–ª–µ–µ –≥–∏–±–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞
        rc_words = set(rc_lower.split())

        logger.info(f"   –ù–∞–π–¥–µ–Ω–æ {len(results)} –∫–∞—Ä—Ç–æ—á–µ–∫, —Ñ–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –ñ–ö '{residential_complex}'")
        logger.info(f"   –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –ñ–ö: {rc_words}")

        for i, result in enumerate(results):
            result_title = result.get('title', '').lower()
            result_address = result.get('address', '').lower()

            if i < 5:  # –õ–æ–≥–∏—Ä—É–µ–º –ø–µ—Ä–≤—ã–µ 5 –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
                logger.info(f"   –ö–∞—Ä—Ç–æ—á–∫–∞ {i+1}:")
                logger.info(f"     Title: {result_title[:100]}")
                logger.info(f"     Address: {result_address[:150]}")

            # –ü–æ–ª–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç)
            if rc_lower in result_title or rc_lower in result_address:
                filtered_results.append(result)
                logger.debug(f"     ‚úì –î–æ–±–∞–≤–ª–µ–Ω–∞ (–ø–æ–ª–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ)")
                continue

            # –ß–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ - –ø—Ä–æ–≤–µ—Ä—è–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ —Å–ª–æ–≤–∞
            # (–º–∏–Ω–∏–º—É–º 2 —Å–ª–æ–≤–∞ –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è –ñ–ö –¥–æ–ª–∂–Ω—ã –ø—Ä–∏—Å—É—Ç—Å—Ç–≤–æ–≤–∞—Ç—å)
            if len(rc_words) >= 2:
                title_words = set(result_title.split())
                address_words = set(result_address.split())

                matching_in_title = len(rc_words & title_words)
                matching_in_address = len(rc_words & address_words)

                if matching_in_title >= 2 or matching_in_address >= 2:
                    filtered_results.append(result)
                    logger.debug(f"     ‚úì –î–æ–±–∞–≤–ª–µ–Ω–∞ (—á–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ: {matching_in_title} –≤ title, {matching_in_address} –≤ address)")
                elif i < 3:
                    logger.debug(f"     ‚úó –ü—Ä–æ–ø—É—â–µ–Ω–∞ (–º–∞–ª–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π: {matching_in_title} –≤ title, {matching_in_address} –≤ address)")

        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
        limited_results = filtered_results[:limit]

        # –ú–∞–ø–ø–∏–Ω–≥ –ø–æ–ª–µ–π –¥–ª—è Pydantic –º–æ–¥–µ–ª–µ–π
        # –ü–∞—Ä—Å–µ—Ä –∫–∞—Ä—Ç–æ—á–µ–∫ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç 'area_value' –∏ 'price_raw', –Ω–æ –º–æ–¥–µ–ª–∏ –æ–∂–∏–¥–∞—é—Ç 'total_area' –∏ 'price'
        for result in limited_results:
            if 'area_value' in result and result['area_value']:
                result['total_area'] = result['area_value']
            if 'price_raw' in result and result['price_raw']:
                result['price'] = result['price_raw']
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º rooms –≤ int –µ—Å–ª–∏ —ç—Ç–æ —Å—Ç—Ä–æ–∫–∞ —Å —Ü–∏—Ñ—Ä–æ–π
            if 'rooms' in result and isinstance(result['rooms'], str) and result['rooms'].isdigit():
                result['rooms'] = int(result['rooms'])

        logger.info(f"‚úì –ù–∞–π–¥–µ–Ω–æ {len(limited_results)} –ø–æ—Ö–æ–∂–∏—Ö –æ–±—ä—è–≤–ª–µ–Ω–∏–π –≤ –ñ–ö {residential_complex}")

        return limited_results

    def search_similar(self, target_property: Dict, limit: int = 20) -> List[Dict]:
        """
        –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö –∫–≤–∞—Ä—Ç–∏—Ä (—à–∏—Ä–æ–∫–∏–π –ø–æ–∏—Å–∫ –ø–æ –≥–æ—Ä–æ–¥—É)

        Args:
            target_property: –¶–µ–ª–µ–≤–æ–π –æ–±—ä–µ–∫—Ç —Å –ø–æ–ª—è–º–∏ price, total_area, rooms
            limit: –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

        Returns:
            –°–ø–∏—Å–æ–∫ –ø–æ—Ö–æ–∂–∏—Ö –æ–±—ä—è–≤–ª–µ–Ω–∏–π
        """
        logger.info("üîç –ù–∞—á–∏–Ω–∞–µ–º –ø–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö –∫–≤–∞—Ä—Ç–∏—Ä...")

        # –§–æ—Ä–º–∏—Ä—É–µ–º –∫—Ä–∏—Ç–µ—Ä–∏–∏ –ø–æ–∏—Å–∫–∞
        target_price = target_property.get('price', 100_000_000)
        target_area = target_property.get('total_area', 100)
        target_rooms = target_property.get('rooms', 2)

        # –°—Ç—Ä–æ–∏–º URL –ø–æ–∏—Å–∫–∞
        search_params = {
            'deal_type': 'sale',
            'offer_type': 'flat',
            'engine_version': '2',
            'price_min': int(target_price * 0.5),
            'price_max': int(target_price * 1.5),
            'minArea': int(target_area * 0.6),
            'maxArea': int(target_area * 1.4),
            'region': '2',  # –°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥ (–Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç—Å—è)
        }

        # –ö–æ–º–Ω–∞—Ç—ã (–¥–∏–∞–ø–∞–∑–æ–Ω ¬±1)
        rooms_min = max(1, target_rooms - 1)
        rooms_max = target_rooms + 1
        for i in range(rooms_min, rooms_max + 1):
            search_params[f'room{i}'] = '1'

        url = f"{self.base_url}/cat.php?" + '&'.join([f"{k}={v}" for k, v in search_params.items()])

        logger.info(f"URL –ø–æ–∏—Å–∫–∞: {url}")

        # –ü–∞—Ä—Å–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        results = self.parse_search_page(url)

        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
        limited_results = results[:limit]

        logger.info(f"‚úì –ù–∞–π–¥–µ–Ω–æ {len(limited_results)} –ø–æ—Ö–æ–∂–∏—Ö –æ–±—ä—è–≤–ª–µ–Ω–∏–π")

        return limited_results
