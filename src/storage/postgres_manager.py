"""
PostgreSQL Manager –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –∞–Ω–∞–ª–∏–∑–∞ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏
–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –∞–Ω–∞–ª–∏–∑–æ–≤, –º–µ—Ç—Ä–∏–∫–∏, —Ç—Ä–µ–Ω–¥—ã
"""

import os
import logging
from typing import Dict, List, Optional, Any
from datetime import datetime, timedelta
import json

try:
    import psycopg2
    from psycopg2.extras import RealDictCursor, Json
    from psycopg2.pool import SimpleConnectionPool
    POSTGRES_AVAILABLE = True
except ImportError:
    POSTGRES_AVAILABLE = False

logger = logging.getLogger(__name__)


class PostgresManager:
    """
    –ú–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å PostgreSQL

    Features:
    - Connection pooling
    - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ —Å—Ö–µ–º—ã
    - –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–æ–≤
    - –ò—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    - –¢—Ä–µ–Ω–¥—ã —Ä—ã–Ω–∫–∞
    """

    def __init__(
        self,
        host: str = None,
        port: int = None,
        database: str = None,
        user: str = None,
        password: str = None,
        min_conn: int = 1,
        max_conn: int = 10
    ):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è PostgreSQL –∫–ª–∏–µ–Ω—Ç–∞

        Args:
            host: PostgreSQL host (default: localhost –∏–ª–∏ POSTGRES_HOST)
            port: PostgreSQL port (default: 5432 –∏–ª–∏ POSTGRES_PORT)
            database: Database name (default: cian_analyzer –∏–ª–∏ POSTGRES_DB)
            user: PostgreSQL user (default: postgres –∏–ª–∏ POSTGRES_USER)
            password: PostgreSQL password (–∏–∑ env POSTGRES_PASSWORD)
            min_conn: –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª-–≤–æ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π –≤ –ø—É–ª–µ
            max_conn: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª-–≤–æ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π –≤ –ø—É–ª–µ
        """
        if not POSTGRES_AVAILABLE:
            raise ImportError(
                "psycopg2 –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install psycopg2-binary"
            )

        self.host = host or os.getenv('POSTGRES_HOST', 'localhost')
        self.port = int(port or os.getenv('POSTGRES_PORT', 5432))
        self.database = database or os.getenv('POSTGRES_DB', 'cian_analyzer')
        self.user = user or os.getenv('POSTGRES_USER', 'postgres')
        self.password = password or os.getenv('POSTGRES_PASSWORD', '')

        self.connection_pool = None
        self._initialize_pool(min_conn, max_conn)
        self._create_schema()

    def _initialize_pool(self, min_conn: int, max_conn: int):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—É–ª–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π"""
        try:
            self.connection_pool = SimpleConnectionPool(
                min_conn,
                max_conn,
                host=self.host,
                port=self.port,
                database=self.database,
                user=self.user,
                password=self.password
            )
            logger.info(f"‚úÖ PostgreSQL –ø–æ–¥–∫–ª—é—á–µ–Ω: {self.host}:{self.port}/{self.database}")

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ PostgreSQL: {e}")
            raise

    def _get_connection(self):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è –∏–∑ –ø—É–ª–∞"""
        return self.connection_pool.getconn()

    def _put_connection(self, conn):
        """–í–æ–∑–≤—Ä–∞—Ç —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è –≤ –ø—É–ª"""
        self.connection_pool.putconn(conn)

    def _create_schema(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Å—Ö–µ–º—ã –ë–î –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç"""
        conn = None
        try:
            conn = self._get_connection()
            cursor = conn.cursor()

            # –¢–∞–±–ª–∏—Ü–∞ –∞–Ω–∞–ª–∏–∑–æ–≤
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS analyses (
                    id SERIAL PRIMARY KEY,
                    session_id VARCHAR(255) UNIQUE NOT NULL,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,

                    -- –¶–µ–ª–µ–≤–æ–π –æ–±—ä–µ–∫—Ç
                    target_url TEXT NOT NULL,
                    target_price BIGINT,
                    target_area DECIMAL(10, 2),
                    target_rooms INTEGER,
                    target_floor INTEGER,
                    target_total_floors INTEGER,
                    target_address TEXT,
                    target_metro TEXT,
                    target_data JSONB,

                    -- –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞
                    fair_price BIGINT,
                    fair_price_per_sqm INTEGER,
                    median_price_per_sqm INTEGER,
                    comparables_count INTEGER,
                    filtered_comparables_count INTEGER,

                    -- –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
                    recommendations JSONB,
                    recommendations_count INTEGER,

                    -- –°—Ü–µ–Ω–∞—Ä–∏–∏
                    price_scenarios JSONB,

                    -- –ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ (backup)
                    analysis_result JSONB,

                    -- –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
                    user_ip VARCHAR(45),
                    user_agent TEXT,
                    duration_seconds DECIMAL(10, 2)
                );
            """)

            # –ò–Ω–¥–µ–∫—Å—ã –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
            cursor.execute("""
                CREATE INDEX IF NOT EXISTS idx_analyses_session_id
                ON analyses(session_id);
            """)
            cursor.execute("""
                CREATE INDEX IF NOT EXISTS idx_analyses_created_at
                ON analyses(created_at DESC);
            """)
            cursor.execute("""
                CREATE INDEX IF NOT EXISTS idx_analyses_target_url
                ON analyses(target_url);
            """)
            cursor.execute("""
                CREATE INDEX IF NOT EXISTS idx_analyses_target_address
                ON analyses USING gin(to_tsvector('russian', target_address));
            """)

            # –¢–∞–±–ª–∏—Ü–∞ —Ü–µ–Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –ø–æ —Ä—ã–Ω–∫—É (–¥–ª—è —Ç—Ä–µ–Ω–¥–æ–≤)
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS market_data (
                    id SERIAL PRIMARY KEY,
                    recorded_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,

                    -- –õ–æ–∫–∞—Ü–∏—è
                    city VARCHAR(100),
                    district VARCHAR(200),
                    metro VARCHAR(200),

                    -- –ü–∞—Ä–∞–º–µ—Ç—Ä—ã
                    rooms INTEGER,
                    area_min DECIMAL(10, 2),
                    area_max DECIMAL(10, 2),

                    -- –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
                    median_price_per_sqm INTEGER,
                    mean_price_per_sqm INTEGER,
                    std_dev INTEGER,
                    sample_size INTEGER,

                    -- –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
                    source VARCHAR(50) DEFAULT 'cian',
                    data JSONB
                );
            """)

            cursor.execute("""
                CREATE INDEX IF NOT EXISTS idx_market_data_recorded_at
                ON market_data(recorded_at DESC);
            """)
            cursor.execute("""
                CREATE INDEX IF NOT EXISTS idx_market_data_location
                ON market_data(city, district, metro);
            """)

            # –¢–∞–±–ª–∏—Ü–∞ –ø–∞—Ä—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤ (–∫—ç—à)
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS parsed_properties (
                    id SERIAL PRIMARY KEY,
                    url TEXT UNIQUE NOT NULL,
                    parsed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,

                    -- –û—Å–Ω–æ–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
                    price BIGINT,
                    price_per_sqm INTEGER,
                    total_area DECIMAL(10, 2),
                    rooms INTEGER,
                    floor INTEGER,
                    total_floors INTEGER,

                    -- –ü–æ–ª–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
                    property_data JSONB,

                    -- TTL –¥–ª—è –∫—ç—à–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
                    expires_at TIMESTAMP,

                    -- –ú–µ—Ç—Ä–∏–∫–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞
                    parse_duration_seconds DECIMAL(10, 2),
                    parser_type VARCHAR(50)
                );
            """)

            cursor.execute("""
                CREATE INDEX IF NOT EXISTS idx_parsed_properties_url
                ON parsed_properties(url);
            """)
            cursor.execute("""
                CREATE INDEX IF NOT EXISTS idx_parsed_properties_expires_at
                ON parsed_properties(expires_at);
            """)

            conn.commit()
            logger.info("‚úÖ –°—Ö–µ–º–∞ –ë–î —Å–æ–∑–¥–∞–Ω–∞/–ø—Ä–æ–≤–µ—Ä–µ–Ω–∞")

        except Exception as e:
            if conn:
                conn.rollback()
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Å—Ö–µ–º—ã: {e}")
            raise
        finally:
            if conn:
                self._put_connection(conn)

    def save_analysis(
        self,
        session_id: str,
        target_property: Dict,
        analysis_result: Dict,
        metadata: Optional[Dict] = None
    ) -> Optional[int]:
        """
        –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞

        Args:
            session_id: ID —Å–µ—Å—Å–∏–∏
            target_property: –î–∞–Ω–Ω—ã–µ —Ü–µ–ª–µ–≤–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞
            analysis_result: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞
            metadata: –î–æ–ø. –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ (user_ip, user_agent, duration)

        Returns:
            ID –∑–∞–ø–∏—Å–∏ –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ
        """
        conn = None
        try:
            conn = self._get_connection()
            cursor = conn.cursor()

            metadata = metadata or {}

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ –ø–æ–ª—è
            fair_price_data = analysis_result.get('fair_price_analysis', {})
            market_stats = analysis_result.get('market_statistics', {})
            recommendations = analysis_result.get('recommendations', [])
            price_scenarios = analysis_result.get('price_scenarios', [])

            cursor.execute("""
                INSERT INTO analyses (
                    session_id,
                    target_url, target_price, target_area, target_rooms,
                    target_floor, target_total_floors, target_address, target_metro,
                    target_data,
                    fair_price, fair_price_per_sqm, median_price_per_sqm,
                    comparables_count, filtered_comparables_count,
                    recommendations, recommendations_count,
                    price_scenarios,
                    analysis_result,
                    user_ip, user_agent, duration_seconds
                ) VALUES (
                    %s, %s, %s, %s, %s, %s, %s, %s, %s, %s,
                    %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s
                )
                ON CONFLICT (session_id) DO UPDATE SET
                    updated_at = CURRENT_TIMESTAMP,
                    analysis_result = EXCLUDED.analysis_result,
                    fair_price = EXCLUDED.fair_price,
                    recommendations = EXCLUDED.recommendations
                RETURNING id;
            """, (
                session_id,
                target_property.get('url'),
                target_property.get('price'),
                target_property.get('total_area'),
                target_property.get('rooms'),
                target_property.get('floor'),
                target_property.get('total_floors'),
                target_property.get('address'),
                ','.join(target_property.get('metro', [])) if isinstance(target_property.get('metro'), list) else target_property.get('metro'),
                Json(target_property),
                fair_price_data.get('final_fair_price'),
                fair_price_data.get('final_fair_price_per_sqm'),
                market_stats.get('median_price_per_sqm'),
                len(analysis_result.get('comparables', [])),
                len(analysis_result.get('filtered_comparables', [])),
                Json(recommendations),
                len(recommendations),
                Json(price_scenarios),
                Json(analysis_result),
                metadata.get('user_ip'),
                metadata.get('user_agent'),
                metadata.get('duration_seconds')
            ))

            analysis_id = cursor.fetchone()[0]
            conn.commit()

            logger.info(f"‚úÖ –ê–Ω–∞–ª–∏–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: ID={analysis_id}, session={session_id}")
            return analysis_id

        except Exception as e:
            if conn:
                conn.rollback()
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∞–Ω–∞–ª–∏–∑–∞: {e}")
            return None
        finally:
            if conn:
                self._put_connection(conn)

    def get_analysis(self, session_id: str) -> Optional[Dict]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞ –ø–æ session_id

        Args:
            session_id: ID —Å–µ—Å—Å–∏–∏

        Returns:
            –î–∞–Ω–Ω—ã–µ –∞–Ω–∞–ª–∏–∑–∞ –∏–ª–∏ None
        """
        conn = None
        try:
            conn = self._get_connection()
            cursor = conn.cursor(cursor_factory=RealDictCursor)

            cursor.execute("""
                SELECT * FROM analyses WHERE session_id = %s;
            """, (session_id,))

            result = cursor.fetchone()
            return dict(result) if result else None

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∞–Ω–∞–ª–∏–∑–∞: {e}")
            return None
        finally:
            if conn:
                self._put_connection(conn)

    def get_recent_analyses(self, limit: int = 50) -> List[Dict]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –∞–Ω–∞–ª–∏–∑–æ–≤

        Args:
            limit: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π

        Returns:
            –°–ø–∏—Å–æ–∫ –∞–Ω–∞–ª–∏–∑–æ–≤
        """
        conn = None
        try:
            conn = self._get_connection()
            cursor = conn.cursor(cursor_factory=RealDictCursor)

            cursor.execute("""
                SELECT
                    id, session_id, created_at,
                    target_url, target_price, target_area, target_rooms,
                    target_address, target_metro,
                    fair_price, fair_price_per_sqm, median_price_per_sqm,
                    comparables_count, recommendations_count
                FROM analyses
                ORDER BY created_at DESC
                LIMIT %s;
            """, (limit,))

            results = cursor.fetchall()
            return [dict(r) for r in results]

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∞–Ω–∞–ª–∏–∑–æ–≤: {e}")
            return []
        finally:
            if conn:
                self._put_connection(conn)

    def search_analyses(
        self,
        city: str = None,
        district: str = None,
        metro: str = None,
        rooms: int = None,
        date_from: datetime = None,
        date_to: datetime = None,
        limit: int = 50
    ) -> List[Dict]:
        """
        –ü–æ–∏—Å–∫ –∞–Ω–∞–ª–∏–∑–æ–≤ –ø–æ –∫—Ä–∏—Ç–µ—Ä–∏—è–º

        Args:
            city: –ì–æ—Ä–æ–¥
            district: –†–∞–π–æ–Ω
            metro: –ú–µ—Ç—Ä–æ
            rooms: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–º–Ω–∞—Ç
            date_from: –î–∞—Ç–∞ –æ—Ç
            date_to: –î–∞—Ç–∞ –¥–æ
            limit: –õ–∏–º–∏—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

        Returns:
            –°–ø–∏—Å–æ–∫ –∞–Ω–∞–ª–∏–∑–æ–≤
        """
        conn = None
        try:
            conn = self._get_connection()
            cursor = conn.cursor(cursor_factory=RealDictCursor)

            query = "SELECT * FROM analyses WHERE 1=1"
            params = []

            if city:
                query += " AND target_address ILIKE %s"
                params.append(f"%{city}%")

            if district:
                query += " AND target_address ILIKE %s"
                params.append(f"%{district}%")

            if metro:
                query += " AND target_metro ILIKE %s"
                params.append(f"%{metro}%")

            if rooms:
                query += " AND target_rooms = %s"
                params.append(rooms)

            if date_from:
                query += " AND created_at >= %s"
                params.append(date_from)

            if date_to:
                query += " AND created_at <= %s"
                params.append(date_to)

            query += " ORDER BY created_at DESC LIMIT %s"
            params.append(limit)

            cursor.execute(query, params)
            results = cursor.fetchall()
            return [dict(r) for r in results]

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –∞–Ω–∞–ª–∏–∑–æ–≤: {e}")
            return []
        finally:
            if conn:
                self._put_connection(conn)

    def save_market_data(
        self,
        city: str,
        district: str,
        metro: str,
        rooms: int,
        area_range: tuple,
        statistics: Dict
    ) -> bool:
        """
        –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä—ã–Ω–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç—Ä–µ–Ω–¥–æ–≤

        Args:
            city: –ì–æ—Ä–æ–¥
            district: –†–∞–π–æ–Ω
            metro: –°—Ç–∞–Ω—Ü–∏—è –º–µ—Ç—Ä–æ
            rooms: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–º–Ω–∞—Ç
            area_range: (min_area, max_area)
            statistics: –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ (median, mean, std_dev, sample_size)

        Returns:
            True –µ—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ
        """
        conn = None
        try:
            conn = self._get_connection()
            cursor = conn.cursor()

            cursor.execute("""
                INSERT INTO market_data (
                    city, district, metro, rooms,
                    area_min, area_max,
                    median_price_per_sqm, mean_price_per_sqm,
                    std_dev, sample_size,
                    data
                ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s);
            """, (
                city,
                district,
                metro,
                rooms,
                area_range[0],
                area_range[1],
                statistics.get('median_price_per_sqm'),
                statistics.get('mean_price_per_sqm'),
                statistics.get('std_dev'),
                statistics.get('sample_size'),
                Json(statistics)
            ))

            conn.commit()
            logger.debug(f"üìä –†—ã–Ω–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {city}, {district}, {metro}")
            return True

        except Exception as e:
            if conn:
                conn.rollback()
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä—ã–Ω–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö: {e}")
            return False
        finally:
            if conn:
                self._put_connection(conn)

    def get_market_trends(
        self,
        city: str,
        district: str = None,
        metro: str = None,
        rooms: int = None,
        days: int = 30
    ) -> List[Dict]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ —Ç—Ä–µ–Ω–¥–æ–≤ —Ä—ã–Ω–∫–∞ –∑–∞ –ø–µ—Ä–∏–æ–¥

        Args:
            city: –ì–æ—Ä–æ–¥
            district: –†–∞–π–æ–Ω (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            metro: –ú–µ—Ç—Ä–æ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            rooms: –ö–æ–ª-–≤–æ –∫–æ–º–Ω–∞—Ç (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            days: –ü–µ—Ä–∏–æ–¥ –≤ –¥–Ω—è—Ö

        Returns:
            –°–ø–∏—Å–æ–∫ –¥–∞–Ω–Ω—ã—Ö —Å —Ç—Ä–µ–Ω–¥–∞–º–∏
        """
        conn = None
        try:
            conn = self._get_connection()
            cursor = conn.cursor(cursor_factory=RealDictCursor)

            query = """
                SELECT * FROM market_data
                WHERE city = %s
                AND recorded_at >= %s
            """
            params = [city, datetime.now() - timedelta(days=days)]

            if district:
                query += " AND district = %s"
                params.append(district)

            if metro:
                query += " AND metro = %s"
                params.append(metro)

            if rooms:
                query += " AND rooms = %s"
                params.append(rooms)

            query += " ORDER BY recorded_at ASC"

            cursor.execute(query, params)
            results = cursor.fetchall()
            return [dict(r) for r in results]

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ç—Ä–µ–Ω–¥–æ–≤: {e}")
            return []
        finally:
            if conn:
                self._put_connection(conn)

    def cache_parsed_property(
        self,
        url: str,
        property_data: Dict,
        ttl_hours: int = 24,
        parser_type: str = 'playwright',
        duration: float = None
    ) -> bool:
        """
        –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞—Ä—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞

        Args:
            url: URL –æ–±—ä–µ–∫—Ç–∞
            property_data: –î–∞–Ω–Ω—ã–µ –æ–±—ä–µ–∫—Ç–∞
            ttl_hours: –í—Ä–µ–º—è –∂–∏–∑–Ω–∏ –∫—ç—à–∞ –≤ —á–∞—Å–∞—Ö
            parser_type: –¢–∏–ø –ø–∞—Ä—Å–µ—Ä–∞
            duration: –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø–∞—Ä—Å–∏–Ω–≥–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö

        Returns:
            True –µ—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ
        """
        conn = None
        try:
            conn = self._get_connection()
            cursor = conn.cursor()

            expires_at = datetime.now() + timedelta(hours=ttl_hours)

            cursor.execute("""
                INSERT INTO parsed_properties (
                    url, price, price_per_sqm, total_area, rooms,
                    floor, total_floors, property_data, expires_at,
                    parser_type, parse_duration_seconds
                ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                ON CONFLICT (url) DO UPDATE SET
                    updated_at = CURRENT_TIMESTAMP,
                    property_data = EXCLUDED.property_data,
                    expires_at = EXCLUDED.expires_at;
            """, (
                url,
                property_data.get('price'),
                property_data.get('price_per_sqm'),
                property_data.get('total_area'),
                property_data.get('rooms'),
                property_data.get('floor'),
                property_data.get('total_floors'),
                Json(property_data),
                expires_at,
                parser_type,
                duration
            ))

            conn.commit()
            logger.debug(f"üíæ –û–±—ä–µ–∫—Ç –∑–∞–∫—ç—à–∏—Ä–æ–≤–∞–Ω: {url}")
            return True

        except Exception as e:
            if conn:
                conn.rollback()
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è –æ–±—ä–µ–∫—Ç–∞: {e}")
            return False
        finally:
            if conn:
                self._put_connection(conn)

    def get_cached_property(self, url: str) -> Optional[Dict]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ –∑–∞–∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞

        Args:
            url: URL –æ–±—ä–µ–∫—Ç–∞

        Returns:
            –î–∞–Ω–Ω—ã–µ –æ–±—ä–µ–∫—Ç–∞ –∏–ª–∏ None –µ—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω/–∏—Å—Ç–µ–∫
        """
        conn = None
        try:
            conn = self._get_connection()
            cursor = conn.cursor(cursor_factory=RealDictCursor)

            cursor.execute("""
                SELECT property_data, parsed_at
                FROM parsed_properties
                WHERE url = %s
                AND (expires_at IS NULL OR expires_at > CURRENT_TIMESTAMP);
            """, (url,))

            result = cursor.fetchone()
            if result:
                logger.debug(f"üíæ –û–±—ä–µ–∫—Ç –ø–æ–ª—É—á–µ–Ω –∏–∑ –∫—ç—à–∞: {url}")
                return result['property_data']
            return None

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∫—ç—à–∞: {e}")
            return None
        finally:
            if conn:
                self._put_connection(conn)

    def cleanup_expired_cache(self) -> int:
        """
        –û—á–∏—Å—Ç–∫–∞ –∏—Å—Ç–µ–∫—à–µ–≥–æ –∫—ç—à–∞

        Returns:
            –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–¥–∞–ª–µ–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π
        """
        conn = None
        try:
            conn = self._get_connection()
            cursor = conn.cursor()

            cursor.execute("""
                DELETE FROM parsed_properties
                WHERE expires_at IS NOT NULL
                AND expires_at < CURRENT_TIMESTAMP;
            """)

            deleted_count = cursor.rowcount
            conn.commit()

            logger.info(f"üßπ –£–¥–∞–ª–µ–Ω–æ –∏—Å—Ç–µ–∫—à–∏—Ö –æ–±—ä–µ–∫—Ç–æ–≤: {deleted_count}")
            return deleted_count

        except Exception as e:
            if conn:
                conn.rollback()
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –∫—ç—à–∞: {e}")
            return 0
        finally:
            if conn:
                self._put_connection(conn)

    def get_stats(self) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ë–î

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π
        """
        conn = None
        try:
            conn = self._get_connection()
            cursor = conn.cursor(cursor_factory=RealDictCursor)

            stats = {}

            # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞–Ω–∞–ª–∏–∑–æ–≤
            cursor.execute("SELECT COUNT(*) as count FROM analyses;")
            stats['total_analyses'] = cursor.fetchone()['count']

            # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 24 —á–∞—Å–∞
            cursor.execute("""
                SELECT COUNT(*) as count FROM analyses
                WHERE created_at >= CURRENT_TIMESTAMP - INTERVAL '24 hours';
            """)
            stats['analyses_24h'] = cursor.fetchone()['count']

            # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä—ã–Ω–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            cursor.execute("SELECT COUNT(*) as count FROM market_data;")
            stats['market_data_count'] = cursor.fetchone()['count']

            # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤
            cursor.execute("""
                SELECT COUNT(*) as count FROM parsed_properties
                WHERE expires_at > CURRENT_TIMESTAMP OR expires_at IS NULL;
            """)
            stats['cached_properties'] = cursor.fetchone()['count']

            # –°—Ä–µ–¥–Ω—è—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø–∞—Ä—Å–∏–Ω–≥–∞
            cursor.execute("""
                SELECT AVG(parse_duration_seconds) as avg_duration
                FROM parsed_properties
                WHERE parse_duration_seconds IS NOT NULL;
            """)
            result = cursor.fetchone()
            stats['avg_parse_duration'] = float(result['avg_duration'] or 0)

            return stats

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
            return {}
        finally:
            if conn:
                self._put_connection(conn)

    def close(self):
        """–ó–∞–∫—Ä—ã—Ç–∏–µ –≤—Å–µ—Ö —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π"""
        if self.connection_pool:
            self.connection_pool.closeall()
            logger.info("üîå PostgreSQL —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è –∑–∞–∫—Ä—ã—Ç—ã")


# Singleton instance
_postgres_manager: Optional[PostgresManager] = None


def get_postgres_manager(
    host: str = None,
    port: int = None,
    database: str = None,
    user: str = None,
    password: str = None
) -> PostgresManager:
    """
    –ü–æ–ª—É—á–µ–Ω–∏–µ singleton instance PostgreSQL –º–µ–Ω–µ–¥–∂–µ—Ä–∞

    Args:
        host: PostgreSQL host
        port: PostgreSQL port
        database: Database name
        user: PostgreSQL user
        password: PostgreSQL password

    Returns:
        PostgresManager instance
    """
    global _postgres_manager

    if _postgres_manager is None:
        _postgres_manager = PostgresManager(
            host=host,
            port=port,
            database=database,
            user=user,
            password=password
        )

    return _postgres_manager
