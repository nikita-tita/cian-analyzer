#!/usr/bin/env python3
"""
Cian.ru Parser —Å –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ–º –ø–æ—Ö–æ–∂–∏—Ö –æ–±—ä—è–≤–ª–µ–Ω–∏–π —á–µ—Ä–µ–∑ –ø–æ–∏—Å–∫ –ø–æ –∞–¥—Ä–µ—Å—É
"""

from playwright.sync_api import sync_playwright, Page
from typing import Dict, List, Optional
import logging
import time
import random
import re
import urllib.parse

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class CianParserWithSimilar:
    """
    –ü–∞—Ä—Å–µ—Ä —Å –ø–æ–∏—Å–∫–æ–º –ø–æ—Ö–æ–∂–∏—Ö –æ–±—ä—è–≤–ª–µ–Ω–∏–π –≤ —Ç–æ–º –∂–µ –¥–æ–º–µ
    """

    def __init__(self, headless: bool = True):
        self.headless = headless
        self.playwright = None
        self.browser = None
        self.context = None

    def __enter__(self):
        """Context manager entry"""
        self.playwright = sync_playwright().start()
        
        logger.info("üöÄ –ó–∞–ø—É—Å–∫ stealth –±—Ä–∞—É–∑–µ—Ä–∞...")
        
        self.browser = self.playwright.chromium.launch(
            headless=self.headless,
            args=[
                '--disable-blink-features=AutomationControlled',
                '--disable-dev-shm-usage',
                '--no-sandbox',
            ]
        )

        self.context = self.browser.new_context(
            user_agent='Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36',
            viewport={'width': 1920, 'height': 1080},
            locale='ru-RU',
            timezone_id='Europe/Moscow',
            extra_http_headers={
                'Accept-Language': 'ru-RU,ru;q=0.9,en-US;q=0.8,en;q=0.7',
            }
        )

        self.context.add_init_script("""
            Object.defineProperty(navigator, 'webdriver', {
                get: () => undefined
            });
            window.chrome = { runtime: {} };
        """)

        logger.info("‚úÖ –ë—Ä–∞—É–∑–µ—Ä –≥–æ—Ç–æ–≤")
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        if self.context:
            self.context.close()
        if self.browser:
            self.browser.close()
        if self.playwright:
            self.playwright.stop()

    def _extract_characteristics(self, page: Page) -> Dict[str, str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫"""
        characteristics = {}

        try:
            items = page.locator('[data-testid="OfferSummaryInfoItem"]').all()
            
            for item in items:
                try:
                    paragraphs = item.locator('p').all()
                    if len(paragraphs) >= 2:
                        key = paragraphs[0].text_content().strip()
                        value = paragraphs[1].text_content().strip()
                        if key and value:
                            characteristics[key] = value
                except:
                    pass

            # –≠—Ç–∞–∂ –∏–∑ meta
            try:
                og_title = page.locator('meta[property="og:title"]').first
                if og_title:
                    content = og_title.get_attribute('content')
                    if content:
                        floor_match = re.search(r'—ç—Ç–∞–∂ (\d+/\d+)', content, re.IGNORECASE)
                        if floor_match:
                            characteristics['–≠—Ç–∞–∂'] = floor_match.group(1)
            except:
                pass

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫: {e}")

        return characteristics

    def _search_similar_by_address(self, address: str, city: str = "–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥") -> List[Dict]:
        """
        –ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö –æ–±—ä—è–≤–ª–µ–Ω–∏–π —á–µ—Ä–µ–∑ –ø–æ–∏—Å–∫ –ø–æ –∞–¥—Ä–µ—Å—É
        """
        similar = []
        
        try:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —É–ª–∏—Ü—É –∏–∑ –∞–¥—Ä–µ—Å–∞
            # –ü—Ä–∏–º–µ—Ä: "–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥, —Ä-–Ω –í—ã–±–æ—Ä–≥—Å–∫–∏–π, –°–≤–µ—Ç–ª–∞–Ω–æ–≤—Å–∫–æ–µ, –°–≤–µ—Ç–ª–∞–Ω–æ–≤—Å–∫–∏–π –ø—Ä-–∫—Ç, 60–∫2"
            street_match = re.search(r'([–ê-–Ø–∞-—è—ë–Å\s-]+(?:—É–ª\.|—É–ª–∏—Ü–∞|–ø—Ä-–∫—Ç|–ø—Ä–æ—Å–ø–µ–∫—Ç|–Ω–∞–±\.|–Ω–∞–±–µ—Ä–µ–∂–Ω–∞—è)[\s,]+[\d–∫–ö\s-]+)', address)
            
            if not street_match:
                # –ü—Ä–æ–±—É–µ–º –±–æ–ª–µ–µ –ø—Ä–æ—Å—Ç–æ–π –ø–∞—Ç—Ç–µ—Ä–Ω
                parts = address.split(',')
                if len(parts) >= 3:
                    street_part = parts[-1].strip()
                else:
                    return similar
            else:
                street_part = street_match.group(1).strip()
            
            logger.info(f"üîç –ü–æ–∏—Å–∫ –æ–±—ä—è–≤–ª–µ–Ω–∏–π –ø–æ –∞–¥—Ä–µ—Å—É: {street_part}")
            
            # –°–æ–∑–¥–∞–µ–º URL –¥–ª—è –ø–æ–∏—Å–∫–∞
            search_query = f"{city} {street_part}"
            encoded_query = urllib.parse.quote(search_query)
            
            # URL –ø–æ–∏—Å–∫–∞ –Ω–∞ Cian
            search_url = f"https://www.cian.ru/cat.php?deal_type=sale&engine_version=2&offer_type=flat&region=2&text={encoded_query}"
            
            page = self.context.new_page()
            page.goto(search_url, wait_until='domcontentloaded', timeout=30000)
            time.sleep(2)
            
            # –ò—â–µ–º –∫–∞—Ä—Ç–æ—á–∫–∏ –æ–±—ä—è–≤–ª–µ–Ω–∏–π
            cards = page.locator('[data-name="CardComponent"], [data-name="OfferCard"], article').all()
            
            logger.info(f"   –ù–∞–π–¥–µ–Ω–æ –∫–∞—Ä—Ç–æ—á–µ–∫ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ –ø–æ–∏—Å–∫–∞: {len(cards)}")
            
            for card in cards[:10]:  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 10
                try:
                    listing = {}
                    
                    # –ó–∞–≥–æ–ª–æ–≤–æ–∫
                    title_elem = card.locator('h3, [data-mark="OfferTitle"], a[class*="title"]').first
                    if title_elem:
                        listing['title'] = title_elem.text_content().strip()
                    
                    # –¶–µ–Ω–∞
                    price_elem = card.locator('[data-mark="MainPrice"], span[class*="price"]').first
                    if price_elem:
                        listing['price'] = price_elem.text_content().strip()
                    
                    # URL
                    link_elem = card.locator('a[href*="/sale/flat/"]').first
                    if link_elem:
                        href = link_elem.get_attribute('href')
                        if href:
                            listing['url'] = href if href.startswith('http') else f"https://www.cian.ru{href}"
                    
                    # –ü–ª–æ—â–∞–¥—å –∏ —ç—Ç–∞–∂ –∏–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞ –∏–ª–∏ –æ–ø–∏—Å–∞–Ω–∏—è
                    if 'title' in listing:
                        area_match = re.search(r'(\d+[,.]?\d*)\s*–º¬≤', listing['title'])
                        if area_match:
                            listing['area'] = area_match.group(0)
                        
                        floor_match = re.search(r'(\d+)/(\d+)\s*—ç—Ç', listing['title'])
                        if floor_match:
                            listing['floor'] = f"{floor_match.group(1)}/{floor_match.group(2)}"
                    
                    if listing.get('title') and listing.get('price'):
                        similar.append(listing)
                
                except Exception as e:
                    continue
            
            page.close()
            
            logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ –ø–æ—Ö–æ–∂–∏—Ö –æ–±—ä—è–≤–ª–µ–Ω–∏–π: {len(similar)}")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –ø–æ—Ö–æ–∂–∏—Ö: {e}")
        
        return similar

    def parse_detail_page_full(self, url: str) -> Dict:
        """
        –ü–æ–ª–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ —Å –ø–æ–∏—Å–∫–æ–º –ø–æ—Ö–æ–∂–∏—Ö –æ–±—ä—è–≤–ª–µ–Ω–∏–π
        """
        result = {
            'url': url,
            'title': None,
            'price': None,
            'price_raw': None,
            'currency': 'RUB',
            'address': None,
            'metro': [],
            'characteristics': {},
            'images': [],
            'description': None,
            'similar_listings': [],
        }

        try:
            page = self.context.new_page()
            
            logger.info(f"üìÑ –ó–∞–≥—Ä—É–∑–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã: {url}")
            
            time.sleep(random.uniform(0.5, 1.5))
            page.goto(url, wait_until='domcontentloaded', timeout=60000)
            
            try:
                page.wait_for_selector('h1', timeout=10000)
            except:
                pass

            time.sleep(2)

            # –ó–∞–≥–æ–ª–æ–≤–æ–∫
            try:
                h1 = page.locator('h1').first
                if h1:
                    result['title'] = h1.text_content().strip()
            except:
                pass

            # –¶–µ–Ω–∞
            try:
                price_selectors = [
                    '[data-testid="price-amount"]',
                    '[data-name="PriceInfo"]',
                ]
                for selector in price_selectors:
                    price_elem = page.locator(selector).first
                    if price_elem:
                        price_text = price_elem.text_content()
                        result['price'] = price_text.strip()
                        price_match = re.search(r'(\d+[\s\d]*)', price_text.replace(' ', ''))
                        if price_match:
                            result['price_raw'] = int(price_match.group(1).replace(' ', ''))
                        break
            except:
                pass

            # –ê–¥—Ä–µ—Å
            try:
                address_elem = page.locator('[data-name="Geo"]').first
                if address_elem:
                    result['address'] = address_elem.text_content().strip()
            except:
                pass

            # –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
            logger.info("üìä –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫...")
            result['characteristics'] = self._extract_characteristics(page)

            # –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            try:
                img_elements = page.locator('img[src*="cdn-cian.ru/images"]').all()
                images = []
                for img in img_elements[:30]:
                    src = img.get_attribute('src')
                    if src and src.startswith('http'):
                        images.append(src)
                result['images'] = list(dict.fromkeys(images))
            except:
                pass

            page.close()

            # –ü–û–ò–°–ö –ü–û–•–û–ñ–ò–• –û–ë–™–Ø–í–õ–ï–ù–ò–ô
            if result.get('address'):
                logger.info("üîç –ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö –æ–±—ä—è–≤–ª–µ–Ω–∏–π –≤ –¥–æ–º–µ...")
                result['similar_listings'] = self._search_similar_by_address(result['address'])

            logger.info(f"‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–æ: {len(result['characteristics'])} —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫, {len(result['similar_listings'])} –ø–æ—Ö–æ–∂–∏—Ö")

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞: {e}")
            result['error'] = str(e)

        return result


# Alias –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
CianParserStealth = CianParserWithSimilar
