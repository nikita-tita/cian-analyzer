"""
Housler - –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏
–í–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å —Å 3-—ç–∫—Ä–∞–Ω–Ω—ã–º wizard UX
"""

from flask import Flask, render_template, request, jsonify, session
import os
import uuid
import logging
from typing import Dict, List
from datetime import datetime
from flask_limiter import Limiter
from flask_limiter.util import get_remote_address
from flask_wtf.csrf import CSRFProtect

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# MULTI-SOURCE PARSER REGISTRY
# –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# –î–æ—Å—Ç—É–ø–Ω—ã–µ –ø–∞—Ä—Å–µ—Ä—ã:
#   ‚úÖ CianParser (–¶–ò–ê–ù) - –°–ü–± –∏ –ú–æ—Å–∫–≤–∞
#   ‚è≥ YandexParser (–Ø–Ω–¥–µ–∫—Å.–ù–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç—å) - –≤—Å—è –†–æ—Å—Å–∏—è [–≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ]
#   ‚è≥ DomClickParser (–î–æ–º–ö–ª–∏–∫/–°–±–µ—Ä–±–∞–Ω–∫) [–≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ]
#   ‚è≥ AvitoParser (–ê–≤–∏—Ç–æ) - –≤—Å—è –†–æ—Å—Å–∏—è [–≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ]
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

try:
    # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º registry
    from src.parsers import get_global_registry
    from src.parsers.playwright_parser import detect_region_from_url, detect_region_from_address
    from src.parsers.browser_pool import BrowserPool

    # –ü—ã—Ç–∞–µ–º—Å—è –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –ø–∞—Ä—Å–µ—Ä—ã
    parsers_loaded = []

    try:
        from src.parsers import CianParser
        parsers_loaded.append('–¶–ò–ê–ù')
    except ImportError as e:
        logger.warning(f"CianParser –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")

    try:
        from src.parsers.yandex_realty_parser import YandexParser
        parsers_loaded.append('–Ø–Ω–¥–µ–∫—Å.–ù–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç—å')
    except ImportError as e:
        logger.warning(f"YandexParser –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")

    try:
        from src.parsers.domclick_parser import DomClickParser
        parsers_loaded.append('–î–æ–º–ö–ª–∏–∫')
    except ImportError as e:
        logger.warning(f"DomClickParser –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")

    try:
        from src.parsers.avito_parser import AvitoParser
        parsers_loaded.append('–ê–≤–∏—Ç–æ')
    except ImportError as e:
        logger.warning(f"AvitoParser –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")

    PARSER_REGISTRY_AVAILABLE = True
    logger.info(f"‚úì Parser Registry: {', '.join(parsers_loaded) if parsers_loaded else '–Ω–µ—Ç –ø–∞—Ä—Å–µ—Ä–æ–≤'}")

except ImportError as e:
    logger.error(f"Failed to import ParserRegistry: {e}")
    # Fallback –Ω–∞ —Å—Ç–∞—Ä—ã–π PlaywrightParser
    try:
        from src.parsers.playwright_parser import PlaywrightParser, detect_region_from_url, detect_region_from_address
        from src.parsers.browser_pool import BrowserPool
        PARSER_REGISTRY_AVAILABLE = False
        logger.warning("‚ö†Ô∏è Fallback: Using legacy PlaywrightParser (—Ç–æ–ª—å–∫–æ –¶–ò–ê–ù)")
    except Exception as e2:
        logger.error(f"Playwright also not available: {e2}")
        from src.parsers.simple_parser import SimpleParser
        PARSER_REGISTRY_AVAILABLE = False
        BrowserPool = None
        def detect_region_from_url(url):
            return None
        def detect_region_from_address(address):
            return 'spb'  # fallback

# Check if Playwright is available for PDF generation
try:
    from playwright.sync_api import sync_playwright
    PLAYWRIGHT_AVAILABLE = True
except ImportError:
    PLAYWRIGHT_AVAILABLE = False
    logger.warning("Playwright –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω - PDF —ç–∫—Å–ø–æ—Ä—Ç –±—É–¥–µ—Ç –∑–∞–º–µ–Ω–µ–Ω –Ω–∞ Markdown")

from src.analytics.analyzer import RealEstateAnalyzer
from src.analytics.offer_generator import generate_housler_offer
from src.models.property import (
    TargetProperty,
    ComparableProperty,
    AnalysisRequest
)
from src.utils.session_storage import get_session_storage
from src.cache import init_cache, get_cache
from src.utils.duplicate_detector import DuplicateDetector

app = Flask(__name__)

# SECURITY: Secret key from environment (CRITICAL FIX)
# Generate with: openssl rand -hex 32
app.secret_key = os.getenv('SECRET_KEY')
if not app.secret_key:
    logger.error("SECRET_KEY not set in environment! Using temporary key for development only.")
    if os.getenv('FLASK_ENV') == 'production':
        raise RuntimeError('SECRET_KEY must be set in production environment')
    # Development fallback (will be different on each restart)
    app.secret_key = os.urandom(24)

# SECURITY: CSRF Protection (–∑–∞—â–∏—Ç–∞ –æ—Ç Cross-Site Request Forgery)
csrf = CSRFProtect(app)
# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ CSRF
app.config['WTF_CSRF_TIME_LIMIT'] = None  # Token doesn't expire (session-based)
app.config['WTF_CSRF_SSL_STRICT'] = os.getenv('FLASK_ENV') == 'production'
app.config['WTF_CSRF_METHODS'] = ['POST', 'PUT', 'PATCH', 'DELETE']
logger.info("CSRF protection enabled")

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Redis –∫—ç—à–∞
# –í –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –±–µ—Ä—É—Ç—Å—è –∏–∑ env –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
property_cache = init_cache(
    host=os.getenv('REDIS_HOST', 'localhost'),
    port=int(os.getenv('REDIS_PORT', 6379)),
    db=int(os.getenv('REDIS_DB', 0)),
    password=os.getenv('REDIS_PASSWORD'),
    namespace=os.getenv('REDIS_NAMESPACE', 'housler'),
    enabled=os.getenv('REDIS_ENABLED', 'false').lower() == 'true'
)

# –•—Ä–∞–Ω–∏–ª–∏—â–µ —Å–µ—Å—Å–∏–π —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π Redis
session_storage = get_session_storage()

# SECURITY & PERFORMANCE: Browser Pool –¥–ª—è –∫–æ–Ω—Ç—Ä–æ–ª—è —Ä–µ—Å—É—Ä—Å–æ–≤ Playwright
# –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ –æ—Ç–∫—Ä—ã—Ç—ã—Ö –±—Ä–∞—É–∑–µ—Ä–æ–≤
# –ó–∞—â–∏—â–∞–µ—Ç –æ—Ç DoS –∞—Ç–∞–∫ –∏ —É—Ç–µ—á–µ–∫ –ø–∞–º—è—Ç–∏
browser_pool = None
# –û—Ç–∫–ª—é—á–∞–µ–º browser pool –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–π —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ (–∫–æ–Ω—Ñ–ª–∏–∫—Ç —Å Flask debug mode)
use_browser_pool = os.getenv('USE_BROWSER_POOL', 'false').lower() == 'true'
if PARSER_REGISTRY_AVAILABLE and use_browser_pool:
    max_browsers = int(os.getenv('MAX_BROWSERS', '3'))  # Production: 3-5 –±—Ä–∞—É–∑–µ—Ä–æ–≤
    browser_pool = BrowserPool(
        max_browsers=max_browsers,
        max_age_seconds=3600,  # 1 —á–∞—Å
        headless=True,
        block_resources=True
    )
    browser_pool.start()
    logger.info(f"Browser pool initialized with max_browsers={max_browsers}")
else:
    logger.info("Browser pool disabled (for local dev or parsers not available)")

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# PARSER REGISTRY INITIALIZATION
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —Ä–µ–µ—Å—Ç—Ä –ø–∞—Ä—Å–µ—Ä–æ–≤ —Å –∫—ç—à–µ–º
parser_registry = None
if PARSER_REGISTRY_AVAILABLE:
    parser_registry = get_global_registry(cache=property_cache, delay=1.0)
    logger.info(f"‚úì Parser Registry –≥–æ—Ç–æ–≤ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é")
    logger.info(f"  –î–æ—Å—Ç—É–ø–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏: {', '.join(parser_registry.get_all_sources())}")
else:
    logger.warning("‚ö†Ô∏è Parser Registry –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω - –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è fallback")

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# DUPLICATE DETECTOR INITIALIZATION
# –î–µ—Ç–µ–∫—Ü–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –∞–Ω–∞–ª–æ–≥–æ–≤ –∏–∑ —Ä–∞–∑–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
duplicate_detector = DuplicateDetector(
    strict_price_tolerance=0.02,      # ¬±2% –¥–ª—è —Å—Ç—Ä–æ–≥–æ–≥–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
    probable_price_tolerance=0.10,    # ¬±10% –¥–ª—è –≤–µ—Ä–æ—è—Ç–Ω–æ–≥–æ –¥—É–±–ª–∏–∫–∞—Ç–∞
    possible_price_tolerance=0.15,    # ¬±15% –¥–ª—è –≤–æ–∑–º–æ–∂–Ω–æ–≥–æ –¥—É–±–ª–∏–∫–∞—Ç–∞
    area_tolerance=0.5,               # ¬±0.5 –º¬≤ –¥–ª—è —Å—Ç—Ä–æ–≥–æ–≥–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
    possible_area_tolerance=1.0       # ¬±1 –º¬≤ –¥–ª—è –≤–æ–∑–º–æ–∂–Ω–æ–≥–æ –¥—É–±–ª–∏–∫–∞—Ç–∞
)
logger.info("‚úì Duplicate Detector –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")


def get_parser_for_url(url: str, region: str = 'spb'):
    """
    –ü–æ–ª—É—á–∏—Ç—å –ø–∞—Ä—Å–µ—Ä –¥–ª—è –∑–∞–¥–∞–Ω–Ω–æ–≥–æ URL

    –ì–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–¥—Ö–æ–¥:
    - –î–ª—è –¶–ò–ê–ù: –∏—Å–ø–æ–ª—å–∑—É–µ–º PlaywrightParser —Å region –∏ browser_pool (—Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å)
    - –î–ª—è –æ—Å—Ç–∞–ª—å–Ω—ã—Ö: –∏—Å–ø–æ–ª—å–∑—É–µ–º parser_registry (–Ω–æ–≤–∞—è —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å)

    Args:
        url: URL –æ–±—ä—è–≤–ª–µ–Ω–∏—è
        region: –†–µ–≥–∏–æ–Ω (—Ç–æ–ª—å–∫–æ –¥–ª—è –¶–ò–ê–ù)

    Returns:
        –ü–∞—Ä—Å–µ—Ä —Å –º–µ—Ç–æ–¥–∞–º–∏ parse_detail_page() –∏ search_similar()
    """
    if not PARSER_REGISTRY_AVAILABLE:
        # Fallback: –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞—Ä—ã–π PlaywrightParser
        from src.parsers.playwright_parser import PlaywrightParser
        return PlaywrightParser(
            headless=True,
            delay=1.0,
            cache=property_cache,
            region=region,
            browser_pool=browser_pool
        )

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫
    source = parser_registry.detect_source(url) if parser_registry else None

    if source == 'cian':
        # –î–ª—è –¶–ò–ê–ù –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞—Ä—ã–π PlaywrightParser —Å –ø–æ–ª–Ω–æ–π –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π
        from src.parsers.playwright_parser import PlaywrightParser
        return PlaywrightParser(
            headless=True,
            delay=1.0,
            cache=property_cache,
            region=region,
            browser_pool=browser_pool
        )
    elif source:
        # –î–ª—è –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º registry
        parser = parser_registry.get_parser(url=url)
        if parser:
            logger.info(f"‚úì –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø–∞—Ä—Å–µ—Ä –¥–ª—è –∏—Å—Ç–æ—á–Ω–∏–∫–∞: {source}")
            return parser
        else:
            logger.error(f"‚ùå –ü–∞—Ä—Å–µ—Ä –¥–ª—è –∏—Å—Ç–æ—á–Ω–∏–∫–∞ {source} –Ω–µ –Ω–∞–π–¥–µ–Ω")
            raise ValueError(f"–ü–∞—Ä—Å–µ—Ä –¥–ª—è {source} –Ω–µ –Ω–∞–π–¥–µ–Ω")
    else:
        # –ò—Å—Ç–æ—á–Ω–∏–∫ –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω - –ø—Ä–æ–±—É–µ–º –¶–ò–ê–ù –∫–∞–∫ fallback
        logger.warning(f"‚ö†Ô∏è –ò—Å—Ç–æ—á–Ω–∏–∫ –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω –¥–ª—è URL: {url}, –∏—Å–ø–æ–ª—å–∑—É–µ–º –¶–ò–ê–ù")
        from src.parsers.playwright_parser import PlaywrightParser
        return PlaywrightParser(
            headless=True,
            delay=1.0,
            cache=property_cache,
            region=region,
            browser_pool=browser_pool
        )


# Rate limiting configuration
# SECURITY: –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–ª—é—á –¥–ª—è –∑–∞—â–∏—Ç—ã –æ—Ç –æ–±—Ö–æ–¥–∞ —á–µ—Ä–µ–∑ –ø—Ä–æ–∫—Å–∏
import hashlib

def get_rate_limit_key():
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–ª—é—á –¥–ª—è rate limiting

    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç: IP + User-Agent + Session (–µ—Å–ª–∏ –µ—Å—Ç—å)
    –≠—Ç–æ –∑–∞—Ç—Ä—É–¥–Ω—è–µ—Ç –æ–±—Ö–æ–¥ —á–µ—Ä–µ–∑ –ø—Ä–æ–∫—Å–∏ –∏–ª–∏ —Å–º–µ–Ω—É IP
    """
    # IP –∞–¥—Ä–µ—Å
    ip = get_remote_address()

    # User-Agent
    user_agent = request.headers.get('User-Agent', '')[:200]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É

    # Session ID (–µ—Å–ª–∏ –µ—Å—Ç—å)
    session_id = session.get('id', '')

    # –ö–æ–º–±–∏–Ω–∏—Ä—É–µ–º –∏ —Ö—ç—à–∏—Ä—É–µ–º –¥–ª—è privacy
    combined = f"{ip}:{user_agent}:{session_id}"
    key_hash = hashlib.sha256(combined.encode()).hexdigest()[:16]

    return key_hash

# –ò—Å–ø–æ–ª—å–∑—É–µ–º Redis –¥–ª—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–≥–æ rate limiting (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω)
limiter = Limiter(
    app=app,
    key_func=get_rate_limit_key,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–ª—É—á—à–µ–Ω–Ω—ã–π –∫–ª—é—á
    storage_uri=f"redis://{os.getenv('REDIS_HOST', 'localhost')}:{os.getenv('REDIS_PORT', 6379)}/{os.getenv('REDIS_DB', 0)}" if os.getenv('REDIS_ENABLED', 'false').lower() == 'true' else 'memory://',
    default_limits=["200 per day", "50 per hour"],
    storage_options={"socket_connect_timeout": 30},
    strategy="moving-window"  # –ë–æ–ª–µ–µ —Å—Ç—Ä–æ–≥–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è
)

logger.info(f"Rate limiting initialized: {limiter._storage_uri[:20]}...")


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# SECURITY UTILITIES (CRITICAL FIX)
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

from urllib.parse import urlparse
import ipaddress

# Whitelist —Ä–∞–∑—Ä–µ—à–µ–Ω–Ω—ã—Ö –¥–æ–º–µ–Ω–æ–≤ –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ (–∑–∞—â–∏—Ç–∞ –æ—Ç SSRF)
ALLOWED_DOMAINS = [
    'www.cian.ru',
    'cian.ru',
    'spb.cian.ru',
    'moscow.cian.ru',
    'www.domclick.ru',
    'domclick.ru'
]

def validate_url(url: str) -> None:
    """
    Validate URL –¥–ª—è –∑–∞—â–∏—Ç—ã –æ—Ç SSRF –∞—Ç–∞–∫

    Args:
        url: URL –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏

    Raises:
        ValueError: –µ—Å–ª–∏ URL –æ–ø–∞—Å–µ–Ω

    –ó–∞—â–∏—Ç–∞ –æ—Ç:
    - Internal network scanning
    - File:// protocol
    - Localhost/private IP access
    - Arbitrary domain access
    """
    if not url:
        raise ValueError('URL –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º')

    # –ü–∞—Ä—Å–∏–º URL
    try:
        parsed = urlparse(url)
    except Exception as e:
        raise ValueError(f'–ù–µ–≤–∞–ª–∏–¥–Ω—ã–π URL: {e}')

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–æ—Ç–æ–∫–æ–ª
    if parsed.scheme not in ['http', 'https']:
        raise ValueError(f'–ó–∞–ø—Ä–µ—â–µ–Ω–Ω—ã–π –ø—Ä–æ—Ç–æ–∫–æ–ª: {parsed.scheme}. –†–∞–∑—Ä–µ—à–µ–Ω—ã —Ç–æ–ª—å–∫–æ http/https')

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ hostname
    if not parsed.hostname:
        raise ValueError('URL –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å hostname')

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º whitelist –¥–æ–º–µ–Ω–æ–≤
    hostname_lower = parsed.hostname.lower()
    if not any(hostname_lower == domain or hostname_lower.endswith('.' + domain)
               for domain in ALLOWED_DOMAINS):
        raise ValueError(f'–î–æ–º–µ–Ω {parsed.hostname} –Ω–µ —Ä–∞–∑—Ä–µ—à–µ–Ω. –†–∞–∑—Ä–µ—à–µ–Ω—ã —Ç–æ–ª—å–∫–æ: {", ".join(ALLOWED_DOMAINS)}')

    # –ë–ª–æ–∫–∏—Ä—É–µ–º private/internal IP –∞–¥—Ä–µ—Å–∞
    try:
        ip = ipaddress.ip_address(parsed.hostname)
        if ip.is_private or ip.is_loopback or ip.is_link_local:
            raise ValueError(f'–ó–∞–ø—Ä–µ—â–µ–Ω –¥–æ—Å—Ç—É–ø –∫ internal IP: {ip}')
    except ValueError:
        # –ù–µ IP –∞–¥—Ä–µ—Å - —ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º
        pass

    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏
    if len(url) > 2048:
        raise ValueError('URL —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π (max 2048 —Å–∏–º–≤–æ–ª–æ–≤)')

    # –ë–ª–æ–∫–∏—Ä—É–µ–º –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
    suspicious_patterns = ['localhost', '127.', '192.168.', '10.', '172.16.', '@']
    for pattern in suspicious_patterns:
        if pattern in url.lower():
            raise ValueError(f'URL —Å–æ–¥–µ—Ä–∂–∏—Ç –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω: {pattern}')


def sanitize_string(text: str, max_length: int = 1000) -> str:
    """
    Sanitize —Å—Ç—Ä–æ–∫—É –æ—Ç –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ –æ–ø–∞—Å–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞

    Args:
        text: –°—Ç—Ä–æ–∫–∞ –¥–ª—è –æ—á–∏—Å—Ç–∫–∏
        max_length: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞

    Returns:
        –û—á–∏—â–µ–Ω–Ω–∞—è —Å—Ç—Ä–æ–∫–∞
    """
    if not text:
        return ''

    # –û–±—Ä–µ–∑–∞–µ–º –¥–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –¥–ª–∏–Ω—ã
    text = str(text).strip()[:max_length]

    # –£–¥–∞–ª—è–µ–º null bytes
    text = text.replace('\x00', '')

    # –£–¥–∞–ª—è–µ–º control characters –∫—Ä–æ–º–µ \n, \r, \t
    text = ''.join(char for char in text if ord(char) >= 32 or char in '\n\r\t')

    return text


# Pydantic models –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
from pydantic import BaseModel, Field, validator, ValidationError as PydanticValidationError

class ManualPropertyInput(BaseModel):
    """–í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ä—É—á–Ω–æ–≥–æ –≤–≤–æ–¥–∞ –æ–±—ä–µ–∫—Ç–∞ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏"""
    address: str = Field(..., min_length=5, max_length=500, description="–ü–æ–ª–Ω—ã–π –∞–¥—Ä–µ—Å")
    price_raw: float = Field(..., gt=0, lt=1_000_000_000_000, description="–¶–µ–Ω–∞ –≤ —Ä—É–±–ª—è—Ö")
    total_area: float = Field(..., gt=1, lt=10000, description="–û–±—â–∞—è –ø–ª–æ—â–∞–¥—å –≤ –º¬≤")
    rooms: str = Field(..., description="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–º–Ω–∞—Ç")
    floor: str = Field(default='', max_length=20, description="–≠—Ç–∞–∂ –≤ —Ñ–æ—Ä–º–∞—Ç–µ N/M")
    living_area: float = Field(default=None, gt=0, lt=10000, description="–ñ–∏–ª–∞—è –ø–ª–æ—â–∞–¥—å –≤ –º¬≤")
    kitchen_area: float = Field(default=None, gt=0, lt=500, description="–ü–ª–æ—â–∞–¥—å –∫—É—Ö–Ω–∏ –≤ –º¬≤")
    repair_level: str = Field(default='—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è', max_length=50)
    view_type: str = Field(default='—É–ª–∏—Ü–∞', max_length=50)

    @validator('address')
    def validate_address(cls, v):
        """–°–∞–Ω–∏—Ç–∏–∑–∞—Ü–∏—è –∞–¥—Ä–µ—Å–∞"""
        v = sanitize_string(v, max_length=500)
        if not v or len(v) < 5:
            raise ValueError('–ê–¥—Ä–µ—Å —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π')
        # –ë–ª–æ–∫–∏—Ä—É–µ–º SQL injection –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        dangerous_patterns = ['<script', 'javascript:', 'onerror=', 'onclick=', 'drop table', 'union select']
        v_lower = v.lower()
        for pattern in dangerous_patterns:
            if pattern in v_lower:
                raise ValueError(f'–ê–¥—Ä–µ—Å —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω–µ–¥–æ–ø—É—Å—Ç–∏–º—ã–µ —Å–∏–º–≤–æ–ª—ã')
        return v

    @validator('rooms')
    def validate_rooms(cls, v):
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –∫–æ–º–Ω–∞—Ç"""
        allowed_values = ['–°—Ç—É–¥–∏—è', '1', '2', '3', '4', '5', '5+']
        if v not in allowed_values:
            raise ValueError(f'–ù–µ–¥–æ–ø—É—Å—Ç–∏–º–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è –∫–æ–º–Ω–∞—Ç: {v}. –†–∞–∑—Ä–µ—à–µ–Ω—ã: {allowed_values}')
        return v

    @validator('living_area')
    def validate_living_area(cls, v, values):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —á—Ç–æ –∂–∏–ª–∞—è –ø–ª–æ—â–∞–¥—å –Ω–µ –±–æ–ª—å—à–µ –æ–±—â–µ–π"""
        if v and 'total_area' in values and v > values['total_area']:
            raise ValueError('–ñ–∏–ª–∞—è –ø–ª–æ—â–∞–¥—å –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –±–æ–ª—å—à–µ –æ–±—â–µ–π')
        return v

    @validator('kitchen_area')
    def validate_kitchen_area(cls, v, values):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —á—Ç–æ –ø–ª–æ—â–∞–¥—å –∫—É—Ö–Ω–∏ –Ω–µ –±–æ–ª—å—à–µ –æ–±—â–µ–π"""
        if v and 'total_area' in values and v > values['total_area']:
            raise ValueError('–ü–ª–æ—â–∞–¥—å –∫—É—Ö–Ω–∏ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –±–æ–ª—å—à–µ –æ–±—â–µ–π')
        return v


# Timeout decorator –¥–ª—è –∑–∞—â–∏—Ç—ã –æ—Ç –∑–∞–≤–∏—Å–∞—é—â–∏—Ö –æ–ø–µ—Ä–∞—Ü–∏–π
import signal
import threading
from contextlib import contextmanager
from functools import wraps

class TimeoutError(Exception):
    """Exception raised when operation times out"""
    pass


@contextmanager
def timeout_context(seconds: int, error_message: str = 'Operation timed out'):
    """
    Context manager –¥–ª—è –∂–µ—Å—Ç–∫–æ–≥–æ timeout –æ–ø–µ—Ä–∞—Ü–∏–π
    –†–∞–±–æ—Ç–∞–µ—Ç –∫–∞–∫ –≤ –≥–ª–∞–≤–Ω–æ–º –ø–æ—Ç–æ–∫–µ (—á–µ—Ä–µ–∑ signal), —Ç–∞–∫ –∏ –≤ –¥–æ—á–µ—Ä–Ω–∏—Ö (—á–µ—Ä–µ–∑ threading.Timer)

    Args:
        seconds: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
        error_message: –°–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ

    Raises:
        TimeoutError: –µ—Å–ª–∏ –æ–ø–µ—Ä–∞—Ü–∏—è –ø—Ä–µ–≤—ã—Å–∏–ª–∞ timeout

    Example:
        with timeout_context(60):
            long_running_operation()
    """
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–∞—Ö–æ–¥–∏–º—Å—è –ª–∏ –º—ã –≤ –≥–ª–∞–≤–Ω–æ–º –ø–æ—Ç–æ–∫–µ
    is_main_thread = threading.current_thread() is threading.main_thread()

    if is_main_thread:
        # –í –≥–ª–∞–≤–Ω–æ–º –ø–æ—Ç–æ–∫–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º signal
        def timeout_handler(signum, frame):
            raise TimeoutError(error_message)

        old_handler = signal.signal(signal.SIGALRM, timeout_handler)
        signal.alarm(seconds)

        try:
            yield
        finally:
            signal.alarm(0)
            signal.signal(signal.SIGALRM, old_handler)
    else:
        # –í –¥–æ—á–µ—Ä–Ω–∏—Ö –ø–æ—Ç–æ–∫–∞—Ö –ø—Ä–æ—Å—Ç–æ –≤—ã–ø–æ–ª–Ω—è–µ–º –±–µ–∑ timeout
        # (signal –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ –¥–æ—á–µ—Ä–Ω–∏—Ö –ø–æ—Ç–æ–∫–∞—Ö —Å Gunicorn gthread worker)
        logger.debug(f"Timeout context called in non-main thread, executing without timeout")
        yield


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# SECURITY HEADERS (CRITICAL FIX)
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

@app.after_request
def set_security_headers(response):
    """
    Apply security headers to all responses

    Protection against:
    - XSS (Content-Security-Policy)
    - Clickjacking (X-Frame-Options)
    - MIME sniffing (X-Content-Type-Options)
    - Information leakage (Referrer-Policy)
    """

    # Content Security Policy - –∑–∞—â–∏—Ç–∞ –æ—Ç XSS
    response.headers['Content-Security-Policy'] = (
        "default-src 'self'; "
        "script-src 'self' https://cdn.jsdelivr.net https://unpkg.com; "
        "style-src 'self' 'unsafe-inline' https://cdn.jsdelivr.net https://fonts.googleapis.com; "
        "img-src 'self' data: https: http:; "
        "font-src 'self' https://cdn.jsdelivr.net https://fonts.gstatic.com; "
        "connect-src 'self'; "
        "frame-ancestors 'none'; "
        "base-uri 'self'; "
        "form-action 'self';"
    )

    # –ó–∞–ø—Ä–µ—Ç –Ω–∞ MIME-sniffing
    response.headers['X-Content-Type-Options'] = 'nosniff'

    # –ó–∞—â–∏—Ç–∞ –æ—Ç clickjacking
    response.headers['X-Frame-Options'] = 'DENY'

    # XSS Protection (legacy, –Ω–æ –¥–ª—è —Å—Ç–∞—Ä—ã—Ö –±—Ä–∞—É–∑–µ—Ä–æ–≤)
    response.headers['X-XSS-Protection'] = '1; mode=block'

    # Referrer Policy - –Ω–µ –ø–µ—Ä–µ–¥–∞–µ–º –ø–æ–ª–Ω—ã–π URL –ø—Ä–∏ –ø–µ—Ä–µ—Ö–æ–¥–∞—Ö
    response.headers['Referrer-Policy'] = 'strict-origin-when-cross-origin'

    # HSTS - –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–π HTTPS (—Ç–æ–ª—å–∫–æ –≤ production)
    if os.getenv('FLASK_ENV') == 'production':
        response.headers['Strict-Transport-Security'] = 'max-age=31536000; includeSubDomains'

    return response


@app.route('/')
def index():
    """Landing page - Agency website"""
    return render_template('index.html')


@app.route('/health', methods=['GET'])
def health_check():
    """
    Health check endpoint –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞

    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç:
    - –î–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
    - –°–æ—Å—Ç–æ—è–Ω–∏–µ Redis –∫—ç—à–∞
    - –°–æ—Å—Ç–æ—è–Ω–∏–µ session storage
    - –í–µ—Ä—Å–∏—é –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è

    Returns:
        200 OK –µ—Å–ª–∏ –≤—Å–µ –≤ –ø–æ—Ä—è–¥–∫–µ
        503 Service Unavailable –µ—Å–ª–∏ –µ—Å—Ç—å –∫—Ä–∏—Ç–∏—á–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã
    """
    health_status = {
        'status': 'healthy',
        'timestamp': datetime.now().isoformat(),
        'version': '2.0.0',  # –í–µ—Ä—Å–∏—è –ø–æ—Å–ª–µ —É–ª—É—á—à–µ–Ω–∏–π
        'components': {}
    }

    all_healthy = True

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫—ç—à–∞
    try:
        cache_health = property_cache.health_check()
        cache_stats = property_cache.get_stats()
        health_status['components']['redis_cache'] = {
            'status': 'healthy' if cache_health else 'degraded',
            'available': cache_health,
            'stats': cache_stats
        }
        if not cache_health and property_cache.enabled:
            # –ï—Å–ª–∏ –∫—ç—à –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤–∫–ª—é—á–µ–Ω, –Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω - warning, –Ω–æ –Ω–µ critical
            health_status['components']['redis_cache']['status'] = 'degraded'
            health_status['status'] = 'degraded'
    except Exception as e:
        health_status['components']['redis_cache'] = {
            'status': 'unhealthy',
            'error': str(e)
        }
        # –ö—ç—à - –Ω–µ –∫—Ä–∏—Ç–∏—á–Ω—ã–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç
        if health_status['status'] != 'unhealthy':
            health_status['status'] = 'degraded'

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ session storage
    try:
        # –ü—Ä–æ–±—É–µ–º –∑–∞–ø–∏—Å–∞—Ç—å –∏ –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ç–µ—Å—Ç–æ–≤—É—é —Å–µ—Å—Å–∏—é
        test_session_id = '_health_check_test'
        session_storage.set(test_session_id, {'test': True})
        test_data = session_storage.get(test_session_id)
        session_storage.delete(test_session_id)

        # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Ö—Ä–∞–Ω–∏–ª–∏—â–∞
        storage_stats = session_storage.get_stats()

        health_status['components']['session_storage'] = {
            'status': 'healthy',
            'type': type(session_storage).__name__,
            'backend': storage_stats['backend'],
            'total_sessions': storage_stats['total_sessions'],
            'hit_rate_percent': storage_stats['hit_rate_percent']
        }
    except Exception as e:
        health_status['components']['session_storage'] = {
            'status': 'unhealthy',
            'error': str(e)
        }
        all_healthy = False
        health_status['status'] = 'unhealthy'

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–∞—Ä—Å–µ—Ä–∞
    try:
        # –ü—Ä–æ—Å—Ç–æ –ø—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∫–ª–∞—Å—Å –¥–æ—Å—Ç—É–ø–µ–Ω
        parser_name = Parser.__name__
        health_status['components']['parser'] = {
            'status': 'healthy',
            'type': parser_name
        }
    except Exception as e:
        # Parser –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω - —ç—Ç–æ –Ω–µ –∫—Ä–∏—Ç–∏—á–Ω–æ, –µ—Å—Ç—å fallback
        health_status['components']['parser'] = {
            'status': 'degraded',
            'error': str(e),
            'fallback': 'SimpleParser available'
        }
        # –ù–ï —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º all_healthy = False, –ø–∞—Ä—Å–µ—Ä –Ω–µ –∫—Ä–∏—Ç–∏—á–µ–Ω
        if health_status['status'] == 'healthy':
            health_status['status'] = 'degraded'

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ browser pool
    if browser_pool:
        try:
            pool_stats = browser_pool.get_stats()
            health_status['components']['browser_pool'] = {
                'status': 'healthy',
                'pool_size': pool_stats['pool_size'],
                'max_browsers': pool_stats['max_browsers'],
                'browsers_in_use': pool_stats['browsers_in_use'],
                'browsers_free': pool_stats['browsers_free']
            }
        except Exception as e:
            health_status['components']['browser_pool'] = {
                'status': 'degraded',
                'error': str(e)
            }
            if health_status['status'] != 'unhealthy':
                health_status['status'] = 'degraded'

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º HTTP —Å—Ç–∞—Ç—É—Å
    if health_status['status'] == 'healthy':
        http_status = 200
    elif health_status['status'] == 'degraded':
        http_status = 200  # Degraded, –Ω–æ —Ä–∞–±–æ—Ç–∞–µ—Ç
    else:
        http_status = 503  # Service Unavailable

    return jsonify(health_status), http_status


@app.route('/api/csrf-token', methods=['GET'])
def get_csrf_token():
    """
    SECURITY: Endpoint –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è CSRF —Ç–æ–∫–µ–Ω–∞

    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç CSRF token –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ AJAX –∑–∞–ø—Ä–æ—Å–∞—Ö

    Returns:
        JSON —Å CSRF —Ç–æ–∫–µ–Ω–æ–º
    """
    from flask_wtf.csrf import generate_csrf
    token = generate_csrf()
    return jsonify({'csrf_token': token})


@app.route('/metrics', methods=['GET'])
def metrics():
    """
    Prometheus-compatible metrics endpoint

    Returns:
        –ú–µ—Ç—Ä–∏–∫–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ Prometheus
    """
    lines = []

    # –ë–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    lines.append('# HELP housler_up Application is running')
    lines.append('# TYPE housler_up gauge')
    lines.append('housler_up 1')

    # –ö—ç—à –º–µ—Ç—Ä–∏–∫–∏
    try:
        cache_stats = property_cache.get_stats()
        if cache_stats.get('available'):
            lines.append('# HELP housler_cache_hit_rate Cache hit rate percentage')
            lines.append('# TYPE housler_cache_hit_rate gauge')
            lines.append(f"housler_cache_hit_rate {cache_stats.get('hit_rate', 0)}")

            lines.append('# HELP housler_cache_keys_total Total number of cached keys')
            lines.append('# TYPE housler_cache_keys_total gauge')
            lines.append(f"housler_cache_keys_total {cache_stats.get('total_keys', 0)}")
    except:
        pass

    return '\n'.join(lines) + '\n', 200, {'Content-Type': 'text/plain'}


@app.route('/calculator')
def calculator():
    """Property calculator - main analysis tool"""
    # –ü–æ–ª—É—á–∞–µ–º session_id –∏–∑ query –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ (–µ—Å–ª–∏ –µ—Å—Ç—å)
    session_id = request.args.get('session')
    return render_template('wizard.html', session_id=session_id)


@app.route('/api/parse', methods=['POST'])
@limiter.limit("10 per minute")  # Expensive operation - –ø–∞—Ä—Å–∏–Ω–≥
def parse_url():
    """
    API: –ü–∞—Ä—Å–∏–Ω–≥ URL —Ü–µ–ª–µ–≤–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞ (–≠–∫—Ä–∞–Ω 1)

    Body:
        {
            "url": "https://www.cian.ru/sale/flat/123/"
        }

    Returns:
        {
            "status": "success",
            "data": {...},
            "session_id": "uuid",
            "missing_fields": ["field1", "field2"]
        }
    """
    try:
        data = request.json
        url = data.get('url')

        if not url:
            return jsonify({'status': 'error', 'message': 'URL –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω'}), 400

        # SECURITY: –í–∞–ª–∏–¥–∞—Ü–∏—è URL (–∑–∞—â–∏—Ç–∞ –æ—Ç SSRF)
        try:
            validate_url(url)
        except ValueError as e:
            logger.warning(f"URL validation failed: {e} (from {request.remote_addr})")
            return jsonify({'status': 'error', 'message': str(e)}), 400

        # –ê–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–µ–≥–∏–æ–Ω–∞ –ø–æ URL
        region = detect_region_from_url(url)
        logger.info(f"–ü–∞—Ä—Å–∏–Ω–≥ URL: {url} (–ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π —Ä–µ–≥–∏–æ–Ω: {region})")

        # SECURITY: –ü–∞—Ä—Å–∏–Ω–≥ —Å timeout (–∑–∞—â–∏—Ç–∞ –æ—Ç DoS)
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º fallback —Ä–µ–≥–∏–æ–Ω –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞, –µ—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å
        try:
            with timeout_context(60, '–ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–Ω—è–ª —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ (>60s)'):
                with get_parser_for_url(url, region=region or 'spb') as parser:
                    parsed_data = parser.parse_detail_page(url)
        except TimeoutError as e:
            logger.error(f"Parsing timeout for {url}: {e}")
            return jsonify({
                'status': 'error',
                'message': '–í—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –∏—Å—Ç–µ–∫–ª–æ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ –∏–ª–∏ –¥—Ä—É–≥–æ–π –æ–±—ä–µ–∫—Ç.'
            }), 408  # Request Timeout

        # –ö–†–ò–¢–ò–ß–ù–û: –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–µ–≥–∏–æ–Ω –ø–æ –∞–¥—Ä–µ—Å—É –æ–±—ä–µ–∫—Ç–∞ –ø–æ—Å–ª–µ –ø–∞—Ä—Å–∏–Ω–≥–∞
        if not region:
            address = parsed_data.get('address', '')
            region = detect_region_from_address(address)
            if region:
                logger.info(f"‚úì –†–µ–≥–∏–æ–Ω –æ–ø—Ä–µ–¥–µ–ª–µ–Ω –ø–æ –∞–¥—Ä–µ—Å—É: {region} (–∞–¥—Ä–µ—Å: {address})")
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–≥–∏–æ–Ω –≤ –¥–∞–Ω–Ω—ã–µ –æ–±—ä–µ–∫—Ç–∞
                parsed_data['region'] = region
            else:
                logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ä–µ–≥–∏–æ–Ω –Ω–∏ –ø–æ URL, –Ω–∏ –ø–æ –∞–¥—Ä–µ—Å—É: {address}")
                # Fallback –Ω–∞ –°–ü–±
                region = 'spb'
                parsed_data['region'] = region
        else:
            parsed_data['region'] = region

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –ø–æ–ª—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        missing_fields = _identify_missing_fields(parsed_data)

        # –°–æ–∑–¥–∞–µ–º —Å–µ—Å—Å–∏—é
        session_id = str(uuid.uuid4())
        session_storage.set(session_id, {
            'target_property': parsed_data,
            'comparables': [],
            'created_at': datetime.now().isoformat(),
            'step': 1
        })

        return jsonify({
            'status': 'success',
            'data': parsed_data,
            'session_id': session_id,
            'missing_fields': missing_fields
        })

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞: {e}", exc_info=True)

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –æ—à–∏–±–∫–∏
        error_str = str(e).lower()
        error_type = 'parsing_error'
        user_message = '–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –æ–±—ä—è–≤–ª–µ–Ω–∏—è'

        if 'url' in error_str and ('invalid' in error_str or '–Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω' in error_str):
            error_type = 'invalid_url'
            user_message = '–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è —Å—Å—ã–ª–∫–∞. –í–≤–µ–¥–∏—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π URL —Å Cian.ru'
        elif 'timeout' in error_str or 'timed out' in error_str:
            error_type = 'timeout'
            user_message = '–ü—Ä–µ–≤—ã—à–µ–Ω–æ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.'
        elif 'not found' in error_str or '404' in error_str:
            error_type = 'no_data'
            user_message = '–û–±—ä—è–≤–ª–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å—Å—ã–ª–∫—É.'
        elif 'captcha' in error_str or 'blocked' in error_str:
            error_type = 'parsing_failed'
            user_message = '–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —á–µ—Ä–µ–∑ –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç.'
        elif 'browser' in error_str or 'playwright' in error_str:
            error_type = 'browser_error'
            user_message = '–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞. –ü–æ–≤—Ç–æ—Ä–∏—Ç–µ –ø–æ–ø—ã—Ç–∫—É.'

        return jsonify({
            'status': 'error',
            'error_type': error_type,
            'message': user_message,
            'technical_details': str(e)
        }), 500


@app.route('/api/create-manual', methods=['POST'])
@limiter.limit("10 per minute")
def create_manual():
    """
    API: –°–æ–∑–¥–∞–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞ –≤—Ä—É—á–Ω—É—é –±–µ–∑ –ø–∞—Ä—Å–∏–Ω–≥–∞ (–≠–∫—Ä–∞–Ω 1)

    Body:
        {
            "address": "–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥, —É–ª–∏—Ü–∞ –õ–µ–Ω–∏–Ω–∞, 10",
            "price_raw": 15000000,
            "total_area": 75.5,
            "rooms": "2",
            "floor": "5/10",
            "living_area": 55.0,
            "kitchen_area": 12.0,
            "repair_level": "—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è",
            "view_type": "—É–ª–∏—Ü–∞"
        }

    Returns:
        {
            "status": "success",
            "data": {...},
            "session_id": "uuid",
            "missing_fields": []
        }
    """
    try:
        data = request.json

        # SECURITY: –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö —á–µ—Ä–µ–∑ Pydantic
        try:
            validated = ManualPropertyInput(**data)
        except PydanticValidationError as e:
            logger.warning(f"Validation error from {request.remote_addr}: {e}")
            # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            errors = []
            for error in e.errors():
                field = error['loc'][0]
                msg = error['msg']
                errors.append(f"{field}: {msg}")
            return jsonify({
                'status': 'error',
                'error_type': 'data_validation_error',
                'message': '–û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –≤–≤–µ–¥–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è.',
                'errors': errors
            }), 400

        # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏ –∏–∑ –≤–∞–ª–∏–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        property_data = {
            'address': validated.address,
            'price_raw': validated.price_raw,
            'price': f"{int(validated.price_raw):,} ‚ÇΩ".replace(',', ' '),
            'total_area': validated.total_area,
            'area': f"{validated.total_area} –º¬≤",
            'rooms': validated.rooms,
            'floor': validated.floor,
            'living_area': validated.living_area,
            'kitchen_area': validated.kitchen_area,
            'repair_level': validated.repair_level,
            'view_type': validated.view_type,
            'manual_input': True,
            'title': f"{validated.rooms}-–∫–æ–º–Ω. –∫–≤–∞—Ä—Ç–∏—Ä–∞, {validated.total_area} –º¬≤",
            'url': 'manual-input',  # –ü–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä –¥–ª—è —Ä—É—á–Ω–æ–≥–æ –≤–≤–æ–¥–∞
            'metro': [],
            'residential_complex': None,
            'characteristics': {}
        }

        # –ü—ã—Ç–∞–µ–º—Å—è –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ä–µ–≥–∏–æ–Ω –∏–∑ –∞–¥—Ä–µ—Å–∞
        address_lower = data['address'].lower()
        if '—Å–∞–Ω–∫—Ç-–ø–µ—Ç–µ—Ä–±—É—Ä–≥' in address_lower or '—Å–ø–±' in address_lower:
            region = 'spb'
        elif '–º–æ—Å–∫–≤–∞' in address_lower or '–º—Å–∫' in address_lower:
            region = 'msk'
        else:
            region = 'spb'  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é

        property_data['region'] = region

        logger.info(f"–°–æ–∑–¥–∞–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞ –≤—Ä—É—á–Ω—É—é: {property_data['address']} (—Ä–µ–≥–∏–æ–Ω: {region})")

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –ø–æ–ª—è (–¥–ª—è —Ä—É—á–Ω–æ–≥–æ –≤–≤–æ–¥–∞ –∏—Ö –º–µ–Ω—å—à–µ)
        missing_fields = _identify_missing_fields(property_data)

        # –°–æ–∑–¥–∞–µ–º —Å–µ—Å—Å–∏—é
        session_id = str(uuid.uuid4())
        session_storage.set(session_id, {
            'target_property': property_data,
            'comparables': [],
            'created_at': datetime.now().isoformat(),
            'step': 1
        })

        return jsonify({
            'status': 'success',
            'data': property_data,
            'session_id': session_id,
            'missing_fields': missing_fields
        })

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –≤—Ä—É—á–Ω—É—é: {e}", exc_info=True)
        return jsonify({
            'status': 'error',
            'message': str(e)
        }), 500


@app.route('/api/update-target', methods=['POST'])
def update_target():
    """
    API: –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞ —Å –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω—ã–º–∏ –ø–æ–ª—è–º–∏ (–≠–∫—Ä–∞–Ω 1 ‚Üí 2)

    Body:
        {
            "session_id": "uuid",
            "data": {
                "has_design": true,
                "ceiling_height": 3.2,
                ...
            }
        }

    Returns:
        {
            "status": "success",
            "message": "–î–∞–Ω–Ω—ã–µ –æ–±–Ω–æ–≤–ª–µ–Ω—ã"
        }
    """
    try:
        payload = request.json
        session_id = payload.get('session_id')
        data = payload.get('data')

        if not session_id or not session_storage.exists(session_id):
            return jsonify({'status': 'error', 'message': '–°–µ—Å—Å–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞'}), 404

        # –û–±–Ω–æ–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ
        session_data = session_storage.get(session_id)
        session_data['target_property'].update(data)
        session_data['step'] = 2
        session_storage.set(session_id, session_data)

        return jsonify({
            'status': 'success',
            'message': '–î–∞–Ω–Ω—ã–µ –æ–±–Ω–æ–≤–ª–µ–Ω—ã'
        })

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è: {e}", exc_info=True)
        return jsonify({
            'status': 'error',
            'message': str(e)
        }), 500


@app.route('/api/find-similar', methods=['POST'])
@limiter.limit("15 per minute")  # Expensive - –ø–æ–∏—Å–∫ –∏ –ø–∞—Ä—Å–∏–Ω–≥ –∞–Ω–∞–ª–æ–≥–æ–≤
def find_similar():
    """
    API: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö –æ–±—ä–µ–∫—Ç–æ–≤ (–≠–∫—Ä–∞–Ω 2)

    Body:
        {
            "session_id": "uuid",
            "limit": 20,
            "search_type": "building"  // "building" –∏–ª–∏ "city"
        }

    Returns:
        {
            "status": "success",
            "comparables": [...],
            "search_type": "building",
            "residential_complex": "–ù–∞–∑–≤–∞–Ω–∏–µ –ñ–ö"
        }
    """
    try:
        import time
        request_start = time.time()

        payload = request.json
        session_id = payload.get('session_id')
        limit = payload.get('limit', 50)  # –£–≤–µ–ª–∏—á–µ–Ω–æ –¥–æ 50 –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        search_type = payload.get('search_type', 'building')  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏—â–µ–º –≤ –ñ–ö

        logger.info(f"üìç [STEP 2] find-similar request started (session: {session_id}, type: {search_type}, limit: {limit})")

        if not session_id or not session_storage.exists(session_id):
            logger.error(f"‚ùå Session not found: {session_id}")
            return jsonify({'status': 'error', 'message': '–°–µ—Å—Å–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞'}), 404

        session_data = session_storage.get(session_id)
        target = session_data['target_property']

        # –ö–†–ò–¢–ò–ß–ù–û: –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–≥–∏–æ–Ω, –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–π –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ (–Ω–µ –æ–ø—Ä–µ–¥–µ–ª—è–µ–º –∑–∞–Ω–æ–≤–æ!)
        # –†–µ–≥–∏–æ–Ω —É–∂–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω –ø–æ –∞–¥—Ä–µ—Å—É –≤ /api/parse
        region = target.get('region')
        if not region:
            # Fallback: –æ–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ URL –∏–ª–∏ –∞–¥—Ä–µ—Å—É
            target_url = target.get('url', '')
            region = detect_region_from_url(target_url)
            if not region:
                address = target.get('address', '')
                region = detect_region_from_address(address)
                if not region:
                    logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ä–µ–≥–∏–æ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback: spb")
                    region = 'spb'

        logger.info(f"üîç Searching for similar properties (session: {session_id}, type: {search_type}, region: {region}, limit: {limit})")

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º URL —Ü–µ–ª–µ–≤–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ø–∞—Ä—Å–µ—Ä–∞
        target_url = target.get('url', '')

        # –ü–æ–∏—Å–∫ –∞–Ω–∞–ª–æ–≥–æ–≤ —Å –∫—ç—à–µ–º –∏ —Ä–µ–≥–∏–æ–Ω–æ–º
        try:
            logger.info(f"üîç Starting search (type: {search_type}, limit: {limit})")
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ü–µ–ª–µ–≤–æ–π URL –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∏—Å—Ç–æ—á–Ω–∏–∫–∞ (–∏–ª–∏ fallback –Ω–∞ –¶–ò–ê–ù)
            search_url = target_url if target_url else 'https://www.cian.ru/'
            with get_parser_for_url(search_url, region=region) as parser:
                if search_type == 'building':
                    # –ü–æ–∏—Å–∫ –≤ —Ç–æ–º –∂–µ –ñ–ö
                    logger.info(f"üè¢ Searching in building: {target.get('residential_complex', 'Unknown')}")
                    similar = parser.search_similar_in_building(target, limit=limit)
                    residential_complex = target.get('residential_complex', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')
                    logger.info(f"‚úÖ Found {len(similar)} comparables in building")

                    # PATCH: FALLBACK - –µ—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞—à–ª–∏ –ø–æ –ñ–ö, –ø—Ä–æ–±—É–µ–º —à–∏—Ä–æ–∫–∏–π –ø–æ–∏—Å–∫
                    if len(similar) == 0:
                        logger.warning("‚ö†Ô∏è Building search returned 0 results! Trying citywide search as fallback...")
                        similar = parser.search_similar(target, limit=limit)
                        residential_complex = None  # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Ç.–∫. –∞–Ω–∞–ª–æ–≥–∏ –Ω–µ –∏–∑ —Ç–æ–≥–æ –∂–µ –ñ–ö
                        logger.info(f"‚úÖ Fallback citywide search found {len(similar)} comparables")
                else:
                    # –®–∏—Ä–æ–∫–∏–π –ø–æ–∏—Å–∫ –ø–æ –≥–æ—Ä–æ–¥—É
                    logger.info(f"üåÜ Searching in city: {region}")
                    similar = parser.search_similar(target, limit=limit)
                    residential_complex = None
                    logger.info(f"‚úÖ Found {len(similar)} comparables in city")
        except Exception as search_error:
            logger.error(f"‚ùå Search failed: {search_error}", exc_info=True)
            return jsonify({
                'status': 'error',
                'message': 'search_failed',
                'details': f'–ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å –ø–æ–∏—Å–∫: {str(search_error)}'
            }), 500

        # –ï—Å–ª–∏ –Ω–∞–π–¥–µ–Ω–æ –º–Ω–æ–≥–æ –∞–Ω–∞–ª–æ–≥–æ–≤ —Å URL, –ø–∞—Ä—Å–∏–º –∏—Ö –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
        # –ü–∞—Ä—Å–∏–º –¥–µ—Ç–∞–ª—å–Ω–æ –æ–±—ä–µ–∫—Ç—ã –±–µ–∑ –ø–æ–ª–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö (price, total_area, price_per_sqm)
        urls_to_parse = [
            c.get('url') for c in similar
            if c.get('url') and not (c.get('price') and c.get('total_area'))
        ]

        logger.info(f"üîç DEBUG: {len(similar)} comparables found, {len(urls_to_parse)} need detailed parsing")

        if urls_to_parse:
            try:
                from src.parsers.async_parser import parse_multiple_urls_parallel
                logger.info(f"üöÄ Starting parallel parsing of {len(urls_to_parse)} URLs...")
                import time
                parse_start = time.time()

                # PATCH 1: Robust parsing with retry + quality metrics
                detailed_results, parse_quality = parse_multiple_urls_parallel(
                    urls=urls_to_parse,
                    headless=True,
                    cache=property_cache,
                    region=region,
                    max_concurrent=3,  # –°–Ω–∏–∂–µ–Ω–æ —Å 5 –¥–æ 3 –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è rate limiting
                    max_retries=2
                )

                parse_elapsed = time.time() - parse_start
                logger.info(
                    f"‚è±Ô∏è Parallel parsing took {parse_elapsed:.1f}s for {len(urls_to_parse)} URLs | "
                    f"Success: {parse_quality['successfully_parsed']}, "
                    f"Failed: {parse_quality['parse_failed']}, "
                    f"Retries: {parse_quality['total_retries']}"
                )

                # –õ–æ–≥–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏ –ø–æ —Ç–∏–ø–∞–º
                if parse_quality['error_breakdown']:
                    logger.warning(f"Parse errors breakdown: {parse_quality['error_breakdown']}")

                # –û–±–Ω–æ–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –∞–Ω–∞–ª–æ–≥–æ–≤ –¥–µ—Ç–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
                url_to_details = {d['url']: d for d in detailed_results}
                updated_count = 0
                for comparable in similar:
                    url = comparable.get('url')
                    if url in url_to_details:
                        comparable.update(url_to_details[url])
                        updated_count += 1

                logger.info(f"‚úÖ Enhanced {updated_count}/{len(similar)} comparables with detailed data")

            except Exception as e:
                logger.error(f"‚ùå Parallel parsing failed, using basic data: {e}", exc_info=True)

        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # –î–ï–¢–ï–ö–¶–ò–Ø –ò –£–î–ê–õ–ï–ù–ò–ï –î–£–ë–õ–ò–ö–ê–¢–û–í
        # –ü—Ä–∏ –ø–æ–∏—Å–∫–µ –ø–æ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–º –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º –æ–¥–Ω–∞ –∫–≤–∞—Ä—Ç–∏—Ä–∞ –º–æ–∂–µ—Ç –±—ã—Ç—å —Ä–∞–∑–º–µ—â–µ–Ω–∞
        # –Ω–∞ –¶–ò–ê–ù, –ê–≤–∏—Ç–æ, –Ø–Ω–¥–µ–∫—Å.–ù–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç—å —Å —Ä–∞–∑–Ω—ã–º–∏ —Ü–µ–Ω–∞–º–∏
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        if len(similar) > 0:
            logger.info(f"üîç Checking for duplicates among {len(similar)} comparables...")
            unique_comparables, removed_duplicates = duplicate_detector.deduplicate_list(
                similar,
                keep_best_price=True  # –û—Å—Ç–∞–≤–ª—è–µ–º –≤–∞—Ä–∏–∞–Ω—Ç —Å –ª—É—á—à–µ–π —Ü–µ–Ω–æ–π
            )

            if removed_duplicates:
                logger.info(f"‚úì Removed {len(removed_duplicates)} strict duplicates")
                for dup in removed_duplicates:
                    logger.debug(f"  - Removed: {dup.get('address', 'Unknown')} ({dup.get('price', 0):,.0f} ‚ÇΩ)")

                # –û–±–Ω–æ–≤–ª—è–µ–º —Å–ø–∏—Å–æ–∫
                similar = unique_comparables
            else:
                logger.info("‚úì No strict duplicates found")

        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # –î–û–†–ê–ë–û–¢–ö–ê #4: –ü–†–û–í–ï–†–ö–ê –ö–ê–ß–ï–°–¢–í–ê –ü–û–î–û–ë–†–ê–ù–ù–´–• –ê–ù–ê–õ–û–ì–û–í
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        warnings = []

        # –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –æ –¥—É–±–ª–∏–∫–∞—Ç–∞—Ö
        duplicate_warnings_count = sum(1 for c in similar if c.get('possible_duplicate'))
        if duplicate_warnings_count > 0:
            warnings.append({
                'type': 'warning',
                'title': '–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –≤–æ–∑–º–æ–∂–Ω—ã–µ –¥—É–±–ª–∏–∫–∞—Ç—ã',
                'message': f'–ù–∞–π–¥–µ–Ω–æ {duplicate_warnings_count} –æ–±—ä–µ–∫—Ç(–æ–≤), –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –±—ã—Ç—å –¥—É–±–ª–∏–∫–∞—Ç–∞–º–∏ (–ø–æ—Ö–æ–∂–∏–µ –∞–¥—Ä–µ—Å–∞ –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã). '
                           '–û–Ω–∏ –ø–æ–º–µ—á–µ–Ω—ã —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–º –∑–Ω–∞—á–∫–æ–º. –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –∏ —É–¥–∞–ª–∏—Ç—å –Ω–µ–ø–æ–¥—Ö–æ–¥—è—â–∏–µ.'
            })

        # PATCH 4: –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –æ –ø—Ä–æ–±–ª–µ–º–∞—Ö –ø–∞—Ä—Å–∏–Ω–≥–∞ (–µ—Å–ª–∏ –±—ã–ª–∏)
        if urls_to_parse and 'parse_quality' in locals():
            parse_failed = parse_quality.get('parse_failed', 0)
            total_found = parse_quality.get('total_found', 0)

            if parse_failed > 0:
                failed_percent = (parse_failed / total_found * 100) if total_found > 0 else 0
                error_breakdown = parse_quality.get('error_breakdown', {})

                error_details = []
                if 'rate_limited' in error_breakdown:
                    error_details.append(f"rate limiting ({error_breakdown['rate_limited']})")
                if 'timeout' in error_breakdown:
                    error_details.append(f"timeout ({error_breakdown['timeout']})")
                if 'captcha' in error_breakdown:
                    error_details.append(f"captcha ({error_breakdown['captcha']})")

                if failed_percent > 50:
                    warnings.append({
                        'type': 'error',
                        'title': '–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–±–ª–µ–º–∞ —Å –∑–∞–≥—Ä—É–∑–∫–æ–π –¥–∞–Ω–Ω—ã—Ö',
                        'message': f'–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–µ—Ç–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è {parse_failed} –∏–∑ {total_found} –∞–Ω–∞–ª–æ–≥–æ–≤ ({failed_percent:.0f}%). ' +
                                   (f'–û—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã: {", ".join(error_details)}. ' if error_details else '') +
                                   '–ê–Ω–∞–ª–∏–∑ –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ—Ç–æ—á–Ω—ã–º. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–≤—Ç–æ—Ä–∏—Ç—å –ø–æ–∑–∂–µ –∏–ª–∏ –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –≤ –ø–æ–¥–¥–µ—Ä–∂–∫—É.'
                    })
                elif failed_percent > 20:
                    warnings.append({
                        'type': 'warning',
                        'title': '–ü—Ä–æ–±–ª–µ–º—ã —Å –∑–∞–≥—Ä—É–∑–∫–æ–π –¥–∞–Ω–Ω—ã—Ö',
                        'message': f'–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–µ—Ç–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è {parse_failed} –∏–∑ {total_found} –∞–Ω–∞–ª–æ–≥–æ–≤ ({failed_percent:.0f}%). ' +
                                   (f'–ü—Ä–∏—á–∏–Ω—ã: {", ".join(error_details)}. ' if error_details else '') +
                                   '–¢–æ—á–Ω–æ—Å—Ç—å –∞–Ω–∞–ª–∏–∑–∞ –º–æ–∂–µ—Ç –±—ã—Ç—å —Å–Ω–∏–∂–µ–Ω–∞.'
                    })

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ 1: –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ª–∏ –∞–Ω–∞–ª–æ–≥–æ–≤?
        if len(similar) == 0:
            warnings.append({
                'type': 'error',
                'title': '–ê–Ω–∞–ª–æ–≥–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã',
                'message': '–ù–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∏ –æ–¥–Ω–æ–≥–æ –∞–Ω–∞–ª–æ–≥–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∏–∑–º–µ–Ω–∏—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–∏—Å–∫–∞ –∏–ª–∏ –¥–æ–±–∞–≤–∏—Ç—å –∞–Ω–∞–ª–æ–≥–∏ –≤—Ä—É—á–Ω—É—é.'
            })
        elif len(similar) < 5:
            warnings.append({
                'type': 'error',
                'title': '–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∞–Ω–∞–ª–æ–≥–æ–≤',
                'message': f'–ù–∞–π–¥–µ–Ω–æ –≤—Å–µ–≥–æ {len(similar)} –∞–Ω–∞–ª–æ–≥(–æ–≤). –î–ª—è —Ç–æ—á–Ω–æ–π –æ—Ü–µ–Ω–∫–∏ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –º–∏–Ω–∏–º—É–º 10-15 –∞–Ω–∞–ª–æ–≥–æ–≤. –î–æ–±–∞–≤—å—Ç–µ –∞–Ω–∞–ª–æ–≥–∏ –≤—Ä—É—á–Ω—É—é –∏–ª–∏ —Ä–∞—Å—à–∏—Ä—å—Ç–µ –∫—Ä–∏—Ç–µ—Ä–∏–∏ –ø–æ–∏—Å–∫–∞.'
            })
        elif len(similar) < 10:
            warnings.append({
                'type': 'warning',
                'title': '–ú–∞–ª–æ –∞–Ω–∞–ª–æ–≥–æ–≤',
                'message': f'–ù–∞–π–¥–µ–Ω–æ {len(similar)} –∞–Ω–∞–ª–æ–≥–æ–≤. –î–ª—è –±–æ–ª–µ–µ —Ç–æ—á–Ω–æ–π –æ—Ü–µ–Ω–∫–∏ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è 15-20 –∞–Ω–∞–ª–æ–≥–æ–≤. –ú–æ–∂–Ω–æ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å, –Ω–æ —Ç–æ—á–Ω–æ—Å—Ç—å –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–∏–∂–µ.'
            })

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ 2: –†–∞–∑–±—Ä–æ—Å —Ü–µ–Ω (–∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –≤–∞—Ä–∏–∞—Ü–∏–∏)
        if len(similar) >= 3:
            prices_per_sqm = [c.get('price_per_sqm', 0) for c in similar if c.get('price_per_sqm')]

            if len(prices_per_sqm) >= 3:
                import statistics
                median_price = statistics.median(prices_per_sqm)

                if median_price > 0:
                    stdev_price = statistics.stdev(prices_per_sqm)
                    cv = stdev_price / median_price  # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –≤–∞—Ä–∏–∞—Ü–∏–∏

                    if cv > 0.5:  # >50% - –æ—á–µ–Ω—å –±–æ–ª—å—à–æ–π —Ä–∞–∑–±—Ä–æ—Å
                        warnings.append({
                            'type': 'error',
                            'title': '–û—á–µ–Ω—å –±–æ–ª—å—à–æ–π —Ä–∞–∑–±—Ä–æ—Å —Ü–µ–Ω',
                            'message': f'–†–∞–∑–±—Ä–æ—Å —Ü–µ–Ω —É –∞–Ω–∞–ª–æ–≥–æ–≤ —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç {cv*100:.0f}%. –≠—Ç–æ —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ - –≤–æ–∑–º–æ–∂–Ω–æ, –∞–Ω–∞–ª–æ–≥–∏ –ø–æ–¥–æ–±—Ä–∞–Ω—ã –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å–ø–∏—Å–æ–∫ –∏ —É–¥–∞–ª–∏—Ç–µ –Ω–µ–ø–æ–¥—Ö–æ–¥—è—â–∏–µ –æ–±—ä–µ–∫—Ç—ã.'
                        })
                    elif cv > 0.3:  # >30% - –±–æ–ª—å—à–æ–π —Ä–∞–∑–±—Ä–æ—Å
                        warnings.append({
                            'type': 'warning',
                            'title': '–ë–æ–ª—å—à–æ–π —Ä–∞–∑–±—Ä–æ—Å —Ü–µ–Ω',
                            'message': f'–†–∞–∑–±—Ä–æ—Å —Ü–µ–Ω —É –∞–Ω–∞–ª–æ–≥–æ–≤ —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç {cv*100:.0f}%. –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Å–ø–∏—Å–æ–∫ –∞–Ω–∞–ª–æ–≥–æ–≤ –∏ —É–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –≤—Å–µ –æ–±—ä–µ–∫—Ç—ã –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ —Å–æ–ø–æ—Å—Ç–∞–≤–∏–º—ã.'
                        })

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ 3: –ï—Å—Ç—å –ª–∏ –∞–Ω–∞–ª–æ–≥–∏ —Å —Ü–µ–Ω–æ–π –∑–∞ –º¬≤?
        if len(similar) > 0:
            with_price = sum(1 for c in similar if c.get('price_per_sqm'))
            if with_price == 0:
                warnings.append({
                    'type': 'error',
                    'title': '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ —Ü–µ–Ω–∞—Ö',
                    'message': '–ù–∏ —É –æ–¥–Ω–æ–≥–æ –∞–Ω–∞–ª–æ–≥–∞ –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ü–µ–Ω–µ –∑–∞ –º¬≤. –ù–µ–≤–æ–∑–º–æ–∂–Ω–æ –ø—Ä–æ–≤–µ—Å—Ç–∏ –∞–Ω–∞–ª–∏–∑.'
                })
            elif with_price < len(similar) * 0.5:  # –ú–µ–Ω—å—à–µ 50% —Å —Ü–µ–Ω–æ–π
                warnings.append({
                    'type': 'warning',
                    'title': '–ù–µ–ø–æ–ª–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –æ —Ü–µ–Ω–∞—Ö',
                    'message': f'–¢–æ–ª—å–∫–æ —É {with_price} –∏–∑ {len(similar)} –∞–Ω–∞–ª–æ–≥–æ–≤ –µ—Å—Ç—å –¥–∞–Ω–Ω—ã–µ –æ —Ü–µ–Ω–µ –∑–∞ –º¬≤. –≠—Ç–æ –º–æ–∂–µ—Ç —Å–Ω–∏–∑–∏—Ç—å —Ç–æ—á–Ω–æ—Å—Ç—å –æ—Ü–µ–Ω–∫–∏.'
                })

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Å–µ—Å—Å–∏—é
        session_data['comparables'] = similar
        session_data['comparables_warnings'] = warnings  # –°–æ—Ö—Ä–∞–Ω—è–µ–º warnings –≤ —Å–µ—Å—Å–∏—é
        session_storage.set(session_id, session_data)

        # Debug logging - trace object count
        request_elapsed = time.time() - request_start
        logger.info(f"üîç Saved {len(similar)} comparables to session {session_id}")
        if warnings:
            logger.warning(f"‚ö†Ô∏è Quality warnings: {len(warnings)} issue(s) detected")
            for w in warnings:
                logger.warning(f"  - [{w['type'].upper()}] {w['title']}: {w['message']}")
        logger.info(f"‚úÖ [STEP 2] find-similar completed in {request_elapsed:.1f}s - returning {len(similar)} comparables")

        return jsonify({
            'status': 'success',
            'comparables': similar,
            'count': len(similar),
            'search_type': search_type,
            'residential_complex': residential_complex,
            'elapsed_time': round(request_elapsed, 1),
            'warnings': warnings  # –î–æ–±–∞–≤–ª—è–µ–º warnings –≤ –æ—Ç–≤–µ—Ç
        })

    except Exception as e:
        logger.error(f"‚ùå [STEP 2] find-similar failed: {e}", exc_info=True)

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –æ—à–∏–±–∫–∏ –¥–ª—è –ª—É—á—à–µ–π –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
        error_str = str(e).lower()
        error_type = 'search_error'
        user_message = '–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –∞–Ω–∞–ª–æ–≥–æ–≤'

        if 'session' in error_str or 'not found' in error_str:
            error_type = 'session_error'
            user_message = '–°–µ—Å—Å–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –∏–ª–∏ –∏—Å—Ç–µ–∫–ª–∞. –ù–∞—á–Ω–∏—Ç–µ —Å–Ω–∞—á–∞–ª–∞.'
        elif 'timeout' in error_str or 'timed out' in error_str:
            error_type = 'timeout'
            user_message = '–ü—Ä–µ–≤—ã—à–µ–Ω–æ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–∞–Ω–Ω—ã—Ö. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.'
        elif 'parsing' in error_str or 'parse' in error_str:
            error_type = 'parsing_error'
            user_message = '–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å—Ç—Ä–∞–Ω–∏—Ü –æ–±—ä—è–≤–ª–µ–Ω–∏–π. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.'
        elif 'browser' in error_str or 'playwright' in error_str:
            error_type = 'browser_error'
            user_message = '–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –±—Ä–∞—É–∑–µ—Ä–∞. –ü–æ–≤—Ç–æ—Ä–∏—Ç–µ –ø–æ–ø—ã—Ç–∫—É —á–µ—Ä–µ–∑ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–µ–∫—É–Ω–¥.'
        elif 'network' in error_str or 'connection' in error_str:
            error_type = 'network_error'
            user_message = '–û—à–∏–±–∫–∞ —Å–µ—Ç–∏ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–∞–Ω–Ω—ã—Ö. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ.'

        return jsonify({
            'status': 'error',
            'error_type': error_type,
            'message': user_message,
            'technical_details': str(e)
        }), 500


@app.route('/api/add-comparable', methods=['POST'])
def add_comparable():
    """
    API: –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∞–Ω–∞–ª–æ–≥–∞ –ø–æ URL (–≠–∫—Ä–∞–Ω 2)

    Body:
        {
            "session_id": "uuid",
            "url": "https://www.cian.ru/sale/flat/456/"
        }

    Returns:
        {
            "status": "success",
            "comparable": {...}
        }
    """
    try:
        payload = request.json
        session_id = payload.get('session_id')
        url = payload.get('url')

        if not session_id or not session_storage.exists(session_id):
            return jsonify({'status': 'error', 'message': '–°–µ—Å—Å–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞'}), 404

        # SECURITY: –í–∞–ª–∏–¥–∞—Ü–∏—è URL (–∑–∞—â–∏—Ç–∞ –æ—Ç SSRF)
        try:
            validate_url(url)
        except ValueError as e:
            logger.warning(f"URL validation failed: {e} (from {request.remote_addr})")
            return jsonify({'status': 'error', 'message': str(e)}), 400

        # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–≥–∏–æ–Ω —Ü–µ–ª–µ–≤–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞
        session_data = session_storage.get(session_id)
        target = session_data['target_property']
        target_region = target.get('region', 'spb')

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–µ–≥–∏–æ–Ω –¥–æ–±–∞–≤–ª—è–µ–º–æ–≥–æ –∞–Ω–∞–ª–æ–≥–∞ –ø–æ URL
        region = detect_region_from_url(url)
        logger.info(f"–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∞–Ω–∞–ª–æ–≥–∞: {url} (–ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π —Ä–µ–≥–∏–æ–Ω: {region}, —Ü–µ–ª–µ–≤–æ–π —Ä–µ–≥–∏–æ–Ω: {target_region})")

        # SECURITY: –ü–∞—Ä—Å–∏–º —Å timeout (–∑–∞—â–∏—Ç–∞ –æ—Ç DoS)
        try:
            logger.info(f"üîç Parsing comparable URL: {url}")
            with timeout_context(120, '–ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–Ω—è–ª —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ (>120s)'):
                with get_parser_for_url(url, region=region) as parser:
                    comparable_data = parser.parse_detail_page(url)
                    logger.info(f"‚úÖ Successfully parsed comparable: {comparable_data.get('title', 'Unknown')}")
        except TimeoutError as e:
            logger.error(f"‚ùå Parsing timeout for {url}: {e}")
            return jsonify({
                'status': 'error',
                'message': 'parsing_timeout',
                'details': '–í—Ä–µ–º—è –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –ø—Ä–µ–≤—ã—Å–∏–ª–æ 2 –º–∏–Ω—É—Ç—ã. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–æ–π –æ–±—ä–µ–∫—Ç.'
            }), 408
        except Exception as parse_error:
            logger.error(f"‚ùå Failed to parse {url}: {parse_error}", exc_info=True)
            return jsonify({
                'status': 'error',
                'message': 'parsing_error',
                'details': str(parse_error)
            }), 500

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –ø–æ–ª—É—á–∏–ª–∏ –≤–∞–ª–∏–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        if not comparable_data or not comparable_data.get('price') or not comparable_data.get('total_area'):
            logger.warning(f"‚ö†Ô∏è Parsed data incomplete: {comparable_data}")
            return jsonify({
                'status': 'error',
                'message': 'parsing_incomplete',
                'details': '–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –ø–æ–ª–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –æ–±—ä–µ–∫—Ç–∞ (—Ü–µ–Ω–∞ –∏–ª–∏ –ø–ª–æ—â–∞–¥—å –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç). –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–æ–π –æ–±—ä–µ–∫—Ç.'
            }), 400

        # –ö–†–ò–¢–ò–ß–ù–û: –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–≥–∏–æ–Ω –∞–Ω–∞–ª–æ–≥–∞
        if not region:
            address = comparable_data.get('address', '')
            region = detect_region_from_address(address)
            if region:
                logger.info(f"‚úì –†–µ–≥–∏–æ–Ω –∞–Ω–∞–ª–æ–≥–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω –ø–æ –∞–¥—Ä–µ—Å—É: {region}")
            else:
                logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ä–µ–≥–∏–æ–Ω –∞–Ω–∞–ª–æ–≥–∞ –ø–æ –∞–¥—Ä–µ—Å—É: {address}")
                region = 'spb'  # fallback

        # –ö–†–ò–¢–ò–ß–ù–û: –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–∞–µ–º –æ –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Ä–µ–≥–∏–æ–Ω–∞
        if region != target_region:
            logger.warning(f"‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï: –ê–Ω–∞–ª–æ–≥ –∏–∑ –¥—Ä—É–≥–æ–≥–æ —Ä–µ–≥–∏–æ–Ω–∞! –¶–µ–ª–µ–≤–æ–π: {target_region}, –ê–Ω–∞–ª–æ–≥: {region}")
            return jsonify({
                'status': 'error',
                'message': 'region_mismatch',
                'details': f'–≠—Ç–æ—Ç –∞–Ω–∞–ª–æ–≥ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ –¥—Ä—É–≥–æ–º —Ä–µ–≥–∏–æ–Ω–µ ({region}), –∞ —Ü–µ–ª–µ–≤–æ–π –æ–±—ä–µ–∫—Ç - –≤ —Ä–µ–≥–∏–æ–Ω–µ {target_region}. –î–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∞–Ω–∞–ª–æ–≥–∏ –∏–∑ —Ç–æ–≥–æ –∂–µ –≥–æ—Ä–æ–¥–∞.'
            }), 400

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –¥—É–±–ª–∏–∫–∞—Ç—ã
        session_data = session_storage.get(session_id)
        existing_comparables = session_data.get('comparables', [])

        if existing_comparables:
            logger.info(f"üîç Checking if new comparable is duplicate of {len(existing_comparables)} existing ones...")
            duplicates = duplicate_detector.find_duplicates(comparable_data, existing_comparables)

            if duplicates:
                # –ù–∞—Ö–æ–¥–∏–º —Å–∞–º—ã–π —É–≤–µ—Ä–µ–Ω–Ω—ã–π –¥—É–±–ª–∏–∫–∞—Ç
                best_match = max(duplicates, key=lambda d: d.confidence)

                if best_match.duplicate_type == 'strict':
                    # –°—Ç—Ä–æ–≥–∏–π –¥—É–±–ª–∏–∫–∞—Ç - –æ—Ç–∫–ª–æ–Ω—è–µ–º
                    logger.warning(f"‚ùå Strict duplicate detected: {best_match.confidence:.0f}% match")
                    existing_obj = existing_comparables[best_match.index]
                    return jsonify({
                        'status': 'error',
                        'message': 'duplicate_object',
                        'details': f'–≠—Ç–æ—Ç –æ–±—ä–µ–∫—Ç —É–∂–µ –¥–æ–±–∞–≤–ª–µ–Ω –≤ —Å–ø–∏—Å–æ–∫ –∞–Ω–∞–ª–æ–≥–æ–≤. '
                                   f'–ê–¥—Ä–µ—Å: {existing_obj.get("address", "Unknown")}, '
                                   f'—Ü–µ–Ω–∞: {existing_obj.get("price", 0):,.0f} ‚ÇΩ. '
                                   f'–°–æ–≤–ø–∞–¥–µ–Ω–∏–µ: {best_match.confidence:.0f}%.'
                    }), 400
                elif best_match.duplicate_type in ['probable', 'possible']:
                    # –í–µ—Ä–æ—è—Ç–Ω—ã–π/–≤–æ–∑–º–æ–∂–Ω—ã–π –¥—É–±–ª–∏–∫–∞—Ç - –ø–æ–º–µ—á–∞–µ–º —Ñ–ª–∞–≥–æ–º
                    logger.info(f"‚ö†Ô∏è {best_match.duplicate_type.title()} duplicate: {best_match.confidence:.0f}% match")
                    comparable_data['possible_duplicate'] = True
                    comparable_data['duplicate_confidence'] = best_match.confidence
                    comparable_data['duplicate_type'] = best_match.duplicate_type

        # –î–æ–±–∞–≤–ª—è–µ–º –≤ —Å–ø–∏—Å–æ–∫
        session_data['comparables'].append(comparable_data)
        session_storage.set(session_id, session_data)

        logger.info(f"‚úÖ Comparable added to session {session_id}, total: {len(session_data['comparables'])}")

        return jsonify({
            'status': 'success',
            'comparable': comparable_data
        })

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è: {e}", exc_info=True)
        return jsonify({
            'status': 'error',
            'message': str(e)
        }), 500


@app.route('/api/exclude-comparable', methods=['POST'])
def exclude_comparable():
    """
    API: –ò—Å–∫–ª—é—á–µ–Ω–∏–µ –∞–Ω–∞–ª–æ–≥–∞ –∏–∑ –∞–Ω–∞–ª–∏–∑–∞ (–≠–∫—Ä–∞–Ω 2)

    Body:
        {
            "session_id": "uuid",
            "index": 3
        }

    Returns:
        {
            "status": "success"
        }
    """
    try:
        payload = request.json
        session_id = payload.get('session_id')
        index = payload.get('index')

        if not session_id or not session_storage.exists(session_id):
            return jsonify({'status': 'error', 'message': '–°–µ—Å—Å–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞'}), 404

        session_data = session_storage.get(session_id)
        comparables = session_data['comparables']

        if 0 <= index < len(comparables):
            comparables[index]['excluded'] = True
            session_storage.set(session_id, session_data)

        return jsonify({'status': 'success'})

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∏—Å–∫–ª—é—á–µ–Ω–∏—è: {e}", exc_info=True)
        return jsonify({
            'status': 'error',
            'message': str(e)
        }), 500


@app.route('/api/include-comparable', methods=['POST'])
def include_comparable():
    """
    API: –í–æ–∑–≤—Ä–∞—Ç –∞–Ω–∞–ª–æ–≥–∞ –≤ –∞–Ω–∞–ª–∏–∑ (–≠–∫—Ä–∞–Ω 2)

    Body:
        {
            "session_id": "uuid",
            "index": 3
        }

    Returns:
        {
            "status": "success"
        }
    """
    try:
        payload = request.json
        session_id = payload.get('session_id')
        index = payload.get('index')

        if not session_id or not session_storage.exists(session_id):
            return jsonify({'status': 'error', 'message': '–°–µ—Å—Å–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞'}), 404

        session_data = session_storage.get(session_id)
        comparables = session_data['comparables']

        if 0 <= index < len(comparables):
            comparables[index]['excluded'] = False
            session_storage.set(session_id, session_data)

        return jsonify({'status': 'success'})

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤–æ–∑–≤—Ä–∞—Ç–∞: {e}", exc_info=True)
        return jsonify({
            'status': 'error',
            'message': str(e)
        }), 500


@app.route('/api/analyze', methods=['POST'])
@limiter.limit("20 per minute")  # –ê–Ω–∞–ª–∏–∑ - –º–µ–Ω–µ–µ expensive
def analyze():
    """
    API: –ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ (–≠–∫—Ä–∞–Ω 3)

    Body:
        {
            "session_id": "uuid",
            "filter_outliers": true,
            "use_median": true
        }

    Returns:
        {
            "status": "success",
            "analysis": {...}
        }
    """
    try:
        payload = request.json
        session_id = payload.get('session_id')
        filter_outliers = payload.get('filter_outliers', True)
        use_median = payload.get('use_median', True)

        if not session_id or not session_storage.exists(session_id):
            return jsonify({'status': 'error', 'message': '–°–µ—Å—Å–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞'}), 404

        session_data = session_storage.get(session_id)

        logger.info(f"–ê–Ω–∞–ª–∏–∑ –¥–ª—è —Å–µ—Å—Å–∏–∏ {session_id}")

        # –í–∞–ª–∏–¥–∞—Ü–∏—è –∏ —Å–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
        try:
            # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —É—Ç–∏–ª–∏—Ç—ã –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏
            from src.models.property import normalize_property_data, validate_property_consistency

            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Ü–µ–ª–µ–≤–æ–π –æ–±—ä–µ–∫—Ç
            normalized_target = normalize_property_data(session_data['target_property'])
            target_property = TargetProperty(**normalized_target)

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å
            warnings = validate_property_consistency(target_property)
            if warnings:
                logger.warning(f"–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {warnings}")

            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∞–Ω–∞–ª–æ–≥–∏
            comparables = [
                ComparableProperty(**normalize_property_data(c))
                for c in session_data['comparables']
            ]

            request_model = AnalysisRequest(
                target_property=target_property,
                comparables=comparables,
                filter_outliers=filter_outliers,
                use_median=use_median
            )

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {e}", exc_info=True)
            return jsonify({
                'status': 'error',
                'error_type': 'data_validation_error',
                'message': '–û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö –∞–Ω–∞–ª–æ–≥–æ–≤. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –≤–≤–µ–¥–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.',
                'technical_details': str(e)
            }), 400

        # –ê–Ω–∞–ª–∏–∑
        analyzer = RealEstateAnalyzer()
        try:
            result = analyzer.analyze(request_model)
        except ValueError as ve:
            # PATCH 4: –°–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –æ—à–∏–±–∫–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Å –¥–µ—Ç–∞–ª—å–Ω—ã–º–∏ —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏
            error_str = str(ve).lower()
            logger.warning(f"–û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∞–Ω–∞–ª–∏–∑–∞: {ve}")

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –æ—à–∏–±–∫–∏ –¥–ª—è –±–æ–ª–µ–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
            if '–Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∞–Ω–∞–ª–æ–≥–æ–≤' in error_str or 'insufficient' in error_str:
                error_type = 'insufficient_comparables'
                user_message = str(ve)
            elif '—Ü–µ–Ω–∞' in error_str or 'price' in error_str:
                error_type = 'invalid_price_data'
                user_message = f'–ü—Ä–æ–±–ª–µ–º–∞ —Å –¥–∞–Ω–Ω—ã–º–∏ –æ —Ü–µ–Ω–∞—Ö: {ve}'
            elif '–ø–ª–æ—â–∞–¥—å' in error_str or 'area' in error_str:
                error_type = 'invalid_area_data'
                user_message = f'–ü—Ä–æ–±–ª–µ–º–∞ —Å –¥–∞–Ω–Ω—ã–º–∏ –æ –ø–ª–æ—â–∞–¥–∏: {ve}'
            else:
                error_type = 'validation_error'
                user_message = str(ve)

            return jsonify({
                'status': 'error',
                'error_type': error_type,
                'message': user_message,
                'details': str(ve)
            }), 422
        except Exception as analysis_error:
            # PATCH 4: –õ—é–±—ã–µ –¥—Ä—É–≥–∏–µ –æ—à–∏–±–∫–∏ –∞–Ω–∞–ª–∏–∑–∞ —Å –¥–µ—Ç–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
            error_str = str(analysis_error)
            logger.error(f"–û—à–∏–±–∫–∞ –≤–æ –≤—Ä–µ–º—è –∞–Ω–∞–ª–∏–∑–∞: {analysis_error}", exc_info=True)

            # –ü—ã—Ç–∞–µ–º—Å—è –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ç–∏–ø –æ—à–∏–±–∫–∏
            error_type = 'analysis_error'
            if 'pydantic' in error_str.lower() or 'validation' in error_str.lower():
                error_type = 'data_validation_error'
                user_message = '–û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö –∞–Ω–∞–ª–æ–≥–æ–≤. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –≤–≤–µ–¥–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.'
            elif 'division' in error_str.lower() or 'zerodivision' in error_str.lower():
                error_type = 'calculation_error'
                user_message = '–û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–æ–≤. –í–æ–∑–º–æ–∂–Ω–æ, –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–∞–Ω–Ω—ã–µ.'
            elif 'key' in error_str.lower():
                error_type = 'missing_data_error'
                user_message = '–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–æ–ª—è –¥–∞–Ω–Ω—ã—Ö. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–æ–ª–Ω–æ—Ç—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–± –∞–Ω–∞–ª–æ–≥–∞—Ö.'
            else:
                user_message = f'–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {error_str[:200]}'  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É

            return jsonify({
                'status': 'error',
                'error_type': error_type,
                'message': user_message,
                'technical_details': error_str
            }), 500

        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ JSON
        try:
            result_dict = result.dict()
        except Exception as dict_error:
            logger.error(f"–û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –≤ dict: {dict_error}", exc_info=True)
            return jsonify({
                'status': 'error',
                'error_type': 'serialization_error',
                'message': '–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞'
            }), 500

        # –í–∞–ª–∏–¥–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –ø–µ—Ä–µ–¥ –æ—Ç–ø—Ä–∞–≤–∫–æ–π
        required_fields = ['market_statistics', 'fair_price_analysis', 'price_scenarios',
                          'strengths_weaknesses', 'target_property']
        missing_fields = [field for field in required_fields if not result_dict.get(field)]

        if missing_fields:
            logger.warning(f"–†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–æ–ª–µ–π: {missing_fields}")
            # –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Å—Ç—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏—Ö –ø–æ–ª–µ–π
            for field in missing_fields:
                if field == 'price_scenarios':
                    result_dict[field] = []
                else:
                    result_dict[field] = {}

        # –ú–µ—Ç—Ä–∏–∫–∏
        try:
            metrics = analyzer.get_metrics()
            result_dict['metrics'] = metrics
        except Exception as metrics_error:
            logger.warning(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫: {metrics_error}")
            result_dict['metrics'] = {}

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ñ—Ñ–µ—Ä Housler
        try:
            housler_offer = generate_housler_offer(
                analysis=result_dict,
                property_info=session_data.get('target_property', {}),
                recommendations=result_dict.get('recommendations', [])
            )
            if housler_offer:
                result_dict['housler_offer'] = housler_offer
            else:
                result_dict['housler_offer'] = None
                logger.warning("–û—Ñ—Ñ–µ—Ä –Ω–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω (–Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö)")
        except Exception as offer_error:
            logger.warning(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ñ—Ñ–µ—Ä–∞: {offer_error}")
            result_dict['housler_offer'] = None

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Å–µ—Å—Å–∏—é
        session_data['analysis'] = result_dict
        session_data['step'] = 3
        session_storage.set(session_id, session_data)

        return jsonify({
            'status': 'success',
            'analysis': result_dict
        })

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {e}", exc_info=True)
        return jsonify({
            'status': 'error',
            'error_type': 'internal_error',
            'message': str(e)
        }), 500


@app.route('/api/session/<session_id>', methods=['GET'])
def get_session(session_id):
    """
    API: –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —Å–µ—Å—Å–∏–∏

    Returns:
        {
            "status": "success",
            "data": {...}
        }
    """
    if not session_storage.exists(session_id):
        return jsonify({'status': 'error', 'message': '–°–µ—Å—Å–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞'}), 404

    return jsonify({
        'status': 'success',
        'data': session_storage.get(session_id)
    })


@app.route('/api/cache/stats', methods=['GET'])
def cache_stats():
    """
    API: –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫—ç—à–∞

    Returns:
        {
            "status": "success",
            "stats": {
                "status": "active|disabled",
                "hit_rate": 85.5,
                "total_keys": 123,
                ...
            }
        }
    """
    try:
        stats = property_cache.get_stats()
        return jsonify({
            'status': 'success',
            'stats': stats
        })
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∫—ç—à–∞: {e}")
        return jsonify({
            'status': 'error',
            'message': str(e)
        }), 500


@app.route('/api/cache/clear', methods=['POST'])
def cache_clear():
    """
    API: –û—á–∏—Å—Ç–∫–∞ –∫—ç—à–∞ (–¥–ª—è –∞–¥–º–∏–Ω–æ–≤)

    Body:
        {
            "pattern": "*"  # optional, default: –≤—Å–µ
        }

    Returns:
        {
            "status": "success",
            "deleted": 42
        }
    """
    try:
        pattern = request.json.get('pattern', '*') if request.json else '*'
        deleted = property_cache.clear_all(pattern)

        return jsonify({
            'status': 'success',
            'deleted': deleted,
            'pattern': pattern
        })
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –∫—ç—à–∞: {e}")
        return jsonify({
            'status': 'error',
            'message': str(e)
        }), 500


@app.route('/api/export-report/<session_id>', methods=['GET'])
def export_report(session_id):
    """
    API: –≠–∫—Å–ø–æ—Ä—Ç –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞ –≤ PDF (–≠–∫—Ä–∞–Ω 3)

    Returns:
        PDF —Ñ–∞–π–ª –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è —Å –ø–æ–ª–Ω—ã–º –≤–∏–∑—É–∞–ª—å–Ω—ã–º –æ—Ç—á–µ—Ç–æ–º
    """
    try:
        if not session_storage.exists(session_id):
            return jsonify({'status': 'error', 'message': '–°–µ—Å—Å–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞'}), 404

        session_data = session_storage.get(session_id)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∞–Ω–∞–ª–∏–∑ –≤—ã–ø–æ–ª–Ω–µ–Ω
        if 'analysis' not in session_data or not session_data['analysis']:
            return jsonify({
                'status': 'error',
                'message': '–ê–Ω–∞–ª–∏–∑ –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω. –°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ –∞–Ω–∞–ª–∏–∑ –Ω–∞ —à–∞–≥–µ 3.'
            }), 400

        logger.info(f"–≠–∫—Å–ø–æ—Ä—Ç PDF –æ—Ç—á–µ—Ç–∞ –¥–ª—è —Å–µ—Å—Å–∏–∏ {session_id}")

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º PDF –∏—Å–ø–æ–ª—å–∑—É—è Playwright
        from datetime import datetime
        import asyncio

        if not PLAYWRIGHT_AVAILABLE:
            # Fallback to markdown if playwright not available
            logger.warning("Playwright –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º markdown")
            return _export_markdown_fallback(session_id, session_data)

        # –°–æ–∑–¥–∞–µ–º URL –¥–ª—è HTML –æ—Ç—á–µ—Ç–∞
        base_url = request.url_root.rstrip('/')
        report_url = f"{base_url}/report/{session_id}"

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º PDF
        pdf_bytes = asyncio.run(_generate_pdf_from_page(report_url))

        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º PDF —Ñ–∞–π–ª
        from flask import Response
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"housler_report_{session_id[:8]}_{timestamp}.pdf"

        return Response(
            pdf_bytes,
            mimetype='application/pdf',
            headers={
                'Content-Disposition': f'attachment; filename="{filename}"',
                'Content-Type': 'application/pdf'
            }
        )

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞ –æ—Ç—á–µ—Ç–∞: {e}", exc_info=True)
        return jsonify({
            'status': 'error',
            'message': f'–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç—á–µ—Ç–∞: {str(e)}'
        }), 500


@app.route('/report/<session_id>', methods=['GET'])
def view_report(session_id):
    """
    –ü—Ä–æ—Å–º–æ—Ç—Ä HTML –æ—Ç—á–µ—Ç–∞ (–¥–ª—è PDF –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏)
    """
    try:
        if not session_storage.exists(session_id):
            return "–°–µ—Å—Å–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞", 404

        session_data = session_storage.get(session_id)

        if 'analysis' not in session_data or not session_data['analysis']:
            return "–ê–Ω–∞–ª–∏–∑ –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω", 400

        analysis = session_data['analysis']
        target = session_data.get('target_property', {})
        comparables = session_data.get('comparables', [])

        # –§–∏–ª—å—Ç—Ä—É–µ–º –∏—Å–∫–ª—é—á–µ–Ω–Ω—ã–µ –∞–Ω–∞–ª–æ–≥–∏
        comparables = [c for c in comparables if not c.get('excluded', False)]

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ñ—Ñ–µ—Ä Housler
        housler_offer = generate_housler_offer(
            analysis=analysis,
            property_info=target,
            recommendations=analysis.get('recommendations', [])
        )

        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —à–∞–±–ª–æ–Ω–∞
        template_data = {
            'date': datetime.now().strftime('%Y-%m-%d %H:%M'),
            'property_info': target,
            'comparables': comparables,
            'fair_price_analysis': analysis.get('fair_price_analysis', {}),
            'market_statistics': analysis.get('market_statistics', {}),
            'recommendations': analysis.get('recommendations', []),
            'price_scenarios': analysis.get('price_scenarios', []),
            'time_forecast': analysis.get('time_forecast', {}),
            'attractiveness_index': analysis.get('attractiveness_index', {}),
            'strengths_weaknesses': analysis.get('strengths_weaknesses', {}),
            'housler_offer': housler_offer
        }

        return render_template('report.html', **template_data)

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –æ—Ç—á–µ—Ç–∞: {e}", exc_info=True)
        return f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç—á–µ—Ç–∞: {str(e)}", 500


@app.route('/api/contact-request', methods=['POST'])
def contact_request():
    """
    –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞—è–≤–∫–∏ –Ω–∞ –∫–æ–Ω—Ç–∞–∫—Ç –æ—Ç –∫–ª–∏–µ–Ω—Ç–∞
    """
    try:
        data = request.get_json()

        name = data.get('name', '').strip()
        phone = data.get('phone', '').strip()
        email = data.get('email', '').strip()
        comment = data.get('comment', '').strip()
        session_id = data.get('session_id', '')

        # –í–∞–ª–∏–¥–∞—Ü–∏—è –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–æ–ª–µ–π
        if not name or not phone:
            return jsonify({'error': '–ò–º—è –∏ —Ç–µ–ª–µ—Ñ–æ–Ω –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã'}), 400

        # –õ–æ–≥–∏—Ä—É–µ–º –∑–∞—è–≤–∫—É
        logger.info(f"=== –ù–û–í–ê–Ø –ó–ê–Ø–í–ö–ê –ù–ê –ö–û–ù–¢–ê–ö–¢ ===")
        logger.info(f"–ò–º—è: {name}")
        logger.info(f"–¢–µ–ª–µ—Ñ–æ–Ω: {phone}")
        logger.info(f"Email: {email if email else '–Ω–µ —É–∫–∞–∑–∞–Ω'}")
        logger.info(f"–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π: {comment if comment else '–Ω–µ—Ç'}")
        logger.info(f"Session ID: {session_id}")
        logger.info(f"================================")

        # TODO: –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å:
        # - –û—Ç–ø—Ä–∞–≤–∫—É email —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è
        # - –û—Ç–ø—Ä–∞–≤–∫—É –≤ CRM
        # - –û—Ç–ø—Ä–∞–≤–∫—É –≤ Telegram
        # - –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö

        # –ü–æ–∫–∞ –ø—Ä–æ—Å—Ç–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —É—Å–ø–µ—Ö
        return jsonify({
            'success': True,
            'message': '–ó–∞—è–≤–∫–∞ –ø—Ä–∏–Ω—è—Ç–∞'
        }), 200

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞—è–≤–∫–∏: {e}", exc_info=True)
        return jsonify({'error': '–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞'}), 500


async def _generate_pdf_from_page(url: str) -> bytes:
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç PDF –∏–∑ HTML —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∏—Å–ø–æ–ª—å–∑—É—è Playwright
    """
    from playwright.async_api import async_playwright

    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True)
        page = await browser.new_page()

        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É
        logger.info(f"–ó–∞–≥—Ä—É–∂–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É –¥–ª—è PDF: {url}")
        await page.goto(url, wait_until='networkidle', timeout=60000)

        # –ñ–¥–µ–º –∑–∞–≥—Ä—É–∑–∫–∏ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ (report-container –≤–º–µ—Å—Ç–æ analysis-results)
        try:
            await page.wait_for_selector('.report-container', timeout=10000)
        except Exception as e:
            logger.warning(f"–ù–µ –¥–æ–∂–¥–∞–ª–∏—Å—å report-container: {e}, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º...")

        # –î–∞–µ–º –≤—Ä–µ–º—è –Ω–∞ –∑–∞–≥—Ä—É–∑–∫—É —à—Ä–∏—Ñ—Ç–æ–≤ –∏ —Å—Ç–∏–ª–µ–π
        await page.wait_for_timeout(2000)

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º PDF
        logger.info("–ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º PDF...")
        pdf_bytes = await page.pdf(
            format='A4',
            margin={
                'top': '15mm',
                'right': '12mm',
                'bottom': '15mm',
                'left': '12mm'
            },
            print_background=True,
            prefer_css_page_size=False,
            display_header_footer=False
        )

        await browser.close()
        logger.info(f"PDF —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω, —Ä–∞–∑–º–µ—Ä: {len(pdf_bytes)} bytes")
        return pdf_bytes


def _export_markdown_fallback(session_id: str, session_data: dict):
    """
    Fallback —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞ –≤ markdown –µ—Å–ª–∏ playwright –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω
    """
    from src.analytics.property_tracker import PropertyLog
    from src.analytics.markdown_exporter import MarkdownExporter
    from datetime import datetime
    from flask import Response

    # –°–æ–∑–¥–∞–µ–º PropertyLog –∏–∑ –¥–∞–Ω–Ω—ã—Ö —Å–µ—Å—Å–∏–∏
    property_log = PropertyLog(
        property_id=session_id,
        url=session_data.get('target_property', {}).get('url'),
        started_at=datetime.now().isoformat(),
        completed_at=datetime.now().isoformat(),
        status='completed'
    )

    # –ó–∞–ø–æ–ª–Ω—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –æ–±—ä–µ–∫—Ç–µ
    target = session_data.get('target_property', {})
    property_log.property_info = {
        'price': target.get('price'),
        'total_area': target.get('total_area'),
        'rooms': target.get('rooms'),
        'floor': target.get('floor'),
        'total_floors': target.get('total_floors'),
        'address': target.get('address')
    }

    # –î–æ–±–∞–≤–ª—è–µ–º –∞–Ω–∞–ª–æ–≥–∏
    comparables = session_data.get('comparables', [])
    property_log.comparables_data = [
        {
            'price': c.get('price'),
            'total_area': c.get('total_area'),
            'price_per_sqm': c.get('price_per_sqm'),
            'address': c.get('address'),
            'url': c.get('url')
        }
        for c in comparables
        if not c.get('excluded', False)
    ]

    # –ó–∞–ø–æ–ª–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞
    analysis = session_data['analysis']
    if 'market_statistics' in analysis:
        property_log.market_stats = analysis['market_statistics']
    if 'fair_price_analysis' in analysis:
        property_log.fair_price_result = analysis['fair_price_analysis']
    if 'price_range' in analysis:
        property_log.price_range = analysis['price_range']
    if 'attractiveness_index' in analysis:
        property_log.attractiveness_index = analysis['attractiveness_index']
    if 'time_forecast' in analysis:
        property_log.time_forecast = analysis['time_forecast']
    if 'price_sensitivity' in analysis:
        property_log.price_sensitivity = analysis['price_sensitivity']
    if 'price_scenarios' in analysis:
        property_log.scenarios = analysis['price_scenarios']
    if 'adjustments_applied' in analysis:
        property_log.adjustments = analysis['adjustments_applied']
    if 'metrics' in analysis:
        property_log.metrics = analysis['metrics']
    if 'recommendations' in analysis:
        property_log.recommendations = analysis['recommendations']

    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º Markdown –æ—Ç—á–µ—Ç
    exporter = MarkdownExporter()
    markdown_content = exporter.export_single_property(property_log)

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"housler_report_{session_id[:8]}_{timestamp}.md"

    return Response(
        markdown_content,
        mimetype='text/markdown',
        headers={
            'Content-Disposition': f'attachment; filename="{filename}"',
            'Content-Type': 'text/markdown; charset=utf-8'
        }
    )


def _identify_missing_fields(parsed_data: Dict) -> List[Dict]:
    """
    –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –ø–æ–ª—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞

    Returns:
        –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏—Ö –ø–æ–ª—è—Ö
    """
    missing = []

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # –ù–û–í–ê–Ø –ö–õ–ê–°–¢–ï–†–ù–ê–Ø –°–ò–°–¢–ï–ú–ê –ü–û–õ–ï–ô (6 –∫–ª–∞—Å—Ç–µ—Ä–æ–≤, 20 –ø–æ–ª–µ–π)
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

    required_fields = [
        # –ö–õ–ê–°–¢–ï–† 1: –û–¢–î–ï–õ–ö–ê
        {
            'field': 'repair_level',
            'label': 'üé® –£—Ä–æ–≤–µ–Ω—å –æ—Ç–¥–µ–ª–∫–∏',
            'type': 'select',
            'options': ['—á–µ—Ä–Ω–æ–≤–∞—è', '—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è', '—É–ª—É—á—à–µ–Ω–Ω–∞—è', '–ø—Ä–µ–º–∏—É–º', '–ª—é–∫—Å'],
            'description': '–ö–∞—á–µ—Å—Ç–≤–æ –æ—Ç–¥–µ–ª–∫–∏ (–≤–∞–∂–Ω—ã–π —Ñ–∞–∫—Ç–æ—Ä —Ü–µ–Ω—ã)',
            'default': '—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è'
        },

        # –ö–õ–ê–°–¢–ï–† 2: –•–ê–†–ê–ö–¢–ï–†–ò–°–¢–ò–ö–ò –ö–í–ê–†–¢–ò–†–´
        {
            'field': 'ceiling_height',
            'label': 'üìè –í—ã—Å–æ—Ç–∞ –ø–æ—Ç–æ–ª–∫–æ–≤, –º',
            'type': 'number',
            'description': '–í—ã—Å–æ—Ç–∞ –ø–æ—Ç–æ–ª–∫–æ–≤ –≤ –º–µ—Ç—Ä–∞—Ö (–Ω–∞–ø—Ä–∏–º–µ—Ä, 2.7)',
            'default': 2.7
        },
        {
            'field': 'bathrooms',
            'label': 'üöø –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∞–Ω—É–∑–ª–æ–≤',
            'type': 'select',
            'options': ['1', '2', '3'],
            'description': '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∞–Ω–Ω—ã—Ö/—Å–∞–Ω—É–∑–ª–æ–≤',
            'default': '1'
        },
        {
            'field': 'window_type',
            'label': 'ü™ü –¢–∏–ø –æ–∫–æ–Ω',
            'type': 'select',
            'options': ['–¥–µ—Ä–µ–≤—è–Ω–Ω—ã–µ', '–ø–ª–∞—Å—Ç–∏–∫–æ–≤—ã–µ', '–ø–∞–Ω–æ—Ä–∞–º–Ω—ã–µ'],
            'description': '–¢–∏–ø —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö –æ–∫–æ–Ω',
            'default': '–ø–ª–∞—Å—Ç–∏–∫–æ–≤—ã–µ'
        },
        {
            'field': 'elevator_count',
            'label': 'üõó –õ–∏—Ñ—Ç—ã',
            'type': 'select',
            'options': ['0', '1', '2+'],
            'description': '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ª–∏—Ñ—Ç–æ–≤ –≤ –¥–æ–º–µ',
            'default': '1'
        },
        {
            'field': 'living_area',
            'label': 'üè† –ñ–∏–ª–∞—è –ø–ª–æ—â–∞–¥—å, –º¬≤',
            'type': 'number',
            'description': '–ñ–∏–ª–∞—è –ø–ª–æ—â–∞–¥—å –∫–≤–∞—Ä—Ç–∏—Ä—ã (–±–µ–∑ –∫—É—Ö–Ω–∏ –∏ –∫–æ—Ä–∏–¥–æ—Ä–æ–≤)',
            'default': None
        },

        # –ö–õ–ê–°–¢–ï–† 3: –í–ò–î –ò –≠–°–¢–ï–¢–ò–ö–ê
        {
            'field': 'view_type',
            'label': 'üåÖ –í–∏–¥ –∏–∑ –æ–∫–Ω–∞',
            'type': 'select',
            'options': ['–¥–æ–º', '—É–ª–∏—Ü–∞', '–ø–∞—Ä–∫', '–≤–æ–¥–∞', '–≥–æ—Ä–æ–¥', '–∑–∞–∫–∞—Ç', '–ø—Ä–µ–º–∏—É–º'],
            'description': '–ß—Ç–æ –≤–∏–¥–Ω–æ –∏–∑ –æ–∫–æ–Ω (–≤–ª–∏—è–µ—Ç –Ω–∞ —Å—Ç–æ–∏–º–æ—Å—Ç—å)',
            'default': '—É–ª–∏—Ü–∞'
        },

        # –ö–õ–ê–°–¢–ï–† 4: –†–ò–°–ö–ò –ò –ö–ê–ß–ï–°–¢–í–û –ú–ê–¢–ï–†–ò–ê–õ–û–í
        {
            'field': 'material_quality',
            'label': 'üì∏ –ö–∞—á–µ—Å—Ç–≤–æ —Ñ–æ—Ç–æ/–º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤',
            'type': 'select',
            'options': ['–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ_—Ñ–æ—Ç–æ_–≤–∏–¥–µ–æ', '–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ_—Ñ–æ—Ç–æ', '—Ç–æ–ª—å–∫–æ_—Ä–µ–Ω–¥–µ—Ä—ã', '—Ç–æ–ª—å–∫–æ_–ø–ª–∞–Ω–∏—Ä–æ–≤–∫–∞'],
            'description': '–ö–∞–∫–∏–µ –≤–∏–∑—É–∞–ª—å–Ω—ã–µ –º–∞—Ç–µ—Ä–∏–∞–ª—ã –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω—ã –≤ –æ–±—ä—è–≤–ª–µ–Ω–∏–∏',
            'default': '–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ_—Ñ–æ—Ç–æ'
        },
        {
            'field': 'ownership_status',
            'label': 'üìã –°—Ç–∞—Ç—É—Å —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏',
            'type': 'select',
            'options': ['1_—Å–æ–±—Å—Ç–≤–µ–Ω–Ω–∏–∫_–±–µ–∑_–æ–±—Ä–µ–º–µ–Ω–µ–Ω–∏–π', '1+_—Å–æ–±—Å—Ç–≤–µ–Ω–Ω–∏–∫–æ–≤_–±–µ–∑_–æ–±—Ä–µ–º–µ–Ω–µ–Ω–∏–π', '–∏–ø–æ—Ç–µ–∫–∞_—Ä–∞—Å—Å—Ä–æ—á–∫–∞', '–µ—Å—Ç—å_–æ–±—Ä–µ–º–µ–Ω–µ–Ω–∏—è'],
            'description': '–Æ—Ä–∏–¥–∏—á–µ—Å–∫–∏–π —Å—Ç–∞—Ç—É—Å –æ–±—ä–µ–∫—Ç–∞',
            'default': '1_—Å–æ–±—Å—Ç–≤–µ–Ω–Ω–∏–∫_–±–µ–∑_–æ–±—Ä–µ–º–µ–Ω–µ–Ω–∏–π'
        },
    ]

    # –ú–∞–ø–ø–∏–Ω–≥ –ø–æ–ª–µ–π –Ω–∞ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
    characteristics_mapping = {
        'ceiling_height': '–í—ã—Å–æ—Ç–∞ –ø–æ—Ç–æ–ª–∫–æ–≤',
        'build_year': '–ì–æ–¥ –ø–æ—Å—Ç—Ä–æ–π–∫–∏',
        'house_type': '–¢–∏–ø –¥–æ–º–∞',
        'has_elevator': '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ª–∏—Ñ—Ç–æ–≤',
        'elevator_count': '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ª–∏—Ñ—Ç–æ–≤',
        'living_area': '–ñ–∏–ª–∞—è –ø–ª–æ—â–∞–¥—å',
        'bathrooms': '–°–∞–Ω—É–∑–µ–ª',
        'window_type': '–û–∫–Ω–∞',
    }

    characteristics = parsed_data.get('characteristics', {})

    for field_info in required_fields:
        field = field_info['field']

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–Ω–∞—á–∞–ª–∞ –≤ –∫–æ—Ä–Ω–µ –¥–∞–Ω–Ω—ã—Ö
        if field in parsed_data and parsed_data[field] is not None:
            continue

        # –ó–∞—Ç–µ–º –ø—Ä–æ–≤–µ—Ä—è–µ–º –≤ characteristics
        char_key = characteristics_mapping.get(field)
        if char_key and char_key in characteristics:
            # –ü–æ–ª–µ –Ω–∞–π–¥–µ–Ω–æ –≤ characteristics - –Ω–µ –¥–æ–±–∞–≤–ª—è–µ–º –≤ missing
            continue

        # –ü–æ–ª–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ - –¥–æ–±–∞–≤–ª—è–µ–º –≤ missing
        missing.append(field_info)

    return missing


# CLEANUP: Shutdown handler –¥–ª—è browser pool
import atexit
import signal

def shutdown_browser_pool():
    """–ó–∞–∫—Ä—ã–≤–∞–µ—Ç browser pool –ø—Ä–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
    if browser_pool:
        logger.info("Shutting down browser pool...")
        try:
            browser_pool.shutdown()
        except Exception as e:
            logger.error(f"Error shutting down browser pool: {e}")

# –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
atexit.register(shutdown_browser_pool)

def signal_handler(signum, frame):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Å–∏–≥–Ω–∞–ª–æ–≤ –¥–ª—è graceful shutdown"""
    logger.info(f"Received signal {signum}, shutting down...")
    shutdown_browser_pool()
    exit(0)

# –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ —Å–∏–≥–Ω–∞–ª–æ–≤
signal.signal(signal.SIGTERM, signal_handler)
signal.signal(signal.SIGINT, signal_handler)


if __name__ == '__main__':
    try:
        app.run(debug=True, host='0.0.0.0', port=5002)
    finally:
        shutdown_browser_pool()
