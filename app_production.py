"""
Production-ready –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å —Å Redis, PostgreSQL, –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–æ–º
–£–ª—É—á—à–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è app_new.py —Å –ø–æ–ª–Ω–æ–π –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π –Ω–æ–≤—ã—Ö –º–æ–¥—É–ª–µ–π
"""

from flask import Flask, render_template, request, jsonify
import os
import uuid
from typing import Dict, List
from datetime import datetime
import time

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
from dotenv import load_dotenv
load_dotenv()

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
from src.utils.logger import (
    setup_logging,
    get_logger,
    log_execution_time,
    log_api_call,
    get_metrics,
    monitor
)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
setup_logging(
    level=os.getenv('LOG_LEVEL', 'INFO'),
    log_file=os.getenv('LOG_FILE'),
    json_logs=os.getenv('LOG_JSON', 'false').lower() == 'true',
    colored_console=True
)

logger = get_logger(__name__)

# Storage managers
from src.storage.redis_manager import get_session_manager
from src.storage.postgres_manager import get_postgres_manager
from src.storage.cache_manager import get_cache_manager

# Parsers
from src.parsers.playwright_parser import PlaywrightParser
from src.parsers.async_parser import AsyncCianParser

# Analytics
from src.analytics.analyzer import RealEstateAnalyzer
from src.models.property import (
    TargetProperty,
    ComparableProperty,
    AnalysisRequest
)

# Flask app
app = Flask(__name__)
app.secret_key = os.getenv('SECRET_KEY', os.urandom(24))

# ==========================================
# Initialize storage managers
# ==========================================
logger.info("üöÄ Initializing storage managers...")

# Redis –¥–ª—è —Å–µ—Å—Å–∏–π
try:
    session_manager = get_session_manager(
        host=os.getenv('REDIS_HOST'),
        port=int(os.getenv('REDIS_PORT', 6379)),
        password=os.getenv('REDIS_PASSWORD'),
        ttl=int(os.getenv('REDIS_TTL', 3600)),
        use_fallback=True  # Fallback –Ω–∞ in-memory –µ—Å–ª–∏ Redis –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω
    )
    logger.info("‚úÖ Redis Session Manager initialized")
except Exception as e:
    logger.warning(f"‚ö†Ô∏è Redis initialization failed, using fallback: {e}")
    session_manager = get_session_manager(use_fallback=True)

# PostgreSQL –¥–ª—è –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö
postgres_manager = None
try:
    postgres_manager = get_postgres_manager(
        host=os.getenv('POSTGRES_HOST'),
        port=int(os.getenv('POSTGRES_PORT', 5432)),
        database=os.getenv('POSTGRES_DB'),
        user=os.getenv('POSTGRES_USER'),
        password=os.getenv('POSTGRES_PASSWORD')
    )
    logger.info("‚úÖ PostgreSQL Manager initialized")
except Exception as e:
    logger.warning(f"‚ö†Ô∏è PostgreSQL initialization failed: {e}")

# Cache Manager
cache_enabled = os.getenv('CACHE_ENABLED', 'true').lower() == 'true'
if cache_enabled:
    cache_manager = get_cache_manager(
        redis_manager=session_manager,
        postgres_manager=postgres_manager,
        use_memory=True,
        memory_max_size=int(os.getenv('CACHE_MEMORY_MAX_SIZE', 100))
    )
    logger.info("‚úÖ Cache Manager initialized")
else:
    cache_manager = None
    logger.info("‚ÑπÔ∏è Caching disabled")

logger.info("‚úÖ All managers initialized successfully")


# ==========================================
# Routes
# ==========================================

@app.route('/')
def index():
    """–ì–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ - –≠–∫—Ä–∞–Ω 1: –ü–∞—Ä—Å–∏–Ω–≥"""
    logger.info("üìÑ Main page loaded")
    return render_template('wizard.html')


@app.route('/api/parse', methods=['POST'])
@log_api_call()
def parse_url():
    """
    API: –ü–∞—Ä—Å–∏–Ω–≥ URL —Ü–µ–ª–µ–≤–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞ (–≠–∫—Ä–∞–Ω 1)

    Body:
        {
            "url": "https://www.cian.ru/sale/flat/123/"
        }

    Returns:
        {
            "status": "success",
            "data": {...},
            "session_id": "uuid",
            "missing_fields": ["field1", "field2"],
            "cached": true/false
        }
    """
    try:
        data = request.json
        url = data.get('url')

        if not url:
            return jsonify({'status': 'error', 'message': 'URL –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω'}), 400

        logger.info(f"üï∑Ô∏è Parsing URL: {url}")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
        cached_data = None
        if cache_manager:
            with monitor('cache_lookup'):
                cached_data = cache_manager.get('property', url)

        if cached_data:
            logger.info(f"üíæ Using cached data for: {url}")
            parsed_data = cached_data
            from_cache = True
        else:
            # –ü–∞—Ä—Å–∏–Ω–≥ —á–µ—Ä–µ–∑ Playwright
            with monitor('parse_property'):
                with PlaywrightParser(headless=True, delay=1.0) as parser:
                    parsed_data = parser.parse_detail_page(url)

            from_cache = False

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à
            if cache_manager and parsed_data:
                cache_manager.set(
                    'property',
                    url,
                    parsed_data,
                    ttl=3600,
                    save_to_postgres=True if postgres_manager else False,
                    postgres_ttl_hours=24
                )
                logger.info(f"üíæ Cached parsed data for: {url}")

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –ø–æ–ª—è
        missing_fields = _identify_missing_fields(parsed_data)

        # –°–æ–∑–¥–∞–µ–º —Å–µ—Å—Å–∏—é
        session_id = str(uuid.uuid4())
        session_data = {
            'target_property': parsed_data,
            'comparables': [],
            'created_at': datetime.now().isoformat(),
            'step': 1
        }

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ Redis/fallback
        session_manager.set(session_id, session_data)

        logger.info(f"‚úÖ Session created: {session_id}")

        return jsonify({
            'status': 'success',
            'data': parsed_data,
            'session_id': session_id,
            'missing_fields': missing_fields,
            'cached': from_cache
        })

    except Exception as e:
        logger.error(f"‚ùå Parse error: {e}", exc_info=True)
        return jsonify({
            'status': 'error',
            'message': str(e)
        }), 500


@app.route('/api/update-target', methods=['POST'])
@log_api_call()
def update_target():
    """
    API: –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞ (–≠–∫—Ä–∞–Ω 1 ‚Üí 2)
    """
    try:
        payload = request.json
        session_id = payload.get('session_id')
        data = payload.get('data')

        if not session_id:
            return jsonify({'status': 'error', 'message': 'session_id –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω'}), 400

        # –ü–æ–ª—É—á–∞–µ–º —Å–µ—Å—Å–∏—é
        session_data = session_manager.get(session_id)
        if not session_data:
            return jsonify({'status': 'error', 'message': '–°–µ—Å—Å–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞'}), 404

        # –û–±–Ω–æ–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ
        session_data['target_property'].update(data)
        session_data['step'] = 2

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º
        session_manager.update(session_id, session_data)

        logger.info(f"‚úÖ Target updated for session: {session_id}")

        return jsonify({
            'status': 'success',
            'message': '–î–∞–Ω–Ω—ã–µ –æ–±–Ω–æ–≤–ª–µ–Ω—ã'
        })

    except Exception as e:
        logger.error(f"‚ùå Update error: {e}", exc_info=True)
        return jsonify({
            'status': 'error',
            'message': str(e)
        }), 500


@app.route('/api/find-similar', methods=['POST'])
@log_api_call()
def find_similar():
    """
    API: –ü–æ–∏—Å–∫ –∞–Ω–∞–ª–æ–≥–æ–≤ (–≠–∫—Ä–∞–Ω 2)

    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –ø–∞—Ä—Å–µ—Ä –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è
    """
    try:
        payload = request.json
        session_id = payload.get('session_id')
        limit = payload.get('limit', 20)
        search_type = payload.get('search_type', 'building')
        use_async = payload.get('use_async', True)  # –§–ª–∞–≥ –¥–ª—è async –ø–∞—Ä—Å–∏–Ω–≥–∞

        if not session_id:
            return jsonify({'status': 'error', 'message': 'session_id –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω'}), 400

        # –ü–æ–ª—É—á–∞–µ–º —Å–µ—Å—Å–∏—é
        session_data = session_manager.get(session_id)
        if not session_data:
            return jsonify({'status': 'error', 'message': '–°–µ—Å—Å–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞'}), 404

        target = session_data['target_property']

        logger.info(f"üîç Searching comparables (type={search_type}, async={use_async})")

        with monitor('find_similar'):
            if use_async:
                # –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ (–±—ã—Å—Ç—Ä–µ–µ)
                import asyncio

                async def async_search():
                    async with AsyncCianParser(
                        headless=True,
                        delay=1.0,
                        max_concurrent=int(os.getenv('ASYNC_MAX_CONCURRENT', 5))
                    ) as parser:
                        if search_type == 'building':
                            # TODO: Implement search_similar_in_building_async
                            return await parser.search_similar_async(target, limit=limit)
                        else:
                            return await parser.search_similar_async(target, limit=limit)

                similar = asyncio.run(async_search())
            else:
                # –°–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ (–æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π)
                with PlaywrightParser(headless=True, delay=1.0) as parser:
                    if search_type == 'building':
                        similar = parser.search_similar_in_building(target, limit=limit)
                    else:
                        similar = parser.search_similar(target, limit=limit)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Å–µ—Å—Å–∏—é
        session_data['comparables'] = similar
        session_manager.update(session_id, session_data)

        logger.info(f"‚úÖ Found {len(similar)} comparables")

        return jsonify({
            'status': 'success',
            'comparables': similar,
            'count': len(similar),
            'search_type': search_type,
            'residential_complex': target.get('residential_complex', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')
        })

    except Exception as e:
        logger.error(f"‚ùå Search error: {e}", exc_info=True)
        return jsonify({
            'status': 'error',
            'message': str(e)
        }), 500


@app.route('/api/add-comparable', methods=['POST'])
@log_api_call()
def add_comparable():
    """
    API: –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∞–Ω–∞–ª–æ–≥–∞ –ø–æ URL (–≠–∫—Ä–∞–Ω 2)
    """
    try:
        payload = request.json
        session_id = payload.get('session_id')
        url = payload.get('url')

        if not session_id or not url:
            return jsonify({'status': 'error', 'message': 'session_id –∏ url –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã'}), 400

        # –ü–æ–ª—É—á–∞–µ–º —Å–µ—Å—Å–∏—é
        session_data = session_manager.get(session_id)
        if not session_data:
            return jsonify({'status': 'error', 'message': '–°–µ—Å—Å–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞'}), 404

        logger.info(f"üï∑Ô∏è Adding comparable: {url}")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
        cached_data = None
        if cache_manager:
            cached_data = cache_manager.get('property', url)

        if cached_data:
            logger.info(f"üíæ Using cached comparable: {url}")
            comparable_data = cached_data
        else:
            # –ü–∞—Ä—Å–∏–º
            with monitor('parse_comparable'):
                with PlaywrightParser(headless=True, delay=1.0) as parser:
                    comparable_data = parser.parse_detail_page(url)

            # –ö—ç—à–∏—Ä—É–µ–º
            if cache_manager and comparable_data:
                cache_manager.set('property', url, comparable_data, ttl=3600)

        # –î–æ–±–∞–≤–ª—è–µ–º –≤ —Å–ø–∏—Å–æ–∫
        session_data['comparables'].append(comparable_data)
        session_manager.update(session_id, session_data)

        logger.info(f"‚úÖ Comparable added")

        return jsonify({
            'status': 'success',
            'comparable': comparable_data
        })

    except Exception as e:
        logger.error(f"‚ùå Add comparable error: {e}", exc_info=True)
        return jsonify({
            'status': 'error',
            'message': str(e)
        }), 500


@app.route('/api/exclude-comparable', methods=['POST'])
@log_api_call()
def exclude_comparable():
    """
    API: –ò—Å–∫–ª—é—á–µ–Ω–∏–µ –∞–Ω–∞–ª–æ–≥–∞ –∏–∑ –∞–Ω–∞–ª–∏–∑–∞ (–≠–∫—Ä–∞–Ω 2)
    """
    try:
        payload = request.json
        session_id = payload.get('session_id')
        index = payload.get('index')

        if not session_id or index is None:
            return jsonify({'status': 'error', 'message': 'session_id –∏ index –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã'}), 400

        # –ü–æ–ª—É—á–∞–µ–º —Å–µ—Å—Å–∏—é
        session_data = session_manager.get(session_id)
        if not session_data:
            return jsonify({'status': 'error', 'message': '–°–µ—Å—Å–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞'}), 404

        comparables = session_data['comparables']

        if 0 <= index < len(comparables):
            comparables[index]['excluded'] = True
            session_manager.update(session_id, session_data)
            logger.info(f"‚úÖ Comparable {index} excluded")

        return jsonify({'status': 'success'})

    except Exception as e:
        logger.error(f"‚ùå Exclude error: {e}", exc_info=True)
        return jsonify({
            'status': 'error',
            'message': str(e)
        }), 500


@app.route('/api/analyze', methods=['POST'])
@log_api_call()
def analyze():
    """
    API: –ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ (–≠–∫—Ä–∞–Ω 3)

    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ PostgreSQL
    """
    start_time = time.time()

    try:
        payload = request.json
        session_id = payload.get('session_id')
        filter_outliers = payload.get('filter_outliers', True)
        use_median = payload.get('use_median', True)

        if not session_id:
            return jsonify({'status': 'error', 'message': 'session_id –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω'}), 400

        # –ü–æ–ª—É—á–∞–µ–º —Å–µ—Å—Å–∏—é
        session_data = session_manager.get(session_id)
        if not session_data:
            return jsonify({'status': 'error', 'message': '–°–µ—Å—Å–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞'}), 404

        logger.info(f"üìä Starting analysis for session: {session_id}")

        # –í–∞–ª–∏–¥–∞—Ü–∏—è –∏ —Å–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
        try:
            with monitor('model_validation'):
                target_property = TargetProperty(**session_data['target_property'])
                comparables = [
                    ComparableProperty(**c)
                    for c in session_data['comparables']
                ]

                request_model = AnalysisRequest(
                    target_property=target_property,
                    comparables=comparables,
                    filter_outliers=filter_outliers,
                    use_median=use_median
                )

        except Exception as e:
            logger.error(f"‚ùå Validation error: {e}", exc_info=True)
            return jsonify({
                'status': 'error',
                'message': f'–û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö: {e}'
            }), 400

        # –ê–Ω–∞–ª–∏–∑
        with monitor('analysis'):
            analyzer = RealEstateAnalyzer()
            result = analyzer.analyze(request_model)

        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ JSON
        result_dict = result.dict()

        # –ú–µ—Ç—Ä–∏–∫–∏
        metrics = analyzer.get_metrics()
        result_dict['metrics'] = metrics

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Å–µ—Å—Å–∏—é
        session_data['analysis'] = result_dict
        session_data['step'] = 3
        session_manager.update(session_id, session_data)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ PostgreSQL
        if postgres_manager:
            try:
                duration = time.time() - start_time
                metadata = {
                    'user_ip': request.remote_addr,
                    'user_agent': request.headers.get('User-Agent'),
                    'duration_seconds': duration
                }

                with monitor('save_to_postgres'):
                    postgres_manager.save_analysis(
                        session_id=session_id,
                        target_property=session_data['target_property'],
                        analysis_result=result_dict,
                        metadata=metadata
                    )

                logger.info(f"üíæ Analysis saved to PostgreSQL")

            except Exception as e:
                logger.error(f"‚ö†Ô∏è Failed to save to PostgreSQL: {e}")

        logger.info(f"‚úÖ Analysis completed in {time.time() - start_time:.2f}s")

        return jsonify({
            'status': 'success',
            'analysis': result_dict
        })

    except Exception as e:
        logger.error(f"‚ùå Analysis error: {e}", exc_info=True)
        return jsonify({
            'status': 'error',
            'message': str(e)
        }), 500


@app.route('/api/session/<session_id>', methods=['GET'])
@log_api_call()
def get_session(session_id):
    """
    API: –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —Å–µ—Å—Å–∏–∏
    """
    session_data = session_manager.get(session_id)

    if not session_data:
        return jsonify({'status': 'error', 'message': '–°–µ—Å—Å–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞'}), 404

    return jsonify({
        'status': 'success',
        'data': session_data
    })


@app.route('/api/metrics', methods=['GET'])
def get_metrics_endpoint():
    """
    API: –ü–æ–ª—É—á–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    """
    try:
        metrics = get_metrics()
        stats = metrics.get_all_stats()

        # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É storage
        storage_stats = {
            'session_manager': session_manager.get_stats() if session_manager else {},
            'postgres_manager': postgres_manager.get_stats() if postgres_manager else {},
            'cache_manager': cache_manager.get_stats() if cache_manager else {}
        }

        return jsonify({
            'status': 'success',
            'performance_metrics': stats,
            'storage_stats': storage_stats
        })

    except Exception as e:
        logger.error(f"‚ùå Metrics error: {e}")
        return jsonify({
            'status': 'error',
            'message': str(e)
        }), 500


@app.route('/health', methods=['GET'])
def health_check():
    """
    Health check endpoint –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
    """
    health_status = {
        'status': 'healthy',
        'timestamp': datetime.now().isoformat(),
        'services': {
            'redis': session_manager._redis_available if session_manager else False,
            'postgres': postgres_manager is not None,
            'cache': cache_manager is not None
        }
    }

    return jsonify(health_status)


# ==========================================
# Helper functions
# ==========================================

def _identify_missing_fields(parsed_data: Dict) -> List[Dict]:
    """
    –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –ø–æ–ª—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    (–ö–æ–ø–∏—è –∏–∑ app_new.py)
    """
    missing = []

    required_fields = [
        {
            'field': 'repair_level',
            'label': 'üé® –£—Ä–æ–≤–µ–Ω—å –æ—Ç–¥–µ–ª–∫–∏',
            'type': 'select',
            'options': ['—á–µ—Ä–Ω–æ–≤–∞—è', '—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è', '—É–ª—É—á—à–µ–Ω–Ω–∞—è', '–ø—Ä–µ–º–∏—É–º', '–ª—é–∫—Å'],
            'description': '–ö–∞—á–µ—Å—Ç–≤–æ –æ—Ç–¥–µ–ª–∫–∏',
            'default': '—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è'
        },
        {
            'field': 'district_type',
            'label': 'üèôÔ∏è –¢–∏–ø —Ä–∞–π–æ–Ω–∞',
            'type': 'select',
            'options': ['center', 'near_center', 'residential', 'transitional', 'remote'],
            'description': '–†–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏–µ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —Ü–µ–Ω—Ç—Ä–∞',
            'default': 'residential'
        },
        {
            'field': 'surroundings',
            'label': 'üå≥ –û–∫—Ä—É–∂–µ–Ω–∏–µ',
            'type': 'multiselect',
            'options': ['–ø–∞—Ä–∫–∏', '—à–∫–æ–ª—ã', '—Ç–æ—Ä–≥–æ–≤–ª—è', '–æ—Ñ–∏—Å—ã', '–ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω–æ—Å—Ç—å', '–ø—Ä–µ—Å—Ç–∏–∂'],
            'description': '–ß—Ç–æ –µ—Å—Ç—å —Ä—è–¥–æ–º',
            'default': []
        },
        {
            'field': 'security_level',
            'label': 'üîí –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å',
            'type': 'select',
            'options': ['–Ω–µ—Ç', '–¥–Ω–µ–≤–Ω–∞—è', '24/7', '24/7+–∫–æ–Ω—Å—å–µ—Ä–∂', '24/7+–∫–æ–Ω—Å—å–µ—Ä–∂+–≤–∏–¥–µ–æ'],
            'description': '–°–∏—Å—Ç–µ–º–∞ –æ—Ö—Ä–∞–Ω—ã',
            'default': '–Ω–µ—Ç'
        },
        {
            'field': 'parking_spaces',
            'label': 'üöô –ú–∞—à–∏–Ω–æ–º–µ—Å—Ç',
            'type': 'number',
            'description': '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –º–µ—Å—Ç',
            'default': 0,
            'min': 0,
            'max': 999
        },
        {
            'field': 'sports_amenities',
            'label': '‚öΩ –°–ø–æ—Ä—Ç',
            'type': 'multiselect',
            'options': ['–¥–µ—Ç—Å–∫–∞—è', '—Å–ø–æ—Ä—Ç–ø–ª–æ—â–∞–¥–∫–∞', '—Ç—Ä–µ–Ω–∞–∂–µ—Ä', '–±–∞—Å—Å–µ–π–Ω', '–ø–æ–ª–Ω—ã–π'],
            'description': '–°–ø–æ—Ä—Ç–∏–≤–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã',
            'default': []
        },
        {
            'field': 'view_type',
            'label': 'üåÖ –í–∏–¥ –∏–∑ –æ–∫–Ω–∞',
            'type': 'select',
            'options': ['—Ö—É–¥–æ–≥–æ–≤', '–¥–æ–º', '—É–ª–∏—Ü–∞', '–ø–∞—Ä–∫', '–≤–æ–¥–∞', '–≥–æ—Ä–æ–¥', '–∑–∞–∫–∞—Ç', '–ø—Ä–µ–º–∏—É–º'],
            'description': '–ß—Ç–æ –≤–∏–¥–Ω–æ',
            'default': '—É–ª–∏—Ü–∞'
        },
        {
            'field': 'noise_level',
            'label': 'üîá –£—Ä–æ–≤–µ–Ω—å —à—É–º–∞',
            'type': 'select',
            'options': ['–æ—á–µ–Ω—å_—Ç–∏—Ö–æ', '—Ç–∏—Ö–æ', '–Ω–æ—Ä–º–∞–ª—å–Ω–æ', '—à—É–º–Ω–æ', '–æ—á–µ–Ω—å_—à—É–º–Ω–æ'],
            'description': '–®—É–º–Ω–æ—Å—Ç—å',
            'default': '–Ω–æ—Ä–º–∞–ª—å–Ω–æ'
        },
        {
            'field': 'crowded_level',
            'label': 'üë• –õ—é–¥–Ω–æ—Å—Ç—å',
            'type': 'select',
            'options': ['–ø—É—Å—Ç—ã–Ω–Ω–æ', '—Å–ø–æ–∫–æ–π–Ω–æ', '–Ω–æ—Ä–º–∞–ª—å–Ω–æ', '–æ–∂–∏–≤–ª–µ–Ω–Ω–æ', '–æ—á–µ–Ω—å_–æ–∂–∏–≤–ª–µ–Ω–Ω–æ'],
            'description': '–ù–∞—Å–∫–æ–ª—å–∫–æ –ª—é–¥–Ω–æ',
            'default': '–Ω–æ—Ä–º–∞–ª—å–Ω–æ'
        },
    ]

    characteristics_mapping = {
        'ceiling_height': '–í—ã—Å–æ—Ç–∞ –ø–æ—Ç–æ–ª–∫–æ–≤',
        'build_year': '–ì–æ–¥ –ø–æ—Å—Ç—Ä–æ–π–∫–∏',
        'house_type': '–¢–∏–ø –¥–æ–º–∞',
        'has_elevator': '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ª–∏—Ñ—Ç–æ–≤',
    }

    characteristics = parsed_data.get('characteristics', {})

    for field_info in required_fields:
        field = field_info['field']

        if field in parsed_data and parsed_data[field] is not None:
            continue

        char_key = characteristics_mapping.get(field)
        if char_key and char_key in characteristics:
            continue

        missing.append(field_info)

    return missing


# ==========================================
# Startup
# ==========================================

if __name__ == '__main__':
    logger.info("=" * 60)
    logger.info("üöÄ Starting Cian Analyzer (Production Mode)")
    logger.info("=" * 60)
    logger.info(f"üìä Redis: {'‚úÖ Connected' if session_manager._redis_available else '‚ö†Ô∏è Fallback mode'}")
    logger.info(f"üìä PostgreSQL: {'‚úÖ Connected' if postgres_manager else '‚ùå Disabled'}")
    logger.info(f"üìä Cache: {'‚úÖ Enabled' if cache_manager else '‚ùå Disabled'}")
    logger.info("=" * 60)

    app.run(
        debug=os.getenv('FLASK_DEBUG', 'false').lower() == 'true',
        host='0.0.0.0',
        port=5002
    )
